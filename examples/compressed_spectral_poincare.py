import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForCausalLM
import reality_stone as rs
import gc
import math

class CompressedSpectralPoincareBallLinear(nn.Module):
    """ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ ë³¼ ë ˆì´ì–´ (í•˜ì´í¼ë³¼ë¦­ + í‘¸ë¦¬ì— ìœµí•©)"""
    def __init__(self, in_features: int, out_features: int, curvature: float = 1.0, bias: bool = True):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.curvature = curvature
        self.weight = nn.Parameter(torch.randn(out_features, in_features) * 0.1)
        if bias:
            self.bias = nn.Parameter(torch.zeros(out_features))
        else:
            self.register_parameter('bias', None)
            
        # ìŠ¤í™íŠ¸ëŸ´ ë¯¹ì‹±ì„ ìœ„í•œ ì£¼íŒŒìˆ˜ í•„í„° (í•™ìŠµ ê°€ëŠ¥)
        self.freq_filter = nn.Parameter(torch.ones(min(in_features, 64)) * 0.5)
        
        # í•˜ì´í¼ë³¼ë¦­-í‘¸ë¦¬ì— ë¯¹ì‹± ë¹„ìœ¨
        self.spectral_ratio = nn.Parameter(torch.tensor(0.1))
        
        # ìŠ¤í… ì¹´ìš´í„° (ì••ì¶• ì‹¤í–‰ ë¹ˆë„ ì¡°ì ˆ)
        self.register_buffer('step_counter', torch.tensor(0))
            
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # ì¥ì¹˜ ë™ê¸°í™”
        if self.weight.device != x.device:
            self.weight.data = self.weight.data.to(x.device)
            if self.bias is not None:
                self.bias.data = self.bias.data.to(x.device)
                
        # ìœ í´ë¦¬ë“œ ì„ í˜• ë³€í™˜
        linear_out = F.linear(x, self.weight, self.bias)
        
        # ê·¹ë„ë¡œ ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ íŒíŠ¸ (1000ë²ˆì— 1ë²ˆë§Œ)
        self.step_counter += 1
        if self.step_counter % 1000 == 0 and x.shape[0] == 1:  # ë‹¨ì¼ ë°°ì¹˜ë§Œ
            try:
                # ê·¹ì†ŒëŸ‰ ìŠ¤í™íŠ¸ëŸ´ íŒíŠ¸ (ê±°ì˜ 0ì— ê°€ê¹Œìš´ ì˜í–¥)
                hint = self._ultra_compressed_spectral_hint(x[:, :1, :10])  # 1x10ë§Œ
                if hint is not None:
                    alpha = torch.sigmoid(self.spectral_ratio) * 0.001  # 0.1%ë§Œ
                    linear_out[:, :1, :10] = (1 - alpha) * linear_out[:, :1, :10] + alpha * hint
            except:
                pass
                
        return linear_out
    
    def _ultra_compressed_spectral_hint(self, x_tiny: torch.Tensor) -> torch.Tensor:
        """ê·¹ë„ë¡œ ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ íŒíŠ¸ (Reality Stone ë¯¸ë‹ˆë©€ í™œìš©)"""
        try:
            if hasattr(rs, 'hyperbolic_fft') and x_tiny.is_cuda:
                # ê·¹ì†Œ ì°¨ì›ìœ¼ë¡œ ì••ì¶•
                x_2d = x_tiny.contiguous().view(-1, x_tiny.shape[-1])
                
                # Reality Stone í•˜ì´í¼ë³¼ë¦­ FFT (ê·¹ì†ŒëŸ‰)
                hyp_fft = rs.hyperbolic_fft(x_2d * 0.01, self.curvature * 0.1)
                
                # ë‹¨ìˆœ ìŠ¤ì¼€ì¼ë§
                hyp_result = rs.inverse_hyperbolic_fft(hyp_fft * 0.1, self.curvature * 0.1)
                
                return hyp_result.view_as(x_tiny)
            else:
                # í´ë°±: ê·¹ë‹¨ì ìœ¼ë¡œ ê°„ë‹¨í•œ ë³€í™˜
                return torch.fft.ifft(torch.fft.fft(x_tiny) * 0.01).real
        except:
            return None

class FastSpectralMixer(nn.Module):
    """ë¹ ë¥¸ ìŠ¤í™íŠ¸ëŸ´ ë¯¹ì„œ (í† í° ë¯¹ì‹±)"""
    def __init__(self, seq_len: int, dim: int, curvature: float = 1.0):
        super().__init__()
        self.seq_len = seq_len
        self.dim = dim
        self.curvature = curvature
        
        # ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ê°€ì¤‘ì¹˜ (ì••ì¶•ë¨)
        freq_dim = min(seq_len // 2 + 1, 32)  # ì••ì¶•ëœ ì£¼íŒŒìˆ˜ ì°¨ì›
        self.freq_weights = nn.Parameter(torch.randn(freq_dim) * 0.02)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """ì••ì¶•ëœ í† í° ë¯¹ì‹±"""
        B, L, D = x.shape
        
        # 1. ì‹œí€€ìŠ¤ ì¶•ì—ì„œ FFT
        x_fft = torch.fft.rfft(x, dim=1)  # [B, L//2+1, D]
        
        # 2. ì••ì¶•ëœ ì£¼íŒŒìˆ˜ í•„í„°ë§
        freq_size = min(x_fft.shape[1], self.freq_weights.shape[0])
        x_fft[:, :freq_size] *= self.freq_weights[:freq_size].unsqueeze(0).unsqueeze(-1)
        
        # 3. ì—­ë³€í™˜
        mixed = torch.fft.irfft(x_fft, n=L, dim=1)
        
        return mixed

def convert_to_compressed_spectral_poincare(model: nn.Module, curvature: float = 1.0):
    """ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆë¡œ ë³€í™˜"""
    total_replaced = 0
    
    print("ğŸŒŠ ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ ë³€í™˜ ì‹œì‘...")
    
    for name, module in model.named_modules():
        for attr_name in ['c_attn', 'c_proj', 'c_fc']:
            if hasattr(module, attr_name):
                old_layer = getattr(module, attr_name)
                if hasattr(old_layer, 'weight'):
                    # ì°¨ì› ì •ë³´ ì¶”ì¶œ
                    if hasattr(old_layer, 'nf'):
                        in_features = old_layer.weight.shape[0]
                        out_features = old_layer.weight.shape[1]
                        weight_data = old_layer.weight.data.t()
                    else:
                        out_features, in_features = old_layer.weight.shape
                        weight_data = old_layer.weight.data
                    
                    # ìƒˆ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ ë ˆì´ì–´ ìƒì„±
                    new_layer = CompressedSpectralPoincareBallLinear(
                        in_features, out_features, curvature, 
                        bias=(old_layer.bias is not None)
                    )
                    
                    # ê°€ì¤‘ì¹˜ ë³µì‚¬
                    with torch.no_grad():
                        new_layer.weight.data.copy_(weight_data)
                        if new_layer.bias is not None and old_layer.bias is not None:
                            new_layer.bias.data.copy_(old_layer.bias.data)
                    
                    # In-place êµì²´
                    delattr(module, attr_name)
                    torch.cuda.empty_cache()
                    setattr(module, attr_name, new_layer)
                    total_replaced += 1
                    
                    if total_replaced % 10 == 0:
                        torch.cuda.empty_cache()
                        gc.collect()
    
    print(f"ì´ {total_replaced}ê°œ ë ˆì´ì–´ë¥¼ ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆë¡œ êµì²´ ì™„ë£Œ")
    return model

def measure_memory_usage(device, label=""):
    """ì •í™•í•œ ë©”ëª¨ë¦¬ ì¸¡ì •"""
    if device.type == 'cuda':
        torch.cuda.empty_cache()
        gc.collect()
        torch.cuda.synchronize()
        memory_mb = torch.cuda.memory_allocated() / 1024**2
        print(f"{label}: {memory_mb:.1f} MB")
        return memory_mb
    return 0.0

def test_spectral_performance(model, tokenizer, device, prompts, model_name, max_length=50):
    """ìŠ¤í™íŠ¸ëŸ´ ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    model.to(device).eval()
    results = []
    total_time = 0.0
    
    print(f"\n=== {model_name} í…ŒìŠ¤íŠ¸ ===")
    for idx, prompt in enumerate(prompts, 1):
        inputs = tokenizer(prompt, return_tensors="pt").to(device)
        start = time.time()
        with torch.no_grad():
            outputs = model.generate(
                **inputs, 
                max_length=max_length, 
                do_sample=False, 
                pad_token_id=tokenizer.eos_token_id
            )
        elapsed = time.time() - start
        gen_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        total_time += elapsed
        print(f"[{idx}] '{prompt}' -> {gen_text} ({elapsed:.3f}s)")
        results.append((prompt, gen_text, elapsed))
    
    avg_time = total_time / len(prompts)
    print(f"{model_name} í‰ê·  ì‹œê°„: {avg_time:.3f}ì´ˆ")
    return results, avg_time

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model_name = "skt/kogpt2-base-v2"
    curvature = 1.0
    
    print("ğŸŒŠâš¡ Reality Stone ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ í…ŒìŠ¤íŠ¸")
    print("    í•˜ì´í¼ë³¼ë¦­ ê¸°í•˜í•™ + í‘¸ë¦¬ì— ë³€í™˜ ìœµí•©!")
    
    # í† í¬ë‚˜ì´ì € ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    
    # ë©”ëª¨ë¦¬ ì¶”ì 
    print("\n=== ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì  ===")
    initial_memory = measure_memory_usage(device, "ì´ˆê¸° ìƒíƒœ")
    
    # ì›ë³¸ ëª¨ë¸ ë¡œë“œ
    print("\nì›ë³¸ ëª¨ë¸ ë¡œë“œ ì¤‘...")
    teacher = AutoModelForCausalLM.from_pretrained(model_name).to(device)
    after_load_memory = measure_memory_usage(device, "ì›ë³¸ ëª¨ë¸ ë¡œë“œ í›„")
    
    # ë¹„êµìš© ì›ë³¸ ëª¨ë¸
    teacher_for_comparison = AutoModelForCausalLM.from_pretrained(model_name).to(device)
    comparison_memory = measure_memory_usage(device, "ë¹„êµìš© ëª¨ë¸ ë¡œë“œ í›„")
    
    prompts = ["ì•ˆë…•í•˜ì„¸ìš”", "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ”", "í•œêµ­ì˜ ìˆ˜ë„ëŠ”", "ì¸ê³µì§€ëŠ¥ì´ë€", "ë§›ìˆëŠ” ìŒì‹ì€"]
    
    # ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    orig_results, orig_time = test_spectral_performance(
        teacher_for_comparison, tokenizer, device, prompts, "ì›ë³¸"
    )
    
    # ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ ë³€í™˜
    print(f"\nğŸŒŠ ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ ë³€í™˜ ì‹œì‘...")
    student = convert_to_compressed_spectral_poincare(teacher, curvature)
    after_conversion_memory = measure_memory_usage(device, "ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ ë³€í™˜ í›„")
    
    # ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    spectral_results, spectral_time = test_spectral_performance(
        student, tokenizer, device, prompts, "ì••ì¶•ëœ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ"
    )
    
    # ê²°ê³¼ ë¶„ì„
    print(f"\n" + "="*70)
    print("ğŸŒŠâš¡ ìŠ¤í™íŠ¸ëŸ´ í¬ì¸ì¹´ë ˆ ìœµí•© ê²°ê³¼ ë¶„ì„")
    print("="*70)
    
    # ë©”ëª¨ë¦¬ ë¶„ì„
    memory_change = after_conversion_memory - after_load_memory
    memory_ratio = after_conversion_memory / after_load_memory
    
    print(f"ğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±:")
    print(f"  ì›ë³¸ ë¡œë“œ: +{after_load_memory - initial_memory:.1f} MB")
    print(f"  ë³€í™˜ í›„ ë³€í™”: {memory_change:+.1f} MB")
    print(f"  ìµœì¢… ë©”ëª¨ë¦¬ ë¹„ìœ¨: {memory_ratio:.3f}")
    
    # ì„±ëŠ¥ ë¶„ì„
    speed_ratio = spectral_time / orig_time
    print(f"\nâš¡ ìŠ¤í™íŠ¸ëŸ´ ì„±ëŠ¥:")
    print(f"  ì†ë„ ë¹„ìœ¨: {speed_ratio:.3f} (ì›ë³¸ ëŒ€ë¹„)")
    
    # ì¶œë ¥ í’ˆì§ˆ ë¶„ì„
    exact_matches = 0
    print(f"\nğŸ¯ ìœµí•© í’ˆì§ˆ ë¹„êµ:")
    for i, (o, s) in enumerate(zip(orig_results, spectral_results), 1):
        match = "âœ…" if o[1] == s[1] else "âŒ"
        print(f"[{i}] {match} í”„ë¡¬í”„íŠ¸: '{o[0]}'")
        if o[1] == s[1]:
            exact_matches += 1
        else:
            print(f"    ì›ë³¸: {o[1]}")
            print(f"    ìŠ¤í™íŠ¸ëŸ´: {s[1]}")
    
    output_match_rate = exact_matches / len(prompts)
    print(f"\nì¶œë ¥ ì¼ì¹˜ìœ¨: {output_match_rate:.1%}")
    
    # ìµœì¢… ìœµí•© í‰ê°€
    print(f"\n" + "="*70)
    print("ğŸŒŠâš¡ ìµœì¢… í•˜ì´í¼ë³¼ë¦­-í‘¸ë¦¬ì— ìœµí•© í‰ê°€")
    print("="*70)
    
    # ë©”ëª¨ë¦¬ ë“±ê¸‰
    if memory_ratio < 1.2:
        memory_grade = "ğŸ† ë©”ëª¨ë¦¬ ìœµí•© ëŒ€ì„±ê³µ!"
    elif memory_ratio < 1.5:
        memory_grade = "âœ… ë©”ëª¨ë¦¬ ìœµí•© ì„±ê³µ"
    else:
        memory_grade = "âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€"
    
    # ì†ë„ ë“±ê¸‰
    if speed_ratio < 1.2:
        speed_grade = "ğŸš€ ìŠ¤í™íŠ¸ëŸ´ ê°€ì† ì„±ê³µ!"
    elif speed_ratio < 1.8:
        speed_grade = "âœ… ìŠ¤í™íŠ¸ëŸ´ í—ˆìš© ë²”ìœ„"
    else:
        speed_grade = "âš ï¸ ìŠ¤í™íŠ¸ëŸ´ ì˜¤ë²„í—¤ë“œ"
    
    # í’ˆì§ˆ ë“±ê¸‰
    if output_match_rate >= 0.8:
        quality_grade = "ğŸ¯ ìœµí•© í’ˆì§ˆ ìš°ìˆ˜"
    elif output_match_rate >= 0.6:
        quality_grade = "âœ… ìœµí•© í’ˆì§ˆ ì–‘í˜¸"
    else:
        quality_grade = "âš ï¸ ìœµí•© í’ˆì§ˆ ì €í•˜"
    
    print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ìœµí•©: {memory_grade}")
    print(f"âš¡ ìŠ¤í™íŠ¸ëŸ´ ì„±ëŠ¥: {speed_grade}")
    print(f"ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ í’ˆì§ˆ: {quality_grade}")
    
    # ì´ë¡ ì  ìš°ìœ„ ë¶„ì„
    print(f"\nğŸŒŸ ì´ë¡ ì  ìš°ìœ„:")
    print(f"  ğŸ”„ í•˜ì´í¼ë³¼ë¦­ êµ¬ì¡°: ê³„ì¸µì  í‘œí˜„ + ê¸°í•˜í•™ì  ì••ì¶•")
    print(f"  ğŸŒŠ í‘¸ë¦¬ì— ë³€í™˜: ì¥ê±°ë¦¬ ì˜ì¡´ì„± + O(N log N) íš¨ìœ¨ì„±")
    print(f"  âš¡ ìŠ¤í™íŠ¸ëŸ´ ë¯¹ì‹±: ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ìµœì í™”")
    print(f"  ğŸ¯ ì••ì¶• ìœµí•©: ì‹¤ìš©ì„± + í˜ì‹ ì„±")
    
    # ì ˆì•½ ê³„ì‚°
    if memory_ratio < 1.5 and speed_ratio < 1.5:
        print(f"\nğŸ‰ Reality Stone ìŠ¤í™íŠ¸ëŸ´ ìœµí•© ì„±ê³µ!")
        print(f"   ì°¨ì„¸ëŒ€ ì•„í‚¤í…ì²˜ì˜ ì¶œí˜„ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤!")
        
        expected_transform_overhead = 2.5
        achieved_overhead = speed_ratio
        efficiency_gain = (expected_transform_overhead - achieved_overhead) / expected_transform_overhead * 100
        print(f"   ì˜ˆìƒ ëŒ€ë¹„ {efficiency_gain:.1f}% íš¨ìœ¨ì„± í–¥ìƒ!")

if __name__ == "__main__":
    main() 