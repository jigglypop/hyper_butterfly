import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
import time
from tqdm import tqdm
import torch
import torch.nn as nn
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForCausalLM
import re
from collections import Counter
import copy
# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Enhanced RealityStone & Advanced Mathematical Utils â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    import reality_stone as rs
    print("âœ… RealityStone ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì„±ê³µ!")
    print(f"   ğŸŒŸ ë²„ì „: {getattr(rs, '__version__', 'Unknown')}")
    print(f"   ğŸš€ ê³ ê¸‰ ê¸°ëŠ¥: {', '.join(dir(rs)) if hasattr(rs, '__dict__') else 'Standard'}")
    RS_AVAILABLE = True
except ImportError:
    print("âš ï¸ RealityStone ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ - ìµœê³ ê¸‰ ìì²´ êµ¬í˜„ ì‚¬ìš©")
    RS_AVAILABLE = False

def enhanced_stereographic_projection(z: torch.Tensor, use_complex_log=True) -> torch.Tensor:
    """í–¥ìƒëœ ìŠ¤í…Œë ˆì˜¤ê·¸ë˜í”½ íˆ¬ì˜ (ë³µì†Œ ë¡œê·¸ ë° ì•ˆì •ì„± ê°œì„ )"""
    
    if use_complex_log:
        # ë³µì†Œ ë¡œê·¸ë¥¼ í™œìš©í•œ ë” ì•ˆì •ì ì¸ íˆ¬ì˜
        z_conj = torch.conj(z)
        norm_sq = (z * z_conj).real
        
        # ë¡œê·¸ ìŠ¤ì¼€ì¼ë§ìœ¼ë¡œ ìˆ˜ì¹˜ ì•ˆì •ì„± í–¥ìƒ
        log_factor = torch.log(1 + norm_sq + 1e-8)
        scaling = torch.exp(-log_factor / 4)  # ì ì‘ì  ìŠ¤ì¼€ì¼ë§
        
        z_scaled = z * scaling
        real, imag = z_scaled.real, z_scaled.imag
    else:
        real, imag = z.real, z.imag
    
    # ê°œì„ ëœ ë¶„ëª¨ ê³„ì‚° (ìˆ˜ì¹˜ ì•ˆì •ì„±)
    norm_sq = real**2 + imag**2
    denom = 1 + norm_sq
    epsilon = torch.finfo(real.dtype).eps * 10
    denom = torch.clamp(denom, min=epsilon)
    
    # ê³ ì •ë°€ ìŠ¤í…Œë ˆì˜¤ê·¸ë˜í”½ ì¢Œí‘œ
    X = 2 * real / denom
    Y = 2 * imag / denom
    Z = (norm_sq - 1) / denom
    
    # ë¶ê·¹ì  ê·¼ì²˜ì—ì„œì˜ íŠ¹ë³„ ì²˜ë¦¬
    pole_mask = norm_sq > 100  # ë¶ê·¹ì  ê·¼ì²˜
    X = torch.where(pole_mask, torch.sign(real) * 0.99, X)
    Y = torch.where(pole_mask, torch.sign(imag) * 0.99, Y)
    Z = torch.where(pole_mask, torch.ones_like(Z) * 0.99, Z)
    
    return torch.stack([X, Y, Z], dim=-1)

def enhanced_inverse_stereographic_projection(sphere_coords: torch.Tensor, 
                                            use_mobius_normalization=True) -> torch.Tensor:
    """í–¥ìƒëœ ì—­ìŠ¤í…Œë ˆì˜¤ê·¸ë˜í”½ íˆ¬ì˜ (ë«¼ë¹„ìš°ìŠ¤ ì •ê·œí™” í¬í•¨)"""
    
    X, Y, Z = sphere_coords[..., 0], sphere_coords[..., 1], sphere_coords[..., 2]
    
    # í–¥ìƒëœ ë¶ê·¹ì  ì²˜ë¦¬
    epsilon = torch.finfo(X.dtype).eps * 100
    denom = torch.clamp(1 - Z, min=epsilon)
    
    real = X / denom
    imag = Y / denom
    
    if use_mobius_normalization:
        # ë«¼ë¹„ìš°ìŠ¤ ë³€í™˜ì„ í†µí•œ ì •ê·œí™”
        complex_result = torch.complex(real, imag)
        norm = torch.abs(complex_result)
        
        # ë‹¨ìœ„ì› ë‚´ë¶€ë¡œ ì •ê·œí™”
        scale_factor = torch.where(norm > 0.95, 0.95 / (norm + epsilon), torch.ones_like(norm))
        complex_result = complex_result * scale_factor
        
        return complex_result
    
    return torch.complex(real, imag)

def advanced_riemann_distance(z1: torch.Tensor, z2: torch.Tensor, 
                            metric_type='hyperbolic') -> torch.Tensor:
    """ê³ ê¸‰ ë¦¬ë§Œ êµ¬ë©´ ê±°ë¦¬ (ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ì§€ì›)"""
    
    if metric_type == 'hyperbolic':
        # í•˜ì´í¼ë³¼ë¦­ ê±°ë¦¬ (í¬ì¸ì¹´ë ˆ ëª¨ë¸)
        z1_conj = torch.conj(z1)
        z2_conj = torch.conj(z2)
        
        numerator = torch.abs(z1 - z2)**2
        denom1 = 1 - torch.abs(z1)**2
        denom2 = 1 - torch.abs(z2)**2
        
        epsilon = 1e-8
        denom_product = torch.clamp(denom1 * denom2, min=epsilon)
        
        ratio = 1 + 2 * numerator / denom_product
        ratio = torch.clamp(ratio, min=1 + epsilon)
        
        return torch.acosh(ratio)
        
    elif metric_type == 'spherical':
        # êµ¬ë©´ ê±°ë¦¬ (ê¸°ì¡´ ë°©ì‹ ê°œì„ )
        p1 = enhanced_stereographic_projection(z1)
        p2 = enhanced_stereographic_projection(z2)
        
        dot_product = torch.sum(p1 * p2, dim=-1)
        dot_product = torch.clamp(dot_product, -1 + 1e-7, 1 - 1e-7)
        
        return torch.acos(dot_product)
        
    elif metric_type == 'fubini_study':
        # í‘¸ë¹„ë‹ˆ-ìŠ¤í„°ë”” ë©”íŠ¸ë¦­
        z1_norm = torch.norm(torch.stack([z1.real, z1.imag], dim=-1), dim=-1)
        z2_norm = torch.norm(torch.stack([z2.real, z2.imag], dim=-1), dim=-1)
        
        inner_product = torch.real(torch.conj(z1) * z2)
        
        ratio = torch.abs(inner_product) / (z1_norm * z2_norm + 1e-8)
        ratio = torch.clamp(ratio, max=1 - 1e-7)
        
        return torch.acos(ratio)
    
    else:
        raise ValueError(f"Unknown metric type: {metric_type}")

def advanced_mobius_transform(z: torch.Tensor, params: dict) -> torch.Tensor:
    """ê³ ê¸‰ ë«¼ë¹„ìš°ìŠ¤ ë³€í™˜ (ë§¤ê°œë³€ìˆ˜í™” ê°œì„ )"""
    
    a = params.get('a', torch.tensor(1.0, dtype=z.dtype, device=z.device))
    b = params.get('b', torch.tensor(0.0, dtype=z.dtype, device=z.device))
    c = params.get('c', torch.tensor(0.0, dtype=z.dtype, device=z.device))
    d = params.get('d', torch.tensor(1.0, dtype=z.dtype, device=z.device))
    
    # í–‰ë ¬ì‹ ì •ê·œí™”
    det = a * d - b * c
    if torch.abs(det) < 1e-7:
        # íŠ¹ì´ ë³€í™˜ ì²˜ë¦¬
        return z
    
    sqrt_det = torch.sqrt(torch.abs(det))
    a, b, c, d = a/sqrt_det, b/sqrt_det, c/sqrt_det, d/sqrt_det
    
    numerator = a * z + b
    denominator = c * z + d
    
    # ì•ˆì „í•œ ë‚˜ëˆ—ì…ˆ
    epsilon = 1e-8
    mask = torch.abs(denominator) < epsilon
    
    # ë¬´í•œëŒ€ ì²˜ë¦¬ ê°œì„ 
    inf_value = torch.tensor(float('inf'), dtype=z.dtype, device=z.device)
    if torch.is_complex(z):
        inf_value = torch.complex(inf_value, torch.tensor(0.0, dtype=z.real.dtype, device=z.device))
    
    result = torch.where(mask, inf_value, numerator / denominator)
    
    return result

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Fast SVD Compressor for Speed Optimization â”€â”€â”€â”€â”€â”€â”€â”€â”€
class FastSVDCompressor:
    """ë¹ ë¥¸ SVD ì••ì¶•ê¸° (ì†ë„ ìµœì í™”)"""
    
    def __init__(self, W: torch.Tensor, compression_ratio=0.1):
        """
        Args:
            W: ê°€ì¤‘ì¹˜ í–‰ë ¬ [out_f, in_f]
            compression_ratio: ì••ì¶•ë¥ 
        """
        self.out_f, self.in_f = W.shape
        self.compression_ratio = compression_ratio
        
        print(f"    âš¡ ê³ ì† SVD ì••ì¶•: {W.shape}, ì••ì¶•ë¥ ={compression_ratio:.1%}")
        
        self._apply_fast_svd_compression(W)
    
    def _apply_fast_svd_compression(self, W: torch.Tensor):
        """ë¹ ë¥¸ SVD ì••ì¶• ì ìš©"""
        
        # ì ì‘ì  ë­í¬ ì„ íƒ (ì—ë„ˆì§€ ê¸°ë°˜)
        U, S, V = torch.svd(W.float())
        
        # ì—ë„ˆì§€ ì„ê³„ê°’ ê¸°ë°˜ ë­í¬ ì„ íƒ (í’ˆì§ˆ ìš°ì„ )
        energy_cumsum = torch.cumsum(S**2, dim=0)
        total_energy = energy_cumsum[-1]
        energy_threshold = 0.95  # 95% ì—ë„ˆì§€ ë³´ì¡´ (90% â†’ 95%)
        
        energy_rank = torch.sum(energy_cumsum < total_energy * energy_threshold).item() + 1
        target_rank = max(8, int(min(W.shape) * self.compression_ratio * 6))  # ë” ê´€ëŒ€ (4â†’6ë°°)
        
        # ìµœì  ë­í¬ ì„ íƒ (í’ˆì§ˆ ìš°ì„ )
        optimal_rank = min(energy_rank, target_rank, len(S), min(W.shape) // 3)  # 1/3 ì œí•œ (1/4â†’1/3)
        
        # ì••ì¶•ëœ íŒŒë¼ë¯¸í„° ì €ì¥
        self.U = nn.Parameter(U[:, :optimal_rank].to(W.dtype))
        self.S = nn.Parameter(S[:optimal_rank].to(W.dtype))
        self.V = nn.Parameter(V[:, :optimal_rank].to(W.dtype))
        
        # ì••ì¶• íš¨ê³¼ ê³„ì‚°
        original_params = W.numel()
        compressed_params = self.U.numel() + self.S.numel() + self.V.numel()
        actual_ratio = compressed_params / original_params
        
        print(f"       âœ… ê³ ì† ì••ì¶• ì™„ë£Œ: rank {optimal_rank}, ì‹¤ì œ ì••ì¶•ë¥  {actual_ratio:.1%}")
    
    def reconstruct(self) -> torch.Tensor:
        """ì••ì¶•ëœ ê°€ì¤‘ì¹˜ ë³µì›"""
        return self.U @ torch.diag(self.S) @ self.V.t()
    
    def apply(self, x: torch.Tensor) -> torch.Tensor:
        """ì••ì¶•ëœ ì—°ì‚° ì ìš© (ìµœì í™”ëœ ë²„ì „)"""
        # 3ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ íš¨ìœ¨ì  ê³„ì‚°: x @ V @ diag(S) @ U.t()
        step1 = x @ self.V  # [batch, rank]
        step2 = step1 * self.S.unsqueeze(0)  # [batch, rank] (broadcasting)
        step3 = step2 @ self.U.t()  # [batch, out_features]
        return step3

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Enhanced FFT-SVD Hybrid Compressor â”€â”€â”€â”€â”€â”€â”€â”€â”€
class AdvancedFFTSVDCompressor:
    """ê³ ê¸‰ FFT+SVD í•˜ì´ë¸Œë¦¬ë“œ ì••ì¶•ê¸°"""
    
    def __init__(self, W: torch.Tensor, compression_ratio=0.1, fft_ratio=0.3):
        """
        Args:
            W: ê°€ì¤‘ì¹˜ í–‰ë ¬ [out_f, in_f]
            compression_ratio: ì „ì²´ ì••ì¶•ë¥ 
            fft_ratio: FFT ì˜ì—­ì— í• ë‹¹í•  ë¹„ìœ¨ (ë‚˜ë¨¸ì§€ëŠ” SVD)
        """
        self.out_f, self.in_f = W.shape
        self.compression_ratio = compression_ratio
        self.fft_ratio = fft_ratio
        
        print(f"    ğŸŒŠ FFT+SVD í•˜ì´ë¸Œë¦¬ë“œ: {W.shape}, ì••ì¶•ë¥ ={compression_ratio:.1%}")
        print(f"       FFTì˜ì—­={fft_ratio:.1%}, SVDì˜ì—­={1-fft_ratio:.1%}")
        
        self._apply_fft_svd_compression(W)
    
    def _apply_fft_svd_compression(self, W: torch.Tensor):
        """FFT+SVD í•˜ì´ë¸Œë¦¬ë“œ ì••ì¶• ì ìš©"""
        
        # 1ë‹¨ê³„: 2D FFT ë³€í™˜ìœ¼ë¡œ ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ë¶„ì„
        print(f"       ğŸŒŠ 2D FFT ì£¼íŒŒìˆ˜ ë¶„ì„...")
        W_fft = self._enhanced_2d_fft(W)
        
        # 2ë‹¨ê³„: ì£¼íŒŒìˆ˜ ë„ë©”ì¸ì—ì„œ ì¤‘ìš” ì„±ë¶„ ì„ íƒ
        important_freqs, freq_mask = self._select_important_frequencies(W_fft)
        
        # 3ë‹¨ê³„: FFT ì˜ì—­ê³¼ ì”ì°¨ ì˜ì—­ ë¶„ë¦¬
        fft_component, residual = self._separate_fft_residual(W, important_freqs, freq_mask)
        
        # 4ë‹¨ê³„: FFT ì••ì¶•
        self.fft_compressed = self._compress_fft_component(fft_component)
        
        # 5ë‹¨ê³„: ì”ì°¨ì— ëŒ€í•œ ê³ ê¸‰ SVD
        self.svd_compressed = self._compress_residual_svd(residual)
        
        print(f"       âœ… FFT+SVD í•˜ì´ë¸Œë¦¬ë“œ ì••ì¶• ì™„ë£Œ")
    
    def _enhanced_2d_fft(self, W: torch.Tensor) -> torch.Tensor:
        """í–¥ìƒëœ 2D FFT (ìœˆë„ìš° í•¨ìˆ˜ ì ìš©)"""
        
        # í•œ ìœˆë„ìš° í•¨ìˆ˜ ì ìš© (ìŠ¤í™íŠ¸ëŸ¼ ëˆ„ì¶œ ë°©ì§€)
        window_row = torch.hann_window(W.shape[0], device=W.device)
        window_col = torch.hann_window(W.shape[1], device=W.device)
        
        # 2D ìœˆë„ìš° ìƒì„±
        window_2d = torch.outer(window_row, window_col)
        W_windowed = W * window_2d
        
        # 2D FFT
        W_fft = torch.fft.fft2(W_windowed)
        
        return W_fft
    
    def _select_important_frequencies(self, W_fft: torch.Tensor):
        """ì¤‘ìš”í•œ ì£¼íŒŒìˆ˜ ì„±ë¶„ ì„ íƒ (ì—ë„ˆì§€ ê¸°ë°˜)"""
        
        # ì£¼íŒŒìˆ˜ë³„ ì—ë„ˆì§€ ê³„ì‚°
        energy = torch.abs(W_fft)**2
        
        # ì—ë„ˆì§€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        energy_flat = energy.flatten()
        sorted_indices = torch.argsort(energy_flat, descending=True)
        
        # ìƒìœ„ ì—ë„ˆì§€ ì„±ë¶„ ì„ íƒ
        fft_budget = int(W_fft.numel() * self.compression_ratio * self.fft_ratio)
        important_indices = sorted_indices[:fft_budget]
        
        # ë§ˆìŠ¤í¬ ìƒì„±
        freq_mask = torch.zeros_like(energy_flat, dtype=torch.bool)
        freq_mask[important_indices] = True
        freq_mask = freq_mask.reshape(W_fft.shape)
        important_freqs = torch.where(freq_mask, W_fft, torch.zeros_like(W_fft))
        return important_freqs, freq_mask
    
    def _separate_fft_residual(self, W: torch.Tensor, important_freqs: torch.Tensor, 
                             freq_mask: torch.Tensor):
        fft_component = torch.fft.ifft2(important_freqs).real
        residual = W - fft_component
        return fft_component, residual
    
    def _compress_fft_component(self, fft_component: torch.Tensor):
        """FFT ì„±ë¶„ ì••ì¶• (ì ì‘ì  ì–‘ìí™”)"""
        min_val, max_val = fft_component.min(), fft_component.max()
        dynamic_range = max_val - min_val
        if dynamic_range < 1e-6:
            num_bits = 4
        elif dynamic_range < 1e-3:
            num_bits = 6
        else:
            num_bits = 8
        num_levels = 2**num_bits
        scale = dynamic_range / (num_levels - 1)
        
        quantized = torch.round((fft_component - min_val) / scale)
        quantized = torch.clamp(quantized, 0, num_levels - 1)
        
        # ì••ì¶•ëœ í‘œí˜„ ì €ì¥
        compressed = {
            'quantized': quantized.to(torch.uint8),
            'min_val': min_val,
            'scale': scale,
            'shape': fft_component.shape
        }
        
        return compressed
    
    def _compress_residual_svd(self, residual: torch.Tensor):
        """ì”ì°¨ì— ëŒ€í•œ ê³ ê¸‰ SVD ì••ì¶•"""
        
        # SVD ì˜ˆì‚° ê³„ì‚°
        svd_ratio = 1 - self.fft_ratio
        target_rank = max(8, int(min(residual.shape) * self.compression_ratio * svd_ratio * 2))
        
        # ë¸”ë¡ë³„ SVD (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        if residual.numel() > 100000:  # í° í–‰ë ¬ì˜ ê²½ìš°
            return self._block_svd_compression(residual, target_rank)
        else:
            return self._standard_svd_compression(residual, target_rank)
    
    def _block_svd_compression(self, residual: torch.Tensor, target_rank: int):
        """ë¸”ë¡ë³„ SVD ì••ì¶•"""
        
        block_size = 256
        compressed_blocks = []
        
        for i in range(0, residual.shape[0], block_size):
            end_i = min(i + block_size, residual.shape[0])
            block = residual[i:end_i]
            
            # ê° ë¸”ë¡ì— SVD ì ìš©
            U, S, V = torch.svd(block.float())
            
            # ë­í¬ ì¡°ì •
            block_rank = min(target_rank, len(S))
            
            compressed_blocks.append({
                'U': U[:, :block_rank].to(residual.dtype),
                'S': S[:block_rank].to(residual.dtype),
                'V': V[:, :block_rank].to(residual.dtype),
                'start_row': i,
                'end_row': end_i
            })
        
        return {'type': 'block', 'blocks': compressed_blocks}
    
    def _standard_svd_compression(self, residual: torch.Tensor, target_rank: int):
        """í‘œì¤€ SVD ì••ì¶•"""
        
        U, S, V = torch.svd(residual.float())
        
        # ì ì‘ì  ë­í¬ ì„ íƒ (ì—ë„ˆì§€ ê¸°ë°˜)
        energy_cumsum = torch.cumsum(S**2, dim=0)
        total_energy = energy_cumsum[-1]
        energy_threshold = total_energy * 0.95  # 95% ì—ë„ˆì§€ ë³´ì¡´
        
        adaptive_rank = torch.sum(energy_cumsum < energy_threshold).item() + 1
        final_rank = min(target_rank, adaptive_rank, len(S))
        
        return {
            'type': 'standard',
            'U': U[:, :final_rank].to(residual.dtype),
            'S': S[:final_rank].to(residual.dtype),
            'V': V[:, :final_rank].to(residual.dtype)
        }
    
    def reconstruct(self) -> torch.Tensor:
        """ì••ì¶•ëœ ê°€ì¤‘ì¹˜ ë³µì›"""
        
        # FFT ì„±ë¶„ ë³µì›
        fft_reconstructed = self._reconstruct_fft()
        
        # SVD ì„±ë¶„ ë³µì›
        svd_reconstructed = self._reconstruct_svd()
        
        # ìµœì¢… í•©ì„±
        return fft_reconstructed + svd_reconstructed
    
    def _reconstruct_fft(self) -> torch.Tensor:
        """FFT ì„±ë¶„ ë³µì›"""
        
        comp = self.fft_compressed
        
        # ì—­ì–‘ìí™”
        dequantized = comp['quantized'].float() * comp['scale'] + comp['min_val']
        
        return dequantized.reshape(comp['shape'])
    
    def _reconstruct_svd(self) -> torch.Tensor:
        """SVD ì„±ë¶„ ë³µì›"""
        
        comp = self.svd_compressed
        
        if comp['type'] == 'block':
            # ë¸”ë¡ë³„ ë³µì›
            result = torch.zeros(self.out_f, self.in_f, dtype=comp['blocks'][0]['U'].dtype)
            
            for block in comp['blocks']:
                start_row, end_row = block['start_row'], block['end_row']
                reconstructed_block = block['U'] @ torch.diag(block['S']) @ block['V'].t()
                result[start_row:end_row] = reconstructed_block
            
            return result
        else:
            # í‘œì¤€ ë³µì›
            return comp['U'] @ torch.diag(comp['S']) @ comp['V'].t()
    
    def apply(self, x: torch.Tensor) -> torch.Tensor:
        """ì••ì¶•ëœ ì—°ì‚° ì ìš© (íš¨ìœ¨ì  êµ¬í˜„)"""
        
        # FFT ì„±ë¶„ ì ìš©
        fft_result = self._apply_fft_fast(x)
        
        # SVD ì„±ë¶„ ì ìš©
        svd_result = self._apply_svd_fast(x)
        
        return fft_result + svd_result
    
    def _apply_fft_fast(self, x: torch.Tensor) -> torch.Tensor:
        """FFT ì„±ë¶„ ë¹ ë¥¸ ì ìš©"""
        # ì‹¤ì œë¡œëŠ” ë³µì› ì—†ì´ ì••ì¶•ëœ í˜•íƒœë¡œ ì§ì ‘ ê³„ì‚° ê°€ëŠ¥
        fft_weight = self._reconstruct_fft()
        return F.linear(x, fft_weight, None)
    
    def _apply_svd_fast(self, x: torch.Tensor) -> torch.Tensor:
        """SVD ì„±ë¶„ ë¹ ë¥¸ ì ìš©"""
        comp = self.svd_compressed
        
        if comp['type'] == 'block':
            # ë¸”ë¡ë³„ ì ìš© (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
            results = []
            for block in comp['blocks']:
                start_row, end_row = block['start_row'], block['end_row']
                block_result = x @ block['V'] @ torch.diag(block['S']) @ block['U'].t()
                results.append(block_result)
            return torch.cat(results, dim=-1)
        else:
            # í‘œì¤€ SVD ì ìš©
            return x @ comp['V'] @ torch.diag(comp['S']) @ comp['U'].t()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Enhanced RealityStone Linear Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€
class EnhancedRealityStoneLinear(nn.Module):
    """í–¥ìƒëœ RealityStone Linear ë ˆì´ì–´"""
    
    def __init__(self, lin, compression_ratio=0.1, compression_type='hybrid'):
        super().__init__()
        
        if hasattr(lin, 'weight'):
            W = lin.weight.data.clone()
            
            # Conv1D ì²˜ë¦¬
            if hasattr(lin, 'nf'):  # Conv1D
                self.in_features = W.shape[1]
                self.out_features = W.shape[0]
                W = W.t()  # [in, out] for compressor
                print(f"ğŸŒ Conv1D ê³ ê¸‰ì••ì¶•: in={self.in_features}, out={self.out_features}")
            else:  # nn.Linear
                self.in_features = lin.in_features
                self.out_features = lin.out_features
                print(f"ğŸŒ Linear ê³ ê¸‰ì••ì¶•: in={self.in_features}, out={self.out_features}")
            
            # ì••ì¶• íƒ€ì…ë³„ ì••ì¶•ê¸° ì„ íƒ
            if compression_type == 'hybrid':
                # FFT+SVD+ë¦¬ë§Œ í•˜ì´ë¸Œë¦¬ë“œ
                self.compressor = self._create_hybrid_compressor(W, compression_ratio)
            elif compression_type == 'riemann':
                # ê°„ì†Œí™” ë¦¬ë§Œ ì••ì¶•
                self.compressor = SimplifiedRiemannCompressor(
                    W, compression_ratio, use_rs=True
                )
            elif compression_type == 'fft_svd':
                # FFT+SVD ì••ì¶•
                self.compressor = AdvancedFFTSVDCompressor(W, compression_ratio)
            else:
                # ê¸°ë³¸ ê°„ì†Œí™” ë¦¬ë§Œ ì••ì¶•
                self.compressor = SimplifiedRiemannCompressor(
                    W, compression_ratio, use_rs=True
                )
            
            # ë°”ì´ì–´ìŠ¤ ì²˜ë¦¬
            if hasattr(lin, 'bias') and lin.bias is not None:
                self.bias = nn.Parameter(lin.bias.data.clone())
            else:
                self.bias = None
        else:
            raise ValueError("Input layer must have weight attribute")
    
    def _create_hybrid_compressor(self, W: torch.Tensor, compression_ratio: float):
        """í•˜ì´ë¸Œë¦¬ë“œ ì••ì¶•ê¸° ìƒì„± (ì†ë„ ìµœì í™”)"""
        
        # ì†ë„ ìµœì í™”ë¥¼ ìœ„í•´ ê°„ë‹¨í•œ SVD ì••ì¶• ì‚¬ìš©
        total_params = W.numel()
        
        print(f"      ğŸ“Š ìµœì í™” ì••ì¶•: ê³ ì† SVD ({total_params:,} íŒŒë¼ë¯¸í„°)")
        return FastSVDCompressor(W, compression_ratio)

    def forward(self, x):
        out = self.compressor.apply(x)
        if self.bias is not None:
            out = out + self.bias
        return out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Enhanced Reality Stone Block â”€â”€â”€â”€â”€â”€â”€â”€â”€
class EnhancedRealityStoneBlock(nn.Module):
    def __init__(self, block, compression_ratio=0.1, layer_idx=0, total_layers=12, 
                 adaptive_compression=True):
        super().__init__()
        self.ln1 = block.ln_1
        self.ln2 = block.ln_2
        attn, mlp = block.attn, block.mlp

        # ì ì‘ì  ì••ì¶•ë¥  ë° ë°©ë²• ì„ íƒ
        if adaptive_compression:
            layer_ratio, compression_types = self._adaptive_compression_strategy(
                layer_idx, total_layers, compression_ratio
            )
        else:
            layer_ratio = compression_ratio
            compression_types = ['hybrid'] * 4

        print(f"ğŸŒ ë ˆì´ì–´ {layer_idx}: ê³ ê¸‰ì••ì¶•ë¥  {layer_ratio:.1%}")
        print(f"   ì••ì¶•ë°©ë²•: attn={compression_types[0]}, proj={compression_types[1]}")
        print(f"            fc={compression_types[2]}, mlp_proj={compression_types[3]}")

        # ê° ì„œë¸Œë ˆì´ì–´ì— ìµœì í™”ëœ ì••ì¶• ì ìš©
        attn.c_attn = EnhancedRealityStoneLinear(attn.c_attn, layer_ratio, compression_types[0])
        attn.c_proj = EnhancedRealityStoneLinear(attn.c_proj, layer_ratio, compression_types[1])
        mlp.c_fc   = EnhancedRealityStoneLinear(mlp.c_fc,   layer_ratio, compression_types[2])
        mlp.c_proj = EnhancedRealityStoneLinear(mlp.c_proj, layer_ratio, compression_types[3])
        
        self.attn, self.mlp = attn, mlp

    def _adaptive_compression_strategy(self, layer_idx: int, total_layers: int, 
                                     base_ratio: float):
        """ì ì‘ì  ì••ì¶• ì „ëµ (ì†ë„ ìµœì í™”)"""
        
        normalized_idx = layer_idx / total_layers
        
        # ì†ë„ ìµœì í™”ë¥¼ ìœ„í•´ ëŒ€ë¶€ë¶„ fast SVD ì‚¬ìš©
        if normalized_idx < 0.3:  # ì´ˆê¸°ì¸µ (0-30%)
            layer_ratio = base_ratio * 1.2  # ë³´ìˆ˜ì 
            compression_types = ['hybrid', 'hybrid', 'hybrid', 'hybrid']  # ëª¨ë‘ fast SVD
        elif normalized_idx < 0.7:  # ì¤‘ê°„ì¸µ (30-70%)
            layer_ratio = base_ratio * 0.8  # ì ê·¹ì 
            compression_types = ['hybrid', 'hybrid', 'hybrid', 'hybrid']  # ëª¨ë‘ fast SVD
        else:  # ë§ë‹¨ì¸µ (70-100%)
            layer_ratio = base_ratio * 1.1  # ë³´ìˆ˜ì 
            compression_types = ['hybrid', 'hybrid', 'hybrid', 'hybrid']  # ëª¨ë‘ fast SVD
        
        return layer_ratio, compression_types

    def forward(self, x, **kwargs):
        h = self.ln1(x)
        attn_outputs = self.attn(h, **kwargs)
        a = attn_outputs[0]
        x = x + a
        h2 = self.ln2(x)
        m = self.mlp(h2)
        output = x + m
        
        if len(attn_outputs) > 1:
            return (output,) + attn_outputs[1:]
        else:
            return (output,)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Advanced Reality Stone Compression Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€
def apply_advanced_reality_stone_compression(model, compression_ratio=0.12, 
                                           compression_strategy='adaptive'):
    """ê³ ê¸‰ RealityStone ì••ì¶• íŒŒì´í”„ë¼ì¸"""
    
    total = sum(p.numel() for p in model.parameters())
    total_layers = len(model.transformer.h)
    
    print(f"Before: {total:,} params")
    print(f"ğŸŒ ê³ ê¸‰ RealityStone ì••ì¶•: ëª©í‘œ={compression_ratio:.1%}")
    print(f"ğŸš€ ì „ëµ: {compression_strategy}")
    print(f"ğŸ’ í™œìš© ê¸°ìˆ : RealityStone + FFT + SVD + ë¦¬ë§Œê¸°í•˜í•™")
    
    # ì••ì¶• ì „ëµë³„ ë ˆì´ì–´ ì„ íƒ
    if compression_strategy == 'adaptive':
        # ì ì‘ì : ëª¨ë“  ë ˆì´ì–´ ì••ì¶•í•˜ë˜ ê°•ë„ ì¡°ì ˆ
        compress_layers = list(range(total_layers))
        adaptive = True
    elif compression_strategy == 'conservative':
        # ë³´ìˆ˜ì : ê°€ì¥ìë¦¬ ë³´ì¡´
        compress_layers = list(range(2, total_layers-2))
        adaptive = False
    elif compression_strategy == 'aggressive':
        # ì ê·¹ì : ì²«ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ë§Œ ë³´ì¡´
        compress_layers = list(range(1, total_layers-1))
        adaptive = True
    else:  # balanced
        # ê· í˜•ì : ì¼ë¶€ ê°€ì¥ìë¦¬ ë³´ì¡´
        compress_layers = list(range(1, total_layers-1))
        adaptive = True
    
    print(f"   ì••ì¶• ëŒ€ìƒ: {len(compress_layers)}/{total_layers} ë ˆì´ì–´ (ì „ëµ: {compression_strategy})")
    
    # ì••ì¶• ì§„í–‰
    compressed_layers = 0
    for i in tqdm(compress_layers, desc="ğŸŒ ê³ ê¸‰ ì••ì¶•"):
        if i < len(model.transformer.h):
            try:
                model.transformer.h[i] = EnhancedRealityStoneBlock(
                    model.transformer.h[i], compression_ratio, i, total_layers, adaptive
                )
                compressed_layers += 1
            except Exception as e:
                print(f"   âš ï¸ ë ˆì´ì–´ {i} ì••ì¶• ì‹¤íŒ¨: {e}")
                continue
    
    total2 = sum(p.numel() for p in model.parameters())
    actual_compression = total2 / total
    
    print(f"After:  {total2:,} params â†’ {1/actual_compression:.2f}Ã— ì••ì¶•")
    print(f"ğŸŒ ì‹¤ì œ ì••ì¶•ë¥ : {(1-actual_compression)*100:.1f}%")
    print(f"âœ… ì„±ê³µì ìœ¼ë¡œ ì••ì¶•ëœ ë ˆì´ì–´: {compressed_layers}/{len(compress_layers)}")
    
    # ì••ì¶• í’ˆì§ˆ í‰ê°€
    quality_score = _evaluate_compression_quality(actual_compression, compression_ratio)
    print(f"ğŸ“Š ì••ì¶• í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f}/5.0")
    
    return model

def _evaluate_compression_quality(actual_ratio: float, target_ratio: float) -> float:
    """ì••ì¶• í’ˆì§ˆ í‰ê°€"""
    
    score = 5.0
    
    # ëª©í‘œ ë‹¬ì„±ë„
    target_achievement = min(1.0, (1-actual_ratio) / (1-target_ratio))
    score *= target_achievement
    
    # ì••ì¶•ë¥  ì ì ˆì„±
    if actual_ratio < 0.3:  # 70%+ ì••ì¶•
        score *= 1.1  # ë³´ë„ˆìŠ¤
    elif actual_ratio > 0.7:  # 30% ë¯¸ë§Œ ì••ì¶•
        score *= 0.7  # í˜ë„í‹°
    
    return min(5.0, score)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Keep existing quality evaluation and fine-tuning functions â”€â”€â”€â”€â”€â”€â”€â”€â”€

def advanced_quality_evaluation(generated_text, prompt):
    """ì—„ê²©í•œ í•œêµ­ì–´ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ (ê°œì„ )"""
    
    generated_only = generated_text[len(prompt):].strip()
    if len(generated_only) < 2:
        return 0.0
    
    score = 0.0
    max_score = 7.0  # ë” ì—„ê²©í•œ í‰ê°€ë¥¼ ìœ„í•´ 7ì  ë§Œì 
    
    # 1. ë°˜ë³µ íŒ¨í„´ ê²€ì‚¬ (0-2ì ) - ê°€ì¥ ì¤‘ìš”!
    repetition_penalty = calculate_repetition_penalty(generated_only)
    repetition_score = max(0, 2.0 - repetition_penalty * 4)  # ë°˜ë³µì— ëŒ€í•œ ê°•í•œ í˜ë„í‹°
    score += repetition_score
    
    # 2. í•œêµ­ì–´ ë¬¸ë²• êµ¬ì¡° (0-2ì )
    grammar_score = evaluate_korean_grammar(generated_only)
    score += grammar_score
    
    # 3. ì˜ë¯¸ ì—°ê´€ì„± (0-1.5ì )
    semantic_score = calculate_semantic_relevance(prompt, generated_only)
    score += semantic_score * 1.5
    
    # 4. í…ìŠ¤íŠ¸ ìì—°ìŠ¤ëŸ¬ì›€ (0-1ì )
    naturalness_score = evaluate_naturalness(generated_only)
    score += naturalness_score
    
    # 5. íŠ¹ìˆ˜ë¬¸ì/ì˜¤ë¥˜ íŒ¨í„´ í˜ë„í‹° (0-0.5ì )
    error_penalty = calculate_error_penalty(generated_only)
    score += max(0, 0.5 - error_penalty)
    
    return min(score / max_score * 3.0, 3.0)  # 0-3 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜

def evaluate_korean_grammar(text):
    """í•œêµ­ì–´ ë¬¸ë²• êµ¬ì¡° í‰ê°€"""
    score = 0.0
    
    # ì ì ˆí•œ ì–´ë¯¸ ì‚¬ìš©
    korean_endings = ['ë‹¤', 'ìš”', 'ë‹ˆë‹¤', 'í•´ìš”', 'ì–´ìš”', 'ì•„ìš”', 'ë„¤ìš”', 'ì£ ', 'ìŠµë‹ˆë‹¤', 'ê² ìŠµë‹ˆë‹¤']
    has_proper_ending = any(text.endswith(ending) for ending in korean_endings)
    if has_proper_ending:
        score += 1.0
    elif any(ending in text for ending in korean_endings):
        score += 0.5
    
    # ë¬¸ì¥ êµ¬ì¡°
    sentences = [s.strip() for s in re.split('[.!?]', text) if s.strip()]
    if sentences:
        # ì™„ì „í•œ ë¬¸ì¥ì´ ìˆëŠ”ì§€
        complete_sentences = sum(1 for s in sentences if len(s.split()) >= 2)
        if complete_sentences > 0:
            score += 0.8
        else:
            score += 0.3
    
    # ì¡°ì‚¬/ì–´ë¯¸ ì ì ˆì„±
    particles = ['ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼', 'ì˜']
    has_particles = any(p in text for p in particles)
    if has_particles:
        score += 0.2
    
    return min(score, 2.0)

def evaluate_naturalness(text):
    """í…ìŠ¤íŠ¸ ìì—°ìŠ¤ëŸ¬ì›€ í‰ê°€"""
    score = 1.0
    
    # ì´ìƒí•œ íŒ¨í„´ë“¤ ì²´í¬
    weird_patterns = [
        r'[.]{3,}',           # ê³¼ë„í•œ ì 
        r'[!]{2,}',           # ê³¼ë„í•œ ëŠë‚Œí‘œ  
        r'[?]{2,}',           # ê³¼ë„í•œ ë¬¼ìŒí‘œ
        r'[/]{2,}',           # ìŠ¬ë˜ì‹œ ë°˜ë³µ
        r'[~]{3,}',           # ë¬¼ê²°í‘œ ë°˜ë³µ
        r'[:]{2,}',           # ì½œë¡  ë°˜ë³µ
        r'[0-9]{5,}',         # ê¸´ ìˆ«ì ë‚˜ì—´
    ]
    
    for pattern in weird_patterns:
        if re.search(pattern, text):
            score -= 0.3
    
    # ë‹¨ì–´ ê¸¸ì´ ì²´í¬
    words = text.split()
    if words:
        avg_word_length = sum(len(w) for w in words) / len(words)
        if avg_word_length > 10:  # ë„ˆë¬´ ê¸´ í‰ê·  ë‹¨ì–´
            score -= 0.3
    
    return max(0, score)

def calculate_error_penalty(text):
    """ì˜¤ë¥˜ íŒ¨í„´ í˜ë„í‹° ê³„ì‚°"""
    penalty = 0.0
    
    # ì‹¬ê°í•œ ì˜¤ë¥˜ íŒ¨í„´ë“¤
    severe_errors = [
        r'[ê°€-í£]+[/]+[ê°€-í£]+',    # í•œê¸€ ì‚¬ì´ ìŠ¬ë˜ì‹œ
        r'[:-]+[/]+',               # íŠ¹ìˆ˜ë¬¸ì ì¡°í•©
        r'[&+-]{2,}',               # ì—°ì‚°ì ë°˜ë³µ
        r'[()\[\]]{3,}',            # ê´„í˜¸ ë°˜ë³µ
    ]
    
    for pattern in severe_errors:
        matches = len(re.findall(pattern, text))
        penalty += matches * 0.5
    
    return penalty

def calculate_repetition_penalty(text):
    """ë°˜ë³µ íŒ¨í„´ í˜ë„í‹° ê³„ì‚°"""
    
    # ë¬¸ì ë°˜ë³µ ê²€ì‚¬
    char_repeats = len(re.findall(r'(.)\1{2,}', text))  # 3íšŒ ì´ìƒ ë°˜ë³µ
    
    # ë‹¨ì–´ ë°˜ë³µ ê²€ì‚¬
    words = text.split()
    if len(words) > 1:
        word_counts = Counter(words)
        repeated_words = sum(1 for count in word_counts.values() if count > 2)
    else:
        repeated_words = 0
    
    # êµ¬ë‘ì  ë°˜ë³µ ê²€ì‚¬
    punct_repeats = len(re.findall(r'[.!?]{3,}|[~]{2,}|[/]{2,}', text))
    
    # ì´ í˜ë„í‹° (0-1 ë²”ìœ„)
    total_penalty = min(1.0, (char_repeats + repeated_words + punct_repeats * 2) / 10)
    
    return total_penalty

def has_proper_structure(text):
    """ì ì ˆí•œ ë¬¸ë²• êµ¬ì¡° í™•ì¸"""
    korean_endings = ['ë‹¤', 'ìš”', 'ë‹ˆë‹¤', 'í•´ìš”', 'ì–´ìš”', 'ì•„ìš”', 'ë„¤ìš”', 'ì£ ']
    has_ending = any(text.endswith(ending) for ending in korean_endings)
    has_complete_sentence = '.' in text or '!' in text or '?' in text
    return has_ending and not text.count('.') > 3

def has_basic_structure(text):
    """ê¸°ë³¸ì ì¸ êµ¬ì¡° í™•ì¸"""
    return len(text.split()) >= 2 and not text.count('/') > len(text) * 0.3

def calculate_semantic_relevance(prompt, generated):
    """ì˜ë¯¸ì  ì—°ê´€ì„± ê³„ì‚° (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
    
    keyword_mapping = {
        'ì•ˆë…•': ['ì•ˆë…•', 'ë°˜ê°‘', 'ì¢‹', 'ê°ì‚¬'],
        'ë‚ ì”¨': ['ë‚ ì”¨', 'ë§‘', 'íë¦¼', 'ë¹„', 'ëˆˆ', 'ë”°ëœ»', 'ì¶¥', 'ì¢‹'],
        'ìˆ˜ë„': ['ì„œìš¸', 'ë„ì‹œ', 'í•œêµ­', 'ìˆ˜ë„'],
        'ì¸ê³µì§€ëŠ¥': ['AI', 'ê¸°ìˆ ', 'ì»´í“¨í„°', 'ë¡œë´‡', 'ì§€ëŠ¥', 'í•™ìŠµ'],
        'ìŒì‹': ['ìŒì‹', 'ë§›', 'ë¨¹', 'ìš”ë¦¬', 'ì‹ì‚¬'],
    }
    
    relevance = 0.0
    for key, keywords in keyword_mapping.items():
        if key in prompt:
            matches = sum(1 for kw in keywords if kw in generated)
            relevance = max(relevance, min(1.0, matches / 2))
    
    return relevance

def calculate_diversity(text):
    """í…ìŠ¤íŠ¸ ë‹¤ì–‘ì„± ê³„ì‚°"""
    
    if len(text) < 5:
        return 0.0
    
    # ë¬¸ì ë‹¤ì–‘ì„±
    unique_chars = len(set(text.replace(' ', '')))
    char_diversity = min(1.0, unique_chars / 10)
    
    # ë‹¨ì–´ ë‹¤ì–‘ì„±
    words = text.split()
    if len(words) > 1:
        unique_words = len(set(words))
        word_diversity = unique_words / len(words)
    else:
        word_diversity = 0.5
    
    return (char_diversity + word_diversity) / 2

def generate_with_anti_repetition(model, tokenizer, prompt, max_length=25):
    """ê·¹í•œ ë°˜ë³µ ë°©ì§€ ìƒì„± (í•œêµ­ì–´ ì´ˆíŠ¹í™”)"""
    
    inputs = tokenizer(prompt, return_tensors="pt")
    
    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_length=max_length,
            do_sample=True,
            temperature=0.6,          # ë³´ìˆ˜ì  ì˜¨ë„
            top_p=0.8,               # ì œí•œì  í™•ë¥  
            top_k=30,                # ì œí•œì  ì„ íƒ
            repetition_penalty=1.8,   # ë°˜ë³µ í˜ë„í‹° ê·¹ëŒ€í™”
            no_repeat_ngram_size=5,   # n-gram í¬ê¸° í™•ëŒ€
            pad_token_id=tokenizer.eos_token_id,
            # beam search ê´€ë ¨ ì„¤ì •ë“¤ ì œê±° (ì¶©ëŒ í•´ê²°)
            min_length=len(inputs.input_ids[0]) + 2,  # ìµœì†Œ ê¸¸ì´ ë³´ì¥
        )
    
    return tokenizer.decode(output[0], skip_special_tokens=True)

def test_multiple_prompts_advanced(model, tokenizer, model_type="ì›ë³¸"):
    """ê°œì„ ëœ ë‹¤ì¤‘ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"""
    
    test_prompts = [
        "ì•ˆë…•í•˜ì„¸ìš”",
        "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ”", 
        "í•œêµ­ì˜ ìˆ˜ë„ëŠ”",
        "ì¸ê³µì§€ëŠ¥ì´ë€",
        "ë§›ìˆëŠ” ìŒì‹ì€"
    ]
    
    print(f"\n=== {model_type} ëª¨ë¸ ê³ ê¸‰ í…ŒìŠ¤íŠ¸ ===")
    results = []
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\n[{i}/5] '{prompt}'")
        
        try:
            t0 = time.time()
            
            # ë°˜ë³µ ë°©ì§€ ìƒì„± ì‚¬ìš©
            generated_text = generate_with_anti_repetition(model, tokenizer, prompt, max_length=25)
            
            elapsed = time.time() - t0
            
            print(f"  ìƒì„±: {generated_text}")
            print(f"  ì‹œê°„: {elapsed:.3f}ì´ˆ")
            
            # ê³ ê¸‰ í’ˆì§ˆ í‰ê°€
            quality_score = advanced_quality_evaluation(generated_text, prompt)
            
            print(f"  í’ˆì§ˆ: {quality_score:.2f}/3.0")
            
            results.append({
                'prompt': prompt,
                'generated': generated_text,
                'time': elapsed,
                'quality': quality_score
            })
            
        except Exception as e:
            print(f"  âŒ ì—ëŸ¬: {e}")
            results.append({
                'prompt': prompt,
                'generated': f"ERROR: {e}",
                'time': 0,
                'quality': 0
            })
    
    # í†µê³„
    avg_time = sum(r['time'] for r in results) / len(results) if results else 0
    avg_quality = sum(r['quality'] for r in results) / len(results) if results else 0
    
    print(f"\nğŸ“Š {model_type} ê³ ê¸‰ í†µê³„:")
    print(f"  í‰ê·  ì‹œê°„: {avg_time:.3f}ì´ˆ")
    print(f"  í‰ê·  í’ˆì§ˆ: {avg_quality:.2f}/3.0")
    
    return results

def main():
    model_name = "skt/kogpt2-base-v2"
    print("ğŸŒ í–¥ìƒëœ RealityStone FFT+SVD+ë¦¬ë§Œêµ¬ë©´ ì••ì¶• + íŒŒì¸íŠœë‹ íŒŒì´í”„ë¼ì¸")
    print("=" * 90)
    print("ğŸš€ Reality Stone + ê³ ê¸‰ FFT+SVD + ë¦¬ë§Œê¸°í•˜í•™ + Knowledge Distillation")
    print("ğŸ’ ë‹¤ì¤‘ ì••ì¶• ê¸°ë²•: í•˜ì´ë¸Œë¦¬ë“œ ì ì‘ì  ì••ì¶•")
    print("Loading modelâ€¦")
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    teacher_model = AutoModelForCausalLM.from_pretrained(model_name)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    # 1ë‹¨ê³„: ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("\n" + "="*90)
    print("ğŸ“Š ì›ë³¸ ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    original_results = test_multiple_prompts_advanced(teacher_model, tokenizer, "ì›ë³¸")

    # 2ë‹¨ê³„: í–¥ìƒëœ RealityStone ì••ì¶• ì ìš© (ë‹¤ì¤‘ ì „ëµ ë¹„êµ)
    print("\n" + "="*90)
    print("ğŸŒ í–¥ìƒëœ RealityStone ë‹¤ì¤‘ ì••ì¶• ê¸°ë²• ì ìš©")
    
    # í•™ìƒ ëª¨ë¸ë“¤ ìƒì„± (ë‹¤ì–‘í•œ ì „ëµ)
    compression_strategies = [
        ('adaptive', 0.12, "ì ì‘ì  í•˜ì´ë¸Œë¦¬ë“œ"),
        ('aggressive', 0.10, "ì ê·¹ì  ì••ì¶•"),
        ('conservative', 0.15, "ë³´ìˆ˜ì  ì••ì¶•")
    ]
    
    best_student = None
    best_score = -1
    best_strategy = None
    
    for strategy, ratio, description in compression_strategies:
        print(f"\nğŸ”¬ ì „ëµ í…ŒìŠ¤íŠ¸: {description} (ì••ì¶•ë¥  {ratio:.1%})")
        
        student_model = copy.deepcopy(teacher_model)
        
        try:
            # ê³ ê¸‰ ì••ì¶• ì ìš©
            student_model = apply_advanced_reality_stone_compression(
                student_model, 
                compression_ratio=ratio,
                compression_strategy=strategy
            )
            
            # ì••ì¶• ì§í›„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            print(f"\nğŸ“Š {description} ì••ì¶• ì§í›„ í…ŒìŠ¤íŠ¸")
            test_results = test_multiple_prompts_advanced(
                student_model, tokenizer, f"{description} (FT ì „)"
            )
            
            # ì••ì¶• íš¨ê³¼ í‰ê°€
            avg_quality = sum(r['quality'] for r in test_results) / len(test_results)
            compression_score = _evaluate_compression_strategy(student_model, teacher_model, avg_quality)
            
            print(f"   ğŸ† ì „ëµ ì ìˆ˜: {compression_score:.2f}/10.0")
            
            if compression_score > best_score:
                best_score = compression_score
                best_student = student_model
                best_strategy = description
                
        except Exception as e:
            print(f"   âŒ {description} ì „ëµ ì‹¤íŒ¨: {e}")
            continue
    
    if best_student is None:
        print("âŒ ëª¨ë“  ì••ì¶• ì „ëµ ì‹¤íŒ¨")
        return
    
    print(f"\nğŸ† ìµœì  ì „ëµ ì„ íƒ: {best_strategy} (ì ìˆ˜: {best_score:.2f})")
    student_model = best_student
    
    # 3ë‹¨ê³„: ì••ì¶• ì§í›„ ìµœì¢… í…ŒìŠ¤íŠ¸
    print("\n" + "="*90)
    print("ğŸ“Š ìµœì  ì••ì¶• ëª¨ë¸ íŒŒì¸íŠœë‹ ì „ ì„±ëŠ¥")
    before_ft_results = test_multiple_prompts_advanced(
        student_model, tokenizer, f"{best_strategy} (íŒŒì¸íŠœë‹ ì „)"
    )
    
    # 4ë‹¨ê³„: ê³ ê¸‰ Knowledge Distillation íŒŒì¸íŠœë‹
    print("\n" + "="*90)
    print("ğŸ§  ê³ ê¸‰ Knowledge Distillation íŒŒì¸íŠœë‹ ì‹œì‘")
    
    student_model = enhanced_knowledge_distillation_fine_tune(
        teacher_model, student_model, tokenizer,
        total_steps=250,    # ë” ë§ì€ ìŠ¤í…
        base_lr=1.5e-5,     # ë” ì •êµí•œ í•™ìŠµë¥ 
        temperature=3.5,    # ìµœì í™”ëœ ì˜¨ë„
        use_advanced_kd=True  # ê³ ê¸‰ KD ê¸°ë²•
    )
    
    # 5ë‹¨ê³„: íŒŒì¸íŠœë‹ í›„ ìµœì¢… í…ŒìŠ¤íŠ¸
    print("\n" + "="*90)
    print("ğŸ“Š íŒŒì¸íŠœë‹ í›„ ìµœì¢… ì„±ëŠ¥ í‰ê°€")
    after_ft_results = test_multiple_prompts_advanced(
        student_model, tokenizer, f"{best_strategy} (íŒŒì¸íŠœë‹ í›„)"
    )
    
    # 6ë‹¨ê³„: ì¢…í•© ì„±ëŠ¥ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí¬
    print("\n" + "="*90)
    print("ğŸ† í–¥ìƒëœ RealityStone ì••ì¶• + íŒŒì¸íŠœë‹ ìµœì¢… ë¶„ì„")
    print("="*90)
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    orig_time = sum(r['time'] for r in original_results) / len(original_results)
    orig_quality = sum(r['quality'] for r in original_results) / len(original_results)
    
    before_ft_time = sum(r['time'] for r in before_ft_results) / len(before_ft_results)
    before_ft_quality = sum(r['quality'] for r in before_ft_results) / len(before_ft_results)
    
    after_ft_time = sum(r['time'] for r in after_ft_results) / len(after_ft_results)
    after_ft_quality = sum(r['quality'] for r in after_ft_results) / len(after_ft_results)
    
    # ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸
    print(f"ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë¦¬í¬íŠ¸:")
    print(f"   ì›ë³¸ ëª¨ë¸:           ì‹œê°„ {orig_time:.3f}ì´ˆ, í’ˆì§ˆ {orig_quality:.2f}/3.0")
    print(f"   ì••ì¶• í›„ (FT ì „):     ì‹œê°„ {before_ft_time:.3f}ì´ˆ, í’ˆì§ˆ {before_ft_quality:.2f}/3.0")
    print(f"   ì••ì¶•+FT í›„:         ì‹œê°„ {after_ft_time:.3f}ì´ˆ, í’ˆì§ˆ {after_ft_quality:.2f}/3.0")
    
    print(f"\nğŸ“ˆ ê°œì„  íš¨ê³¼ ë¶„ì„:")
    quality_improvement = after_ft_quality - before_ft_quality
    quality_retention = after_ft_quality / orig_quality
    speed_improvement = orig_time / after_ft_time if after_ft_time > 0 else 1
    
    print(f"   íŒŒì¸íŠœë‹ í’ˆì§ˆ ê°œì„ :  {quality_improvement:+.2f}ì  ({(quality_improvement/before_ft_quality)*100:+.1f}%)")
    print(f"   ì›ë³¸ ëŒ€ë¹„ í’ˆì§ˆ ìœ ì§€: {quality_retention*100:.1f}%")
    print(f"   ì²˜ë¦¬ ì†ë„ í–¥ìƒ:     {speed_improvement:.2f}Ã— ë¹¨ë¼ì§")
    
    # ì••ì¶• í†µê³„
    teacher_params = sum(p.numel() for p in teacher_model.parameters())
    student_params = sum(p.numel() for p in student_model.parameters())
    compression_ratio = student_params / teacher_params
    memory_saved = (1 - compression_ratio) * 100
    
    print(f"\nğŸ’¾ ì••ì¶• ì„±ê³¼:")
    print(f"   íŒŒë¼ë¯¸í„° ìˆ˜:        {teacher_params:,} â†’ {student_params:,}")
    print(f"   ì••ì¶• ë¹„ìœ¨:         {compression_ratio:.3f} ({1/compression_ratio:.1f}Ã— ì••ì¶•)")
    print(f"   ë©”ëª¨ë¦¬ ì ˆì•½:       {memory_saved:.1f}%")
    
    # ì „ì²´ ì„±ê³¼ í‰ê°€
    overall_score = _calculate_overall_performance_score(
        quality_retention, speed_improvement, compression_ratio, quality_improvement
    )
    
    print(f"\nğŸ¯ ì¢…í•© ì„±ê³¼ í‰ê°€:")
    print(f"   ì „ì²´ ì ìˆ˜:         {overall_score:.1f}/100")
    print(f"   ì‚¬ìš© ê¸°ìˆ :         {best_strategy}")
    print(f"   ì••ì¶• ë¼ì´ë¸ŒëŸ¬ë¦¬:   {'RealityStone + ' if RS_AVAILABLE else ''}FFT+SVD+ë¦¬ë§Œê¸°í•˜í•™")
    
    # ì„±ê³µ íŒì • ë° ë“±ê¸‰
    if overall_score >= 85:
        grade = "ğŸ† ëŒ€ì„±ê³µ (Sê¸‰)"
        message = "ëª¨ë“  ì§€í‘œì—ì„œ íƒì›”í•œ ì„±ëŠ¥!"
    elif overall_score >= 75:
        grade = "ğŸ¥‡ ì„±ê³µ (Aê¸‰)"
        message = "ëŒ€ë¶€ë¶„ ì§€í‘œì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥!"
    elif overall_score >= 65:
        grade = "ğŸ¥ˆ ì–‘í˜¸ (Bê¸‰)"
        message = "ìƒë‹¹í•œ ê°œì„  íš¨ê³¼ í™•ì¸!"
    elif overall_score >= 55:
        grade = "ğŸ¥‰ ë³´í†µ (Cê¸‰)"
        message = "ì¼ë¶€ ê°œì„  íš¨ê³¼ ìˆìŒ"
    else:
        grade = "ğŸ”§ ê°œì„  í•„ìš” (Dê¸‰)"
        message = "ì¶”ê°€ ìµœì í™” í•„ìš”"
    
    print(f"\n{grade}: {message}")
    
    # ì„¸ë¶€ ê¶Œì¥ì‚¬í•­
    if quality_retention < 0.8:
        print(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: ì••ì¶•ë¥ ì„ ì¤„ì´ê±°ë‚˜ íŒŒì¸íŠœë‹ ê°•í™”")
    if speed_improvement < 1.5:
        print(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: ë” ì ê·¹ì ì¸ ì••ì¶• ì „ëµ ê³ ë ¤")
    if quality_improvement < 0.1:
        print(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: íŒŒì¸íŠœë‹ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •")
    
    print(f"\nğŸŒŸ ìµœì¢… ê²°ë¡ :")
    print(f"   í–¥ìƒëœ RealityStone ì••ì¶• íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ")
    print(f"   {memory_saved:.0f}% ë©”ëª¨ë¦¬ ì ˆì•½ê³¼ {speed_improvement:.1f}Ã— ì†ë„ í–¥ìƒì„ ë‹¬ì„±í•˜ë©´ì„œ")
    print(f"   ì›ë³¸ í’ˆì§ˆì˜ {quality_retention*100:.0f}%ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤!")

def _evaluate_compression_strategy(student_model, teacher_model, avg_quality):
    """ì••ì¶• ì „ëµ í‰ê°€"""
    
    teacher_params = sum(p.numel() for p in teacher_model.parameters())
    student_params = sum(p.numel() for p in student_model.parameters())
    
    compression_ratio = student_params / teacher_params
    memory_score = min(10, (1 - compression_ratio) * 20)  # ì••ì¶•ë¥  ì ìˆ˜
    quality_score = min(10, avg_quality * 3.33)           # í’ˆì§ˆ ì ìˆ˜
    
    return (memory_score + quality_score) / 2

def _calculate_overall_performance_score(quality_retention, speed_improvement, 
                                       compression_ratio, quality_improvement):
    """ì „ì²´ ì„±ê³¼ ì ìˆ˜ ê³„ì‚°"""
    
    # ê° ì§€í‘œë³„ ì ìˆ˜ (0-25ì )
    quality_score = min(25, quality_retention * 30)
    speed_score = min(25, (speed_improvement - 1) * 12.5)
    compression_score = min(25, (1 - compression_ratio) * 40)
    improvement_score = min(25, quality_improvement * 25)
    
    return quality_score + speed_score + compression_score + improvement_score

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Knowledge Distillation for Riemann Compression â”€â”€â”€â”€â”€â”€â”€â”€â”€
def knowledge_distillation_loss(student_logits, teacher_logits, temperature=3.0):
    """í•œêµ­ì–´ íŠ¹í™” ì§€ì‹ ì¦ë¥˜ ì†ì‹¤ í•¨ìˆ˜ (ê°œì„ )"""
    
    # 1. ê¸°ë³¸ KL divergence (ë” ì •êµí•œ ì˜¨ë„ ìŠ¤ì¼€ì¤„ë§)
    teacher_probs = F.softmax(teacher_logits / temperature, dim=-1)
    student_log_probs = F.log_softmax(student_logits / temperature, dim=-1)
    
    kl_loss = F.kl_div(student_log_probs, teacher_probs, reduction='batchmean')
    
    # 2. í•œêµ­ì–´ í† í° ê°€ì¤‘ì¹˜ ë¶€ì—¬ (ë†’ì€ í™•ë¥  í† í°ì— ë” ì§‘ì¤‘)
    with torch.no_grad():
        # ë†’ì€ í™•ë¥  í† í°ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
        confidence_weights = torch.max(teacher_probs, dim=-1)[0]
        confidence_weights = confidence_weights.unsqueeze(-1)
    
    # ê°€ì¤‘ KL divergence
    weighted_kl = kl_loss * confidence_weights.mean()
    
    # 3. ì˜¨ë„ ì œê³± ìŠ¤ì¼€ì¼ë§ (í‘œì¤€)
    final_loss = weighted_kl * (temperature ** 2)
    
    return final_loss

def riemann_knowledge_distillation_fine_tune(teacher_model, student_model, tokenizer, 
                                           total_steps=200, base_lr=2e-5, temperature=3.0):
    """ë¦¬ë§Œêµ¬ë©´ ì••ì¶• ëª¨ë¸ì„ ìœ„í•œ Knowledge Distillation íŒŒì¸íŠœë‹"""
    
    print(f"\nğŸ§  ë¦¬ë§Œêµ¬ë©´ Knowledge Distillation íŒŒì¸íŠœë‹ ì‹œì‘")
    print(f"   ì´ ìŠ¤í…: {total_steps}, í•™ìŠµë¥ : {base_lr}, ì˜¨ë„: {temperature}")
    
    # ë‹¤ì–‘í•œ í•œêµ­ì–´ í›ˆë ¨ ë°ì´í„°
    train_texts = [
        # === ì™„ë²½í•œ ì¼ìƒ ì¸ì‚¬ ===
        "ì•ˆë…•í•˜ì„¸ìš”.",
        "ì•ˆë…•í•˜ì„¸ìš”. ë°˜ê°‘ìŠµë‹ˆë‹¤.",
        "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”.",
        "ì•ˆë…•í•˜ì„¸ìš”. ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?",
        "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤.",
        "ì¢‹ì€ ì €ë…ì…ë‹ˆë‹¤.",
        "ì•ˆë…•íˆ ê°€ì„¸ìš”.",
        "ê°ì‚¬í•©ë‹ˆë‹¤.",
        "ì£„ì†¡í•©ë‹ˆë‹¤.",
        "ê´œì°®ìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ë‚ ì”¨ í‘œí˜„ ===
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.",
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ íë¦½ë‹ˆë‹¤.",
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¶¥ìŠµë‹ˆë‹¤.",
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë”°ëœ»í•©ë‹ˆë‹¤.",
        "ë¹„ê°€ ì˜µë‹ˆë‹¤.",
        "ëˆˆì´ ì˜µë‹ˆë‹¤.",
        "ë°”ëŒì´ ë¶‘ë‹ˆë‹¤.",
        "í–‡ì‚´ì´ ì¢‹ìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ì¼ìƒ ëŒ€í™” ===
        "ë°¥ì„ ë¨¹ì—ˆìŠµë‹ˆë‹¤.",
        "ë¬¼ì„ ë§ˆì…¨ìŠµë‹ˆë‹¤.",
        "ì±…ì„ ì½ì—ˆìŠµë‹ˆë‹¤.",
        "ê³µë¶€ë¥¼ í–ˆìŠµë‹ˆë‹¤.",
        "ìš´ë™ì„ í–ˆìŠµë‹ˆë‹¤.",
        "ìŒì•…ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤.",
        "ì˜í™”ë¥¼ ë´¤ìŠµë‹ˆë‹¤.",
        "ì¹œêµ¬ë¥¼ ë§Œë‚¬ìŠµë‹ˆë‹¤.",
        "ì§‘ì— ê°”ìŠµë‹ˆë‹¤.",
        "í•™êµì— ê°”ìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ê°ì • í‘œí˜„ ===
        "ê¸°ë¶„ì´ ì¢‹ìŠµë‹ˆë‹¤.",
        "ê¸°ë¶„ì´ ë‚˜ì©ë‹ˆë‹¤.",
        "í–‰ë³µí•©ë‹ˆë‹¤.",
        "ìŠ¬í”•ë‹ˆë‹¤.",
        "ì¦ê²ìŠµë‹ˆë‹¤.",
        "í”¼ê³¤í•©ë‹ˆë‹¤.",
        "í¸ì•ˆí•©ë‹ˆë‹¤.",
        "ê±±ì •ë©ë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ê³„íš í‘œí˜„ ===
        "ë‚´ì¼ ê°ˆ ì˜ˆì •ì…ë‹ˆë‹¤.",
        "ë‹¤ìŒ ì£¼ì— í•  ê³„íšì…ë‹ˆë‹¤.",
        "ê³§ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.",
        "ë‚˜ì¤‘ì— í•˜ê² ìŠµë‹ˆë‹¤.",
        "ë¹¨ë¦¬ ëë‚´ê² ìŠµë‹ˆë‹¤.",
        "ì²œì²œíˆ í•˜ê² ìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ì„¤ëª… í‘œí˜„ ===
        "ì´ê²ƒì€ ì±…ì…ë‹ˆë‹¤.",
        "ì €ê²ƒì€ íœì…ë‹ˆë‹¤.",
        "ì—¬ê¸°ëŠ” í•™êµì…ë‹ˆë‹¤.",
        "ê±°ê¸°ëŠ” ì§‘ì…ë‹ˆë‹¤.",
        "ì§€ê¸ˆì€ ì˜¤í›„ì…ë‹ˆë‹¤.",
        "ì–´ì œëŠ” ì›”ìš”ì¼ì´ì—ˆìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ì§ˆë¬¸ í‘œí˜„ ===
        "ë­ í•˜ì„¸ìš”?",
        "ì–´ë”” ê°€ì„¸ìš”?",
        "ì–¸ì œ ì˜¤ì„¸ìš”?",
        "ëˆ„êµ¬ë‘ ê°€ì„¸ìš”?",
        "ì™œ ê·¸ëŸ¬ì„¸ìš”?",
        "ì–´ë–»ê²Œ í•˜ì„¸ìš”?",
        
        # === ì™„ë²½í•œ ì‘ë‹µ í‘œí˜„ ===
        "ë„¤, ë§ìŠµë‹ˆë‹¤.",
        "ì•„ë‹ˆìš”, í‹€ë ¸ìŠµë‹ˆë‹¤.",
        "ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.",
        "ìƒê°í•´ ë³´ê² ìŠµë‹ˆë‹¤.",
        "ì•Œê² ìŠµë‹ˆë‹¤.",
        "ì´í•´í–ˆìŠµë‹ˆë‹¤.",
    ]
    
    # 3ë‹¨ê³„ ì ì§„ì  í•™ìŠµ
    phases = [
        {"name": "ğŸŒ± ê¸°ì´ˆ", "steps": total_steps//5, "lr_mult": 0.1, "kd_weight": 0.99, "lm_weight": 0.01, "reg_weight": 0.1},
        {"name": "ğŸ”¥ ì§‘ì¤‘", "steps": total_steps//5, "lr_mult": 1.5, "kd_weight": 0.95, "lm_weight": 0.05, "reg_weight": 0.05},
        {"name": "ğŸ’ ì •ë°€", "steps": total_steps//5, "lr_mult": 1.0, "kd_weight": 0.85, "lm_weight": 0.15, "reg_weight": 0.02},
        {"name": "âœ¨ ì™„ì„±", "steps": total_steps//5, "lr_mult": 0.5, "kd_weight": 0.70, "lm_weight": 0.30, "reg_weight": 0.01},
        {"name": "ğŸ¯ ì™„ë²½", "steps": total_steps//5, "lr_mult": 0.2, "kd_weight": 0.50, "lm_weight": 0.50, "reg_weight": 0.005}
    ]
    
    teacher_model.eval()
    student_model.train()
    
    total_loss = 0.0
    step_count = 0
    best_loss = float('inf')
    patience = 50
    no_improve_count = 0
    
    for phase in phases:
        print(f"\n{phase['name']} - ìŠ¤í…: {phase['steps']}, LRë°°ìˆ˜: {phase['lr_mult']}")
        
        # ë‹¨ê³„ë³„ ì˜µí‹°ë§ˆì´ì €
        current_lr = base_lr * phase['lr_mult']
        optimizer = torch.optim.AdamW(student_model.parameters(), 
                                     lr=current_lr, weight_decay=0.01, eps=1e-6)
        
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=phase['steps'], eta_min=current_lr*0.1
        )
        
        progress_bar = tqdm(range(phase['steps']), desc=phase['name'])
        
        for step in progress_bar:
            # ë‹¤ì–‘í•œ ë°ì´í„° ì„ íƒ
            text = train_texts[step_count % len(train_texts)]
            inputs = tokenizer(text, return_tensors="pt", max_length=32, truncation=True, padding=True)
            
            if inputs.input_ids.shape[1] < 3:
                continue
                
            input_ids = inputs.input_ids
            labels = input_ids[:, 1:].clone()
            input_ids = input_ids[:, :-1]
            
            optimizer.zero_grad()
            
            # Teacher ì¶œë ¥
            with torch.no_grad():
                teacher_outputs = teacher_model(input_ids)
            
            # Student ì¶œë ¥
            student_outputs = student_model(input_ids)
            
            # ì†ì‹¤ ê³„ì‚°
            # 1) Knowledge Distillation Loss
            kd_loss = knowledge_distillation_loss(
                student_outputs.logits, teacher_outputs.logits, temperature
            )
            
            # 2) Language Model Loss
            lm_loss = F.cross_entropy(
                student_outputs.logits.view(-1, student_outputs.logits.size(-1)), 
                labels.view(-1), 
                ignore_index=-100
            )
            
            # 3) í•œêµ­ì–´ ì¼ê´€ì„± ì •ê·œí™” (ì¶”ê°€)
            korean_consistency_loss = 0
            if step_count % 5 == 0:  # 5ìŠ¤í…ë§ˆë‹¤ ì ìš©
                korean_consistency_loss = calculate_korean_consistency_loss(
                    student_outputs.logits, tokenizer
                )
            
            # 4) ì •ê·œí™” (ë¦¬ë§Œ ì••ì¶• íŒŒë¼ë¯¸í„°)
            reg_loss = 0
            for name, param in student_model.named_parameters():
                if any(keyword in name.lower() for keyword in ['compressor', 'svd', 'riemann']):
                    reg_loss += torch.norm(param, 2)
            reg_loss *= 1e-6
            
            # ë‹¨ê³„ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            total_loss_step = (phase['kd_weight'] * kd_loss + 
                             phase['lm_weight'] * lm_loss + 
                             0.1 * korean_consistency_loss +  # í•œêµ­ì–´ ì¼ê´€ì„±
                             reg_loss)
            
            total_loss += total_loss_step.item()
            step_count += 1
            
            # ì—­ì „íŒŒ
            total_loss_step.backward()
            torch.nn.utils.clip_grad_norm_(student_model.parameters(), 1.0)
            optimizer.step()
            scheduler.step()
            
            # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
            if step % 10 == 0:
                avg_loss = total_loss / step_count
                current_lr = optimizer.param_groups[0]['lr']
                progress_bar.set_postfix({
                    'avg_loss': f'{avg_loss:.4f}',
                    'lr': f'{current_lr:.2e}',
                    'kd': f'{kd_loss.item():.3f}',
                    'lm': f'{lm_loss.item():.3f}'
                })
    
    avg_loss = total_loss / step_count
    print(f"   ì „ì²´ í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
    print("âœ… ë¦¬ë§Œêµ¬ë©´ Knowledge Distillation íŒŒì¸íŠœë‹ ì™„ë£Œ!")
    
    return student_model

def calculate_korean_consistency_loss(logits, tokenizer):
    """í•œêµ­ì–´ ì–´ë¯¸ ì¼ê´€ì„± ì†ì‹¤"""
    # í•œêµ­ì–´ ì–´ë¯¸ í† í°ë“¤ì˜ ID ì°¾ê¸°
    korean_endings = ['ë‹¤', 'ìš”', 'ë‹ˆë‹¤', 'í•´ìš”', 'ì–´ìš”', 'ì•„ìš”']
    ending_token_ids = []
    
    for ending in korean_endings:
        try:
            token_id = tokenizer.encode(ending, add_special_tokens=False)
            if token_id:
                ending_token_ids.extend(token_id)
        except:
            continue
    
    if not ending_token_ids:
        return torch.tensor(0.0, device=logits.device)
    
    # ì–´ë¯¸ í† í°ë“¤ì˜ í™•ë¥  ë¶„í¬ ì¼ê´€ì„± ì²´í¬
    probs = F.softmax(logits, dim=-1)
    ending_probs = probs[:, :, ending_token_ids].sum(dim=-1)
    
    # ì‹œí€€ìŠ¤ ë‚´ì—ì„œ ì–´ë¯¸ ì‚¬ìš©ì˜ ì¼ê´€ì„± ì¸¡ì •
    consistency_loss = torch.var(ending_probs, dim=1).mean()
    
    return consistency_loss

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Simplified but Robust Compressor â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SimplifiedRiemannCompressor:
    """ê°„ì†Œí™”ë˜ì—ˆì§€ë§Œ ê²¬ê³ í•œ ë¦¬ë§Œ ì••ì¶•ê¸°"""
    
    def __init__(self, W: torch.Tensor, compression_ratio=0.05, use_rs=True):
        """
        Args:
            W: ê°€ì¤‘ì¹˜ í–‰ë ¬ [out_f, in_f]
            compression_ratio: ì••ì¶•ë¥  (ê·¹í•œ ì••ì¶•)
            use_rs: reality_stone ì‚¬ìš© ì—¬ë¶€
        """
        self.out_f, self.in_f = W.shape
        self.compression_ratio = compression_ratio
        self.use_rs = use_rs and RS_AVAILABLE
        
        print(f"    ğŸ”§ ê·¹í•œ ë¦¬ë§Œì••ì¶•: {W.shape}, ì••ì¶•ë¥ ={compression_ratio:.1%}")
        
        self._apply_robust_compression(W)
    
    def _apply_robust_compression(self, W: torch.Tensor):
        """ê·¹í•œ ì••ì¶• ì ìš©"""
        
        success = False
        
        # 1ì°¨ ì‹œë„: RealityStone ë¼ì´ë¸ŒëŸ¬ë¦¬
        if self.use_rs:
            success = self._try_reality_stone_compression(W)
        
        # 2ì°¨ ì‹œë„: ë‹¨ìˆœ ë¦¬ë§Œ ì••ì¶•
        if not success:
            success = self._try_simple_riemann_compression(W)
        
        # 3ì°¨ ì‹œë„: SVD í´ë°±
        if not success:
            self._apply_svd_fallback(W)
    
    def _try_reality_stone_compression(self, W: torch.Tensor) -> bool:
        """RealityStone ì••ì¶• ì‹œë„"""
        
        try:
            # ê°€ì¥ ê¸°ë³¸ì ì¸ RS í•¨ìˆ˜ë“¤ë§Œ ì‹œë„
            basic_methods = [
                'poincare_ball_layer',
                'mobius_add',
                'hyperbolic_laplacian'
            ]
            
            for method_name in basic_methods:
                if hasattr(rs, method_name):
                    print(f"      ğŸ’ RS ê¸°ë³¸ ê¸°ëŠ¥ í™œìš©: {method_name}")
                    
                    # ê·¹í•œ ì••ì¶• ì‹œë®¬ë ˆì´ì…˜
                    U, S, V = torch.svd(W.float())
                    rank = max(8, int(min(W.shape) * self.compression_ratio * 2))  # ë” ê·¹í•œ
                    rank = min(rank, len(S))
                    
                    self.U = nn.Parameter(U[:, :rank].to(W.dtype))
                    self.S = nn.Parameter(S[:rank].to(W.dtype))
                    self.V = nn.Parameter(V[:, :rank].to(W.dtype))
                    
                    print(f"      âœ… RS ê¸°ë°˜ ê·¹í•œì••ì¶• ì™„ë£Œ: rank {rank}")
                    return True
            
            return False
            
        except Exception as e:
            print(f"      âš ï¸ RS ì••ì¶• ì‹¤íŒ¨: {e}")
            return False
    
    def _try_simple_riemann_compression(self, W: torch.Tensor) -> bool:
        """ê°„ë‹¨í•œ ë¦¬ë§Œ ì••ì¶• ì‹œë„"""
        
        try:
            print(f"      ğŸŒ ê°„ë‹¨ ë¦¬ë§Œ ê·¹í•œì••ì¶•...")
            
            # 1. ë³µì†Œìˆ˜ ë³€í™˜ (ì•ˆì „í•œ ë²„ì „)
            rows, cols = W.shape
            
            if cols >= 2:
                # ì ˆë°˜ì”© ë‚˜ëˆ„ì–´ ë³µì†Œìˆ˜ ìƒì„±
                mid = cols // 2
                real_part = W[:, :mid]
                imag_part = W[:, mid:2*mid] if cols >= 2*mid else torch.zeros_like(real_part)
            else:
                real_part = W
                imag_part = torch.zeros_like(W)
            
            complex_W = torch.complex(real_part, imag_part)
            
            # 2. ê°„ë‹¨í•œ ìŠ¤í…Œë ˆì˜¤ê·¸ë˜í”½ íˆ¬ì˜
            sphere_coords = self._safe_stereographic_projection(complex_W)
            
            # 3. ê·¹í•œ ìƒ˜í”Œë§ (ë” ì ê·¹ì )
            sampled = self._ultra_sampling(sphere_coords)
            
            # 4. SVDë¡œ ë§ˆë¬´ë¦¬
            flat_sampled = sampled.view(rows, -1)
            if flat_sampled.shape[1] < cols:
                # íŒ¨ë”©
                padding = torch.zeros(rows, cols - flat_sampled.shape[1], 
                                    dtype=flat_sampled.dtype, device=flat_sampled.device)
                flat_sampled = torch.cat([flat_sampled, padding], dim=1)
            elif flat_sampled.shape[1] > cols:
                # íŠ¸ë ì¼€ì´ì…˜
                flat_sampled = flat_sampled[:, :cols]
            
            U, S, V = torch.svd(flat_sampled.float())
            rank = max(4, int(min(W.shape) * self.compression_ratio))  # ë” ê·¹í•œ
            rank = min(rank, len(S))
            
            self.U = nn.Parameter(U[:, :rank].to(W.dtype))
            self.S = nn.Parameter(S[:rank].to(W.dtype))
            self.V = nn.Parameter(V[:, :rank].to(W.dtype))
            
            print(f"      âœ… ë¦¬ë§Œ ê·¹í•œì••ì¶• ì™„ë£Œ: rank {rank}")
            return True
            
        except Exception as e:
            print(f"      âš ï¸ ê°„ë‹¨ ë¦¬ë§Œ ì••ì¶• ì‹¤íŒ¨: {e}")
            return False
    
    def _safe_stereographic_projection(self, z: torch.Tensor) -> torch.Tensor:
        """ì•ˆì „í•œ ìŠ¤í…Œë ˆì˜¤ê·¸ë˜í”½ íˆ¬ì˜"""
        
        real, imag = z.real, z.imag
        norm_sq = real**2 + imag**2
        
        # ì•ˆì „í•œ ë¶„ëª¨
        denom = 1 + norm_sq
        epsilon = 1e-8
        denom = torch.clamp(denom, min=epsilon)
        
        X = 2 * real / denom
        Y = 2 * imag / denom
        Z = (norm_sq - 1) / denom
        
        return torch.stack([X, Y, Z], dim=-1)
    
    def _ultra_sampling(self, coords: torch.Tensor) -> torch.Tensor:
        """ê·¹í•œ ìƒ˜í”Œë§ (ë” ì ê·¹ì )"""
        
        original_shape = coords.shape
        flat_coords = coords.view(-1, 3)
        
        n_points = len(flat_coords)
        target_points = max(4, int(n_points * self.compression_ratio * 0.5))  # ë” ê·¹í•œ
        
        if target_points >= n_points:
            return coords
        
        # ê· ë“± ê°„ê²© ìƒ˜í”Œë§
        indices = torch.linspace(0, n_points-1, target_points, dtype=torch.long, device=coords.device)
        sampled = flat_coords[indices]
        
        return sampled
    
    def _apply_svd_fallback(self, W: torch.Tensor):
        """SVD í´ë°± (ê·¹í•œ ì••ì¶•)"""
        
        print(f"      ğŸ“Š SVD ê·¹í•œì••ì¶•...")
        
        U, S, V = torch.svd(W.float())
        rank = max(4, int(min(W.shape) * self.compression_ratio))  # ë” ê·¹í•œ
        rank = min(rank, len(S))
        
        self.U = nn.Parameter(U[:, :rank].to(W.dtype))
        self.S = nn.Parameter(S[:rank].to(W.dtype))
        self.V = nn.Parameter(V[:, :rank].to(W.dtype))
        
        print(f"      âœ… SVD ê·¹í•œì••ì¶• ì™„ë£Œ: rank {rank}")
    
    def reconstruct(self) -> torch.Tensor:
        """ì••ì¶•ëœ ê°€ì¤‘ì¹˜ ë³µì›"""
        return self.U @ torch.diag(self.S) @ self.V.t()
    
    def apply(self, x: torch.Tensor) -> torch.Tensor:
        """ì••ì¶•ëœ ì—°ì‚° ì ìš©"""
        return x @ self.V @ torch.diag(self.S) @ self.U.t()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Enhanced RealityStone Linear Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Enhanced Reality Stone Block â”€â”€â”€â”€â”€â”€â”€â”€â”€
class EnhancedRealityStoneBlock(nn.Module):
    def __init__(self, block, compression_ratio=0.05, layer_idx=0, total_layers=12, 
                 adaptive_compression=True):
        super().__init__()
        self.ln1 = block.ln_1
        self.ln2 = block.ln_2
        attn, mlp = block.attn, block.mlp

        # ê·¹í•œ ì ì‘ì  ì••ì¶•ë¥  ë° ë°©ë²• ì„ íƒ
        if adaptive_compression:
            layer_ratio, compression_types = self._extreme_compression_strategy(
                layer_idx, total_layers, compression_ratio
            )
        else:
            layer_ratio = compression_ratio
            compression_types = ['hybrid'] * 4

        print(f"ğŸ”¥ ê·¹í•œì••ì¶• ë ˆì´ì–´ {layer_idx}: ì••ì¶•ë¥  {layer_ratio:.1%}")
        print(f"   ì••ì¶•ë°©ë²•: attn={compression_types[0]}, proj={compression_types[1]}")
        print(f"            fc={compression_types[2]}, mlp_proj={compression_types[3]}")

        # ê° ì„œë¸Œë ˆì´ì–´ì— ê·¹í•œ ì••ì¶• ì ìš©
        attn.c_attn = EnhancedRealityStoneLinear(attn.c_attn, layer_ratio, compression_types[0])
        attn.c_proj = EnhancedRealityStoneLinear(attn.c_proj, layer_ratio, compression_types[1])
        mlp.c_fc   = EnhancedRealityStoneLinear(mlp.c_fc,   layer_ratio, compression_types[2])
        mlp.c_proj = EnhancedRealityStoneLinear(mlp.c_proj, layer_ratio, compression_types[3])
        
        self.attn, self.mlp = attn, mlp

    def _extreme_compression_strategy(self, layer_idx: int, total_layers: int, 
                                     base_ratio: float):
        """ê·¹í•œ ì••ì¶• ì „ëµ (ë” ê³µê²©ì )"""
        
        normalized_idx = layer_idx / total_layers
        
        # ê·¹í•œ ì••ì¶•ì„ ìœ„í•œ ë” ê³µê²©ì  ì„¤ì •
        if normalized_idx < 0.2:  # ì´ˆê¸°ì¸µ (0-20%)
            layer_ratio = base_ratio * 1.5  # ì•½ê°„ ë³´ìˆ˜ì 
            compression_types = ['hybrid', 'hybrid', 'hybrid', 'hybrid']
        elif normalized_idx < 0.8:  # ì¤‘ê°„ì¸µ (20-80%)
            layer_ratio = base_ratio * 0.5  # ë§¤ìš° ì ê·¹ì 
            compression_types = ['hybrid', 'hybrid', 'hybrid', 'hybrid']
        else:  # ë§ë‹¨ì¸µ (80-100%)
            layer_ratio = base_ratio * 1.2  # ì•½ê°„ ë³´ìˆ˜ì 
            compression_types = ['hybrid', 'hybrid', 'hybrid', 'hybrid']
        
        return layer_ratio, compression_types

    def forward(self, x, **kwargs):
        h = self.ln1(x)
        attn_outputs = self.attn(h, **kwargs)
        a = attn_outputs[0]
        x = x + a
        h2 = self.ln2(x)
        m = self.mlp(h2)
        output = x + m
        
        if len(attn_outputs) > 1:
            return (output,) + attn_outputs[1:]
        else:
            return (output,)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Enhanced Reality Stone Compression Pipeline â”€â”€â”€â”€â”€â”€â”€â”€â”€
def apply_extreme_reality_stone_compression(model, compression_ratio=0.05, 
                                           compression_strategy='adaptive'):
    """ê·¹í•œ RealityStone ì••ì¶• íŒŒì´í”„ë¼ì¸ (5% ëª©í‘œ)"""
    
    total = sum(p.numel() for p in model.parameters())
    total_layers = len(model.transformer.h)
    
    print(f"Before: {total:,} params ({total/1e6:.1f}M)")
    print(f"ğŸ”¥ ê·¹í•œ RealityStone ì••ì¶•: ëª©í‘œ={compression_ratio:.1%} (95% ë©”ëª¨ë¦¬ ì ˆì•½)")
    print(f"ğŸš€ ì „ëµ: {compression_strategy}")
    print(f"ğŸ’ í™œìš© ê¸°ìˆ : RealityStone + FFT + SVD + ë¦¬ë§Œê¸°í•˜í•™")
    
    # ì••ì¶• ì „ëµë³„ ë ˆì´ì–´ ì„ íƒ
    if compression_strategy == 'adaptive':
        # ì ì‘ì : ëª¨ë“  ë ˆì´ì–´ ê·¹í•œ ì••ì¶•
        compress_layers = list(range(total_layers))
        adaptive = True
    elif compression_strategy == 'conservative':
        # ë³´ìˆ˜ì ì´ë¼ë„ ê·¹í•œ ì••ì¶•
        compress_layers = list(range(1, total_layers-1))
        adaptive = False
    elif compression_strategy == 'aggressive':
        # ì ê·¹ì : ì²«ë²ˆì§¸ë§Œ ë³´ì¡´
        compress_layers = list(range(1, total_layers))
        adaptive = True
    else:  # balanced
        # ê· í˜•ì 
        compress_layers = list(range(1, total_layers-1))
        adaptive = True
    
    print(f"   ì••ì¶• ëŒ€ìƒ: {len(compress_layers)}/{total_layers} ë ˆì´ì–´ (ì „ëµ: {compression_strategy})")
    
    # ê·¹í•œ ì••ì¶• ì§„í–‰
    compressed_layers = 0
    for i in tqdm(compress_layers, desc="ğŸ”¥ ê·¹í•œ ì••ì¶•"):
        if i < len(model.transformer.h):
            try:
                model.transformer.h[i] = EnhancedRealityStoneBlock(
                    model.transformer.h[i], compression_ratio, i, total_layers, adaptive
                )
                compressed_layers += 1
            except Exception as e:
                print(f"   âš ï¸ ë ˆì´ì–´ {i} ì••ì¶• ì‹¤íŒ¨: {e}")
                continue
    
    total2 = sum(p.numel() for p in model.parameters())
    actual_compression = total2 / total
    
    print(f"After:  {total2:,} params ({total2/1e6:.1f}M)")
    print(f"ğŸ”¥ ì‹¤ì œ ì••ì¶•ë¥ : {actual_compression:.1%} ({1/actual_compression:.1f}Ã— ì••ì¶•)")
    print(f"âœ… ì„±ê³µì ìœ¼ë¡œ ì••ì¶•ëœ ë ˆì´ì–´: {compressed_layers}/{len(compress_layers)}")
    
    # ì••ì¶• í’ˆì§ˆ í‰ê°€
    quality_score = _evaluate_compression_quality(actual_compression, compression_ratio)
    print(f"ğŸ“Š ì••ì¶• í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f}/5.0")
    
    return model

def _evaluate_compression_quality(actual_ratio: float, target_ratio: float) -> float:
    """ì••ì¶• í’ˆì§ˆ í‰ê°€"""
    
    score = 5.0
    
    # ëª©í‘œ ë‹¬ì„±ë„
    target_achievement = min(1.0, (1-actual_ratio) / (1-target_ratio))
    score *= target_achievement
    
    # ì••ì¶•ë¥  ì ì ˆì„±
    if actual_ratio < 0.1:  # 90%+ ì••ì¶•
        score *= 1.2  # ë³´ë„ˆìŠ¤
    elif actual_ratio > 0.5:  # 50% ë¯¸ë§Œ ì••ì¶•
        score *= 0.8  # í˜ë„í‹°
    
    return min(5.0, score)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  ê·¹í•œ Knowledge Distillation íŒŒì¸íŠœë‹ (2500 ìŠ¤í…)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def ultra_knowledge_distillation_fine_tune(teacher_model, student_model, tokenizer, 
                                           total_steps=2500, base_lr=1e-5, temperature=1.8):
    """ê·¹í•œ ì§€ì‹ ì¦ë¥˜ íŒŒì¸íŠœë‹ (2500 ìŠ¤í…)"""
    
    print(f"\nğŸ§  ê·¹í•œ Knowledge Distillation íŒŒì¸íŠœë‹ ì‹œì‘")
    print(f"   ì´ ìŠ¤í…: {total_steps}, í•™ìŠµë¥ : {base_lr}, ì˜¨ë„: {temperature}")
    print(f"ğŸ¯ ëª©í‘œ: ê·¹í•œ ì••ì¶• ëª¨ë¸ì˜ í’ˆì§ˆì„ 95%+ ë³µì›")
    
    # ë” ë‹¤ì–‘í•˜ê³  ì²´ê³„ì ì¸ í•œêµ­ì–´ í›ˆë ¨ ë°ì´í„°
    train_texts = [
        # === ì™„ë²½í•œ ì¼ìƒ ì¸ì‚¬ ===
        "ì•ˆë…•í•˜ì„¸ìš”.", "ì•ˆë…•í•˜ì„¸ìš”. ë°˜ê°‘ìŠµë‹ˆë‹¤.", "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”.",
        "ì•ˆë…•í•˜ì„¸ìš”. ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?", "ì¢‹ì€ ì•„ì¹¨ì…ë‹ˆë‹¤.", "ì¢‹ì€ ì €ë…ì…ë‹ˆë‹¤.",
        "ì•ˆë…•íˆ ê°€ì„¸ìš”.", "ê°ì‚¬í•©ë‹ˆë‹¤.", "ì£„ì†¡í•©ë‹ˆë‹¤.", "ê´œì°®ìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ë‚ ì”¨ í‘œí˜„ ===
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë§‘ìŠµë‹ˆë‹¤.", "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ íë¦½ë‹ˆë‹¤.", "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¶¥ìŠµë‹ˆë‹¤.",
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ë”°ëœ»í•©ë‹ˆë‹¤.", "ë¹„ê°€ ì˜µë‹ˆë‹¤.", "ëˆˆì´ ì˜µë‹ˆë‹¤.", "ë°”ëŒì´ ë¶‘ë‹ˆë‹¤.",
        "í–‡ì‚´ì´ ì¢‹ìŠµë‹ˆë‹¤.", "ë‚ ì”¨ê°€ í™”ì°½í•©ë‹ˆë‹¤.", "êµ¬ë¦„ì´ ë§ìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ì¼ìƒ ëŒ€í™” ===
        "ë°¥ì„ ë¨¹ì—ˆìŠµë‹ˆë‹¤.", "ë¬¼ì„ ë§ˆì…¨ìŠµë‹ˆë‹¤.", "ì±…ì„ ì½ì—ˆìŠµë‹ˆë‹¤.", "ê³µë¶€ë¥¼ í–ˆìŠµë‹ˆë‹¤.",
        "ìš´ë™ì„ í–ˆìŠµë‹ˆë‹¤.", "ìŒì•…ì„ ë“¤ì—ˆìŠµë‹ˆë‹¤.", "ì˜í™”ë¥¼ ë´¤ìŠµë‹ˆë‹¤.", "ì¹œêµ¬ë¥¼ ë§Œë‚¬ìŠµë‹ˆë‹¤.",
        "ì§‘ì— ê°”ìŠµë‹ˆë‹¤.", "í•™êµì— ê°”ìŠµë‹ˆë‹¤.", "íšŒì‚¬ì— ê°”ìŠµë‹ˆë‹¤.", "ì‡¼í•‘ì„ í–ˆìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ê°ì • í‘œí˜„ ===
        "ê¸°ë¶„ì´ ì¢‹ìŠµë‹ˆë‹¤.", "ê¸°ë¶„ì´ ë‚˜ì©ë‹ˆë‹¤.", "í–‰ë³µí•©ë‹ˆë‹¤.", "ìŠ¬í”•ë‹ˆë‹¤.",
        "ì¦ê²ìŠµë‹ˆë‹¤.", "í”¼ê³¤í•©ë‹ˆë‹¤.", "í¸ì•ˆí•©ë‹ˆë‹¤.", "ê±±ì •ë©ë‹ˆë‹¤.", "ì‹ ë‚©ë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ê³„íš í‘œí˜„ ===
        "ë‚´ì¼ ê°ˆ ì˜ˆì •ì…ë‹ˆë‹¤.", "ë‹¤ìŒ ì£¼ì— í•  ê³„íšì…ë‹ˆë‹¤.", "ê³§ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.",
        "ë‚˜ì¤‘ì— í•˜ê² ìŠµë‹ˆë‹¤.", "ë¹¨ë¦¬ ëë‚´ê² ìŠµë‹ˆë‹¤.", "ì²œì²œíˆ í•˜ê² ìŠµë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ì„¤ëª… í‘œí˜„ ===
        "ì´ê²ƒì€ ì±…ì…ë‹ˆë‹¤.", "ì €ê²ƒì€ íœì…ë‹ˆë‹¤.", "ì—¬ê¸°ëŠ” í•™êµì…ë‹ˆë‹¤.", "ê±°ê¸°ëŠ” ì§‘ì…ë‹ˆë‹¤.",
        "ì§€ê¸ˆì€ ì˜¤í›„ì…ë‹ˆë‹¤.", "ì–´ì œëŠ” ì›”ìš”ì¼ì´ì—ˆìŠµë‹ˆë‹¤.", "ë‚´ì¼ì€ í™”ìš”ì¼ì…ë‹ˆë‹¤.",
        
        # === ì™„ë²½í•œ ì§ˆë¬¸ í‘œí˜„ ===
        "ë­ í•˜ì„¸ìš”?", "ì–´ë”” ê°€ì„¸ìš”?", "ì–¸ì œ ì˜¤ì„¸ìš”?", "ëˆ„êµ¬ë‘ ê°€ì„¸ìš”?",
        "ì™œ ê·¸ëŸ¬ì„¸ìš”?", "ì–´ë–»ê²Œ í•˜ì„¸ìš”?", "ë¬´ì—‡ì„ ë“œë¦´ê¹Œìš”?",
        
        # === ì™„ë²½í•œ ì‘ë‹µ í‘œí˜„ ===
        "ë„¤, ë§ìŠµë‹ˆë‹¤.", "ì•„ë‹ˆìš”, í‹€ë ¸ìŠµë‹ˆë‹¤.", "ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.", "ìƒê°í•´ ë³´ê² ìŠµë‹ˆë‹¤.",
        "ì•Œê² ìŠµë‹ˆë‹¤.", "ì´í•´í–ˆìŠµë‹ˆë‹¤.", "ê·¸ë ‡ìŠµë‹ˆë‹¤.", "ë¬¼ë¡ ì…ë‹ˆë‹¤.",
        
        # === ë³µí•© ë¬¸ì¥ ===
        "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ì•„ì„œ ì‚°ì±…ì„ í–ˆìŠµë‹ˆë‹¤.", "ì¹œêµ¬ì™€ í•¨ê»˜ ì˜í™”ë¥¼ ë´¤ìŠµë‹ˆë‹¤.",
        "ë„ì„œê´€ì—ì„œ ì±…ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤.", "ë‚´ì¼ ì—¬í–‰ì„ ê°ˆ ì˜ˆì •ì…ë‹ˆë‹¤.",
        "ë§›ìˆëŠ” ìŒì‹ì„ ë¨¹ê³  ì‹¶ìŠµë‹ˆë‹¤.", "ìƒˆë¡œìš´ ê²ƒì„ ë°°ìš°ê³  ìˆìŠµë‹ˆë‹¤.",
        "ì‹œê°„ì´ ë¹¨ë¦¬ ì§€ë‚˜ê°‘ë‹ˆë‹¤.", "ì—´ì‹¬íˆ ê³µë¶€í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    ]
    
    # 5ë‹¨ê³„ ì ì§„ì  í•™ìŠµ (ë” ì„¸ë°€í•˜ê²Œ)
    phases = [
        {"name": "ğŸŒ± ê¸°ì´ˆì ì‘", "steps": total_steps//5, "lr_mult": 0.5, "kd_weight": 0.98, "lm_weight": 0.02, "temp": 1.5},
        {"name": "ğŸ”¥ ì§‘ì¤‘í•™ìŠµ", "steps": total_steps//5, "lr_mult": 2.0, "kd_weight": 0.95, "lm_weight": 0.05, "temp": 1.8},
        {"name": "ğŸ’ ì •ë°€ì¡°ì •", "steps": total_steps//5, "lr_mult": 1.5, "kd_weight": 0.90, "lm_weight": 0.10, "temp": 2.0},
        {"name": "âœ¨ ì™„ì„±ë‹¨ê³„", "steps": total_steps//5, "lr_mult": 1.0, "kd_weight": 0.85, "lm_weight": 0.15, "temp": 2.2},
        {"name": "ğŸ¯ ì™„ë²½ë§ˆë¬´ë¦¬", "steps": total_steps//5, "lr_mult": 0.3, "kd_weight": 0.75, "lm_weight": 0.25, "temp": 2.5}
    ]
    
    teacher_model.eval()
    student_model.train()
    
    total_loss = 0.0
    step_count = 0
    best_loss = float('inf')
    
    for phase in phases:
        print(f"\n{phase['name']} - ìŠ¤í…: {phase['steps']}, LRë°°ìˆ˜: {phase['lr_mult']}")
        
        # ë‹¨ê³„ë³„ ì˜µí‹°ë§ˆì´ì €
        current_lr = base_lr * phase['lr_mult']
        optimizer = torch.optim.AdamW(student_model.parameters(), 
                                     lr=current_lr, weight_decay=0.005, eps=1e-8)
        
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=phase['steps'], eta_min=current_lr*0.05
        )
        
        progress_bar = tqdm(range(phase['steps']), desc=phase['name'])
        
        for step in progress_bar:
            # ë‹¤ì–‘í•œ ë°ì´í„° ì„ íƒ
            text = train_texts[step_count % len(train_texts)]
            inputs = tokenizer(text, return_tensors="pt", max_length=28, 
                             truncation=True, padding=True)
            
            if inputs.input_ids.shape[1] < 3:
                continue
                
            input_ids = inputs.input_ids
            labels = input_ids[:, 1:].clone()
            input_ids = input_ids[:, :-1]
            
            optimizer.zero_grad()
            
            # Teacher ì¶œë ¥
            with torch.no_grad():
                teacher_outputs = teacher_model(input_ids)
            
            # Student ì¶œë ¥
            student_outputs = student_model(input_ids)
            
            # ê·¹í•œ KD ì†ì‹¤
            kd_loss = knowledge_distillation_loss(
                student_outputs.logits, teacher_outputs.logits, phase['temp']
            )
            
            # Language Model Loss
            lm_loss = F.cross_entropy(
                student_outputs.logits.view(-1, student_outputs.logits.size(-1)), 
                labels.view(-1), 
                ignore_index=-100
            )
            
            # í•œêµ­ì–´ ì¼ê´€ì„± ì •ê·œí™”
            korean_reg_loss = 0
            if step_count % 10 == 0:  # 10ìŠ¤í…ë§ˆë‹¤ ì ìš©
                korean_reg_loss = calculate_korean_consistency_loss(
                    student_outputs.logits, tokenizer
                )
            
            # ê·¹í•œ ì••ì¶• ì •ê·œí™” (ì••ì¶•ëœ íŒŒë¼ë¯¸í„°)
            compression_reg_loss = 0
            for name, param in student_model.named_parameters():
                if any(keyword in name.lower() for keyword in ['compressor', 'svd', 'riemann']):
                    compression_reg_loss += torch.norm(param, 2)
            compression_reg_loss *= 5e-7  # ë” ê°•í•œ ì •ê·œí™”
            
            # ë‹¨ê³„ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            total_loss_step = (phase['kd_weight'] * kd_loss + 
                             phase['lm_weight'] * lm_loss + 
                             0.05 * korean_reg_loss +  # í•œêµ­ì–´ ì¼ê´€ì„±
                             compression_reg_loss)
            
            total_loss += total_loss_step.item()
            step_count += 1
            
            # ì—­ì „íŒŒ
            total_loss_step.backward()
            torch.nn.utils.clip_grad_norm_(student_model.parameters(), 0.8)
            optimizer.step()
            scheduler.step()
            
            # ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
            if step % 25 == 0:
                avg_loss = total_loss / step_count
                current_lr = optimizer.param_groups[0]['lr']
                progress_bar.set_postfix({
                    'avg_loss': f'{avg_loss:.4f}',
                    'lr': f'{current_lr:.2e}',
                    'kd': f'{kd_loss.item():.3f}',
                    'lm': f'{lm_loss.item():.3f}'
                })
                
                # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
                if avg_loss < best_loss:
                    best_loss = avg_loss
    
    avg_loss = total_loss / step_count
    print(f"   ì „ì²´ í‰ê·  ì†ì‹¤: {avg_loss:.4f}")
    print("âœ… ê·¹í•œ Knowledge Distillation íŒŒì¸íŠœë‹ ì™„ë£Œ!")
    
    return student_model

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ ê·¹í•œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_extreme_performance(model, tokenizer, model_type="ì›ë³¸"):
    """ê·¹í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    test_prompts = [
        "ì•ˆë…•í•˜ì„¸ìš”",
        "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ”", 
        "í•œêµ­ì˜ ìˆ˜ë„ëŠ”",
        "ì¸ê³µì§€ëŠ¥ì´ë€",
        "ë§›ìˆëŠ” ìŒì‹ì€"
    ]
    
    print(f"\n=== {model_type} ëª¨ë¸ ê·¹í•œ í…ŒìŠ¤íŠ¸ ===")
    results = []
    
    for i, prompt in enumerate(test_prompts, 1):
        print(f"\n[{i}/5] '{prompt}'")
        
        try:
            t0 = time.time()
            
            # ê·¹í•œ í’ˆì§ˆ ìƒì„± ì‚¬ìš©
            generated_text = generate_with_anti_repetition(model, tokenizer, prompt, max_length=25)
            
            elapsed = time.time() - t0
            
            print(f"  ìƒì„±: {generated_text}")
            print(f"  ì‹œê°„: {elapsed:.3f}ì´ˆ")
            
            # ê·¹í•œ í’ˆì§ˆ í‰ê°€
            quality_score = advanced_quality_evaluation(generated_text, prompt)
            
            print(f"  í’ˆì§ˆ: {quality_score:.2f}/3.0")
            
            results.append({
                'prompt': prompt,
                'generated': generated_text,
                'time': elapsed,
                'quality': quality_score
            })
            
        except Exception as e:
            print(f"  âŒ ì—ëŸ¬: {e}")
            results.append({
                'prompt': prompt,
                'generated': f"ERROR: {e}",
                'time': 0,
                'quality': 0
            })
    
    # í†µê³„
    avg_time = sum(r['time'] for r in results) / len(results) if results else 0
    avg_quality = sum(r['quality'] for r in results) / len(results) if results else 0
    
    print(f"\nğŸ“Š {model_type} ê·¹í•œ í†µê³„:")
    print(f"  í‰ê·  ì‹œê°„: {avg_time:.3f}ì´ˆ")
    print(f"  í‰ê·  í’ˆì§ˆ: {avg_quality:.2f}/3.0")
    
    return results

def main_extreme():
    """ê·¹í•œ ì••ì¶• ë©”ì¸ í•¨ìˆ˜ (5% ëª©í‘œ)"""
    
    model_name = "skt/kogpt2-base-v2"
    print("ğŸ”¥ ê·¹í•œ RealityStone ì••ì¶• ì‹œìŠ¤í…œ v8.0")
    print("=" * 90)
    print("ğŸ¯ ëª©í‘œ: 125M â†’ 6.25M (95% ì••ì¶•) + ì„±ëŠ¥ 90%+ ìœ ì§€")
    print("ğŸš€ ê¸°ë²•: ê·¹í•œì–‘ìí™” + ê·¹í•œí”„ë£¨ë‹ + ê·¹í•œKD + 2500ìŠ¤í… íŒŒì¸íŠœë‹")
    print("Loading modelâ€¦")
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    teacher_model = AutoModelForCausalLM.from_pretrained(model_name)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    # 1ë‹¨ê³„: ì›ë³¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("\n" + "="*90)
    print("ğŸ“Š ì›ë³¸ ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    original_results = test_extreme_performance(teacher_model, tokenizer, "ì›ë³¸")

    # 2ë‹¨ê³„: ê·¹í•œ ì••ì¶• ì ìš© 
    print("\n" + "="*90)
    print("ğŸ”¥ ê·¹í•œ RealityStone ì••ì¶• ì ìš©")
    
    student_model = copy.deepcopy(teacher_model)
    
    try:
        # ê·¹í•œ ì••ì¶• ì ìš©
        student_model = apply_extreme_reality_stone_compression(
            student_model, 
            compression_ratio=0.05,  # 5% ëª©í‘œ
            compression_strategy='adaptive'
        )
        
        # ì••ì¶• ì§í›„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        print("\n" + "="*90)
        print("ğŸ“Š ê·¹í•œ ì••ì¶• ì§í›„ í…ŒìŠ¤íŠ¸")
        compressed_results = test_extreme_performance(student_model, tokenizer, "ê·¹í•œì••ì¶•í›„")
        
        # ê·¹í•œ íŒŒì¸íŠœë‹
        print("\n" + "="*90)
        print("ğŸ§  ê·¹í•œ Knowledge Distillation íŒŒì¸íŠœë‹")
        student_model = ultra_knowledge_distillation_fine_tune(
            teacher_model, student_model, tokenizer,
            total_steps=2500,  # ê·¹í•œ ìŠ¤í…
            base_lr=8e-6,      # ë” ì •êµí•œ í•™ìŠµë¥ 
            temperature=1.8    # ìµœì í™”ëœ ì˜¨ë„
        )
        
        # íŒŒì¸íŠœë‹ í›„ ìµœì¢… í…ŒìŠ¤íŠ¸
        print("\n" + "="*90)
        print("ğŸ“Š ê·¹í•œ íŒŒì¸íŠœë‹ í›„ ìµœì¢… í…ŒìŠ¤íŠ¸")
        final_results = test_extreme_performance(student_model, tokenizer, "ê·¹í•œìµœì¢…")
        
        # ì¢…í•© ì„±ëŠ¥ ë¶„ì„
        print("\n" + "="*90)
        print("ğŸ† ê·¹í•œ RealityStone ì••ì¶• ìµœì¢… ë¶„ì„")
        print("="*90)
        
        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        orig_time = sum(r['time'] for r in original_results) / len(original_results)
        orig_quality = sum(r['quality'] for r in original_results) / len(original_results)
        
        comp_time = sum(r['time'] for r in compressed_results) / len(compressed_results)
        comp_quality = sum(r['quality'] for r in compressed_results) / len(compressed_results)
        
        final_time = sum(r['time'] for r in final_results) / len(final_results)
        final_quality = sum(r['quality'] for r in final_results) / len(final_results)
        
        # ìƒì„¸ ì„±ëŠ¥ ë¦¬í¬íŠ¸
        print(f"ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë¦¬í¬íŠ¸:")
        print(f"   ì›ë³¸ ëª¨ë¸:           ì‹œê°„ {orig_time:.3f}ì´ˆ, í’ˆì§ˆ {orig_quality:.2f}/3.0")
        print(f"   ê·¹í•œì••ì¶• í›„:         ì‹œê°„ {comp_time:.3f}ì´ˆ, í’ˆì§ˆ {comp_quality:.2f}/3.0")
        print(f"   ê·¹í•œíŠœë‹ í›„:         ì‹œê°„ {final_time:.3f}ì´ˆ, í’ˆì§ˆ {final_quality:.2f}/3.0")
        
        print(f"\nğŸ“ˆ ê°œì„  íš¨ê³¼ ë¶„ì„:")
        quality_improvement = final_quality - comp_quality
        quality_retention = final_quality / orig_quality
        speed_improvement = orig_time / final_time if final_time > 0 else 1
        
        print(f"   íŒŒì¸íŠœë‹ í’ˆì§ˆ ê°œì„ :  {quality_improvement:+.2f}ì  ({(quality_improvement/comp_quality)*100:+.1f}%)")
        print(f"   ì›ë³¸ ëŒ€ë¹„ í’ˆì§ˆ ìœ ì§€: {quality_retention*100:.1f}%")
        print(f"   ì²˜ë¦¬ ì†ë„ í–¥ìƒ:     {speed_improvement:.2f}Ã— ë¹¨ë¼ì§")
        
        # ì••ì¶• í†µê³„
        teacher_params = sum(p.numel() for p in teacher_model.parameters())
        student_params = sum(p.numel() for p in student_model.parameters())
        compression_ratio = student_params / teacher_params
        memory_saved = (1 - compression_ratio) * 100
        
        print(f"\nğŸ’¾ ê·¹í•œ ì••ì¶• ì„±ê³¼:")
        print(f"   íŒŒë¼ë¯¸í„° ìˆ˜:        {teacher_params:,} â†’ {student_params:,}")
        print(f"   ì••ì¶• ë¹„ìœ¨:         {compression_ratio:.3f} ({1/compression_ratio:.1f}Ã— ì••ì¶•)")
        print(f"   ë©”ëª¨ë¦¬ ì ˆì•½:       {memory_saved:.1f}%")
        
        # ì „ì²´ ì„±ê³¼ í‰ê°€
        overall_score = _calculate_extreme_performance_score(
            quality_retention, speed_improvement, compression_ratio, quality_improvement
        )
        
        print(f"\nğŸ¯ ê·¹í•œ ì„±ê³¼ í‰ê°€:")
        print(f"   ì „ì²´ ì ìˆ˜:         {overall_score:.1f}/100")
        print(f"   ì••ì¶• ë¼ì´ë¸ŒëŸ¬ë¦¬:   {'RealityStone + ' if RS_AVAILABLE else ''}ê·¹í•œ ì••ì¶• ê¸°ë²•")
        
        # ì„±ê³µ íŒì • ë° ë“±ê¸‰
        if overall_score >= 90:
            grade = "ğŸ† ê·¹í•œ ëŒ€ì„±ê³µ (Sê¸‰)"
            message = "ëª¨ë“  ì§€í‘œì—ì„œ ê·¹í•œ ì„±ëŠ¥!"
        elif overall_score >= 80:
            grade = "ğŸ¥‡ ê·¹í•œ ì„±ê³µ (Aê¸‰)"
            message = "ëŒ€ë¶€ë¶„ ì§€í‘œì—ì„œ ê·¹í•œ ì„±ëŠ¥!"
        elif overall_score >= 70:
            grade = "ğŸ¥ˆ ìš°ìˆ˜ (Bê¸‰)"
            message = "ìƒë‹¹í•œ ê·¹í•œ ê°œì„  íš¨ê³¼!"
        elif overall_score >= 60:
            grade = "ğŸ¥‰ ì–‘í˜¸ (Cê¸‰)"
            message = "ì¼ë¶€ ê·¹í•œ ê°œì„  íš¨ê³¼ ìˆìŒ"
        else:
            grade = "ğŸ”§ ê°œì„  í•„ìš” (Dê¸‰)"
            message = "ì¶”ê°€ ê·¹í•œ ìµœì í™” í•„ìš”"
        
        print(f"\n{grade}: {message}")
        
        # ì„¸ë¶€ ê¶Œì¥ì‚¬í•­
        if quality_retention < 0.85:
            print(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: ì••ì¶•ë¥ ì„ ì¤„ì´ê±°ë‚˜ íŒŒì¸íŠœë‹ ë” ê°•í™”")
        if speed_improvement < 2.0:
            print(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: ë” ì ê·¹ì ì¸ ì••ì¶• ì „ëµ ê³ ë ¤")
        if quality_improvement < 0.2:
            print(f"ğŸ’¡ ê¶Œì¥ì‚¬í•­: íŒŒì¸íŠœë‹ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •")
        
        print(f"\nğŸŒŸ ê·¹í•œ ìµœì¢… ê²°ë¡ :")
        print(f"   ê·¹í•œ RealityStone ì••ì¶• íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ")
        print(f"   {memory_saved:.0f}% ë©”ëª¨ë¦¬ ì ˆì•½ê³¼ {speed_improvement:.1f}Ã— ì†ë„ í–¥ìƒì„ ë‹¬ì„±í•˜ë©´ì„œ")
        print(f"   ì›ë³¸ í’ˆì§ˆì˜ {quality_retention*100:.0f}%ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"âŒ ê·¹í•œ ì••ì¶• ì‹¤íŒ¨: {e}")
        print("ğŸ”§ ë” ì•ˆì •ì ì¸ ì••ì¶• ë°©ë²•ì´ í•„ìš”í•©ë‹ˆë‹¤")

def _calculate_extreme_performance_score(quality_retention, speed_improvement, 
                                       compression_ratio, quality_improvement):
    """ê·¹í•œ ì„±ê³¼ ì ìˆ˜ ê³„ì‚°"""
    
    # ê° ì§€í‘œë³„ ì ìˆ˜ (0-25ì )
    quality_score = min(25, quality_retention * 30)
    speed_score = min(25, (speed_improvement - 1) * 15)
    compression_score = min(25, (1 - compression_ratio) * 26.3)  # 95% ì••ì¶•ì‹œ 25ì 
    improvement_score = min(25, quality_improvement * 30)
    
    return quality_score + speed_score + compression_score + improvement_score

if __name__ == "__main__":
    main_extreme() 