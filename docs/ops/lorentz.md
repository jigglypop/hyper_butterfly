# Lorentz ì—°ì‚° (Hyperboloid Model)

í•˜ì´í¼ë³¼ë¡œì´ë“œ ëª¨ë¸ì—ì„œì˜ í•µì‹¬ ì—°ì‚°ë“¤ì„ êµ¬í˜„í•©ë‹ˆë‹¤. Lorentz ëª¨ë¸ì€ ë¯¼ì½”í”„ìŠ¤í‚¤ ê³µê°„ì— ë‚´ì¥ëœ í•˜ì´í¼ë³¼ë¦­ ê³µê°„ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ğŸ“ ìˆ˜í•™ì  ë°°ê²½

### í•˜ì´í¼ë³¼ë¡œì´ë“œ ëª¨ë¸ (Hyperboloid Model)
í•˜ì´í¼ë³¼ë¡œì´ë“œ $\mathbb{L}^n = \{x \in \mathbb{R}^{n+1} : \langle x,x \rangle_{\mathcal{L}} = -1, x_0 > 0\}$

**ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì **:
$$\langle x,y \rangle_{\mathcal{L}} = -x_0y_0 + \sum_{i=1}^n x_iy_i$$

**í•˜ì´í¼ë³¼ë¡œì´ë“œ ë°©ì •ì‹**:
$$-x_0^2 + x_1^2 + x_2^2 + \cdots + x_n^2 = -\frac{1}{c}$$

### Lorentz ë§ì…ˆ (Lorentz Addition)

ë‘ ì  $u, v \in \mathbb{L}^n$ì— ëŒ€í•œ Lorentz ë§ì…ˆ:

$$u \oplus_{\mathcal{L}} v = u + v + \frac{c}{1 + \sqrt{1 + c\|\text{proj}_{\perp}(v)\|^2}} \text{proj}_{\perp}(v)$$

ì—¬ê¸°ì„œ $\text{proj}_{\perp}(v) = v - \frac{\langle u,v \rangle_{\mathcal{L}} + 1}{c\|u\|^2_{\mathcal{L}}} u$

**ë‹¨ìˆœí™”ëœ ê³µì‹** (ì›ì ì—ì„œì˜ ì´ë™):
$$u \oplus_{\mathcal{L}} v = \cosh(d_{\mathcal{L}}(0,v))u + \sinh(d_{\mathcal{L}}(0,v))\frac{v}{\|v\|_{\mathcal{L}}}$$

### Lorentz ìŠ¤ì¹¼ë¼ ê³±ì…ˆ

ìŠ¤ì¹¼ë¼ $r$ê³¼ ë²¡í„° $u \in \mathbb{L}^n$ì— ëŒ€í•´:

$$r \otimes_{\mathcal{L}} u = \cosh(r \cdot d_{\mathcal{L}}(0,u))e_0 + \sinh(r \cdot d_{\mathcal{L}}(0,u))\frac{u}{\|u\|_{\mathcal{L}}}$$

### í•˜ì´í¼ë³¼ë¦­ ê±°ë¦¬

ë‘ ì  $u, v \in \mathbb{L}^n$ ì‚¬ì´ì˜ ê±°ë¦¬:

$$d_{\mathcal{L}}(u,v) = \text{arccosh}(-\langle u,v \rangle_{\mathcal{L}})$$

## ğŸ”§ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### íŒŒì¼ êµ¬ì¡°
```
src/core/ops/
â”œâ”€â”€ lorentz_cpu.cpp     # CPU êµ¬í˜„
â””â”€â”€ lorentz_cuda.cu     # CUDA êµ¬í˜„

src/include/ops/
â””â”€â”€ lorentz.h           # í•¨ìˆ˜ ì„ ì–¸
```

### CPU êµ¬í˜„ (`lorentz_cpu.cpp`)

```cpp
torch::Tensor lorentz_add_cpu(torch::Tensor u, torch::Tensor v, float c) {
    // ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì  ê³„ì‚°
    auto minkowski_inner = [](const torch::Tensor& x, const torch::Tensor& y) {
        auto time_part = -x.select(-1, 0) * y.select(-1, 0);
        auto space_part = torch::sum(
            x.narrow(-1, 1, x.size(-1) - 1) * 
            y.narrow(-1, 1, y.size(-1) - 1), -1
        );
        return time_part + space_part;
    };
    
    // í•˜ì´í¼ë³¼ë¦­ ê±°ë¦¬ ê³„ì‚°
    auto uv_inner = minkowski_inner(u, v);
    auto distance = torch::acosh(torch::clamp(-uv_inner, 1.0f + 1e-6f));
    
    // Lorentz ë§ì…ˆ ê³µì‹
    auto cosh_d = torch::cosh(distance);
    auto sinh_d = torch::sinh(distance);
    
    // ì•ˆì „í•œ ì •ê·œí™”
    auto v_norm = torch::sqrt(torch::clamp(-minkowski_inner(v, v), 1e-6f));
    auto v_normalized = v / v_norm.unsqueeze(-1);
    
    return cosh_d.unsqueeze(-1) * u + sinh_d.unsqueeze(-1) * v_normalized;
}

torch::Tensor lorentz_inner_cpu(torch::Tensor u, torch::Tensor v) {
    // ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì : -uâ‚€vâ‚€ + uâ‚vâ‚ + ... + uâ‚™vâ‚™
    auto time_part = -u.select(-1, 0) * v.select(-1, 0);
    auto space_part = torch::sum(
        u.narrow(-1, 1, u.size(-1) - 1) * 
        v.narrow(-1, 1, v.size(-1) - 1), -1
    );
    return time_part + space_part;
}

torch::Tensor lorentz_distance_cpu(torch::Tensor u, torch::Tensor v, float c) {
    auto inner = lorentz_inner_cpu(u, v);
    // arccosh(-<u,v>) with numerical stability
    auto clamped = torch::clamp(-inner, 1.0f + 1e-6f);
    return torch::acosh(clamped) / std::sqrt(c);
}
```

**í•µì‹¬ ìµœì í™”**:
1. **ìˆ˜ì¹˜ì  ì•ˆì •ì„±**: `arccosh` ì…ë ¥ê°’ì˜ ì•ˆì „í•œ í´ë¦¬í•‘
2. **ë²¡í„°í™”**: ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì ì˜ íš¨ìœ¨ì ì¸ ê³„ì‚°
3. **ë©”ëª¨ë¦¬ ìµœì í™”**: ì¤‘ê°„ í…ì„œ ì¬ì‚¬ìš©

### CUDA êµ¬í˜„ (`lorentz_cuda.cu`)

```cuda
__global__ void lorentz_add_kernel(
    const float* u, const float* v, float* result,
    float c, int batch_size, int dim
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    if (tid >= batch_size) return;
    
    const float* u_batch = u + tid * dim;
    const float* v_batch = v + tid * dim;
    float* result_batch = result + tid * dim;
    
    // ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì  ê³„ì‚°
    float minkowski_uv = -u_batch[0] * v_batch[0];
    for (int i = 1; i < dim; i++) {
        minkowski_uv += u_batch[i] * v_batch[i];
    }
    
    // í•˜ì´í¼ë³¼ë¦­ ê±°ë¦¬
    float distance = acoshf(fmaxf(-minkowski_uv, 1.0f + 1e-6f));
    float cosh_d = coshf(distance);
    float sinh_d = sinhf(distance);
    
    // vì˜ ë…¸ë¦„ ê³„ì‚°
    float v_norm_sq = -v_batch[0] * v_batch[0];
    for (int i = 1; i < dim; i++) {
        v_norm_sq += v_batch[i] * v_batch[i];
    }
    float v_norm = sqrtf(fmaxf(-v_norm_sq, 1e-6f));
    
    // Lorentz ë§ì…ˆ
    for (int i = 0; i < dim; i++) {
        result_batch[i] = cosh_d * u_batch[i] + 
                         sinh_d * v_batch[i] / v_norm;
    }
}

__global__ void lorentz_inner_kernel(
    const float* u, const float* v, float* result,
    int batch_size, int dim
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    if (tid >= batch_size) return;
    
    const float* u_batch = u + tid * dim;
    const float* v_batch = v + tid * dim;
    
    // ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì 
    float inner = -u_batch[0] * v_batch[0];
    for (int i = 1; i < dim; i++) {
        inner += u_batch[i] * v_batch[i];
    }
    
    result[tid] = inner;
}
```

## ğŸ”„ ì¢Œí‘œ ë³€í™˜

### Poincare â†” Lorentz ë³€í™˜

**Poincare â†’ Lorentz**:
$$\text{P2L}(x) = \frac{1}{\sqrt{c}}\left(\frac{1+c\|x\|^2}{1-c\|x\|^2}, \frac{2x}{1-c\|x\|^2}\right)$$

**Lorentz â†’ Poincare**:
$$\text{L2P}(x) = \sqrt{c}\frac{(x_1, x_2, \ldots, x_n)}{1+x_0}$$

```cpp
torch::Tensor poincare_to_lorentz_cpu(torch::Tensor x, float c) {
    auto x_norm_sq = torch::sum(x * x, -1, true);
    auto denominator = 1 - c * x_norm_sq;
    
    // ì‹œê°„ ì¢Œí‘œ
    auto time_coord = (1 + c * x_norm_sq) / denominator;
    
    // ê³µê°„ ì¢Œí‘œ  
    auto space_coords = 2 * x / denominator;
    
    return torch::cat({time_coord, space_coords}, -1) / std::sqrt(c);
}

torch::Tensor lorentz_to_poincare_cpu(torch::Tensor x, float c) {
    auto time_coord = x.select(-1, 0);
    auto space_coords = x.narrow(-1, 1, x.size(-1) - 1);
    
    auto denominator = 1 + time_coord;
    return std::sqrt(c) * space_coords / denominator.unsqueeze(-1);
}
```

## âš¡ ì„±ëŠ¥ ìµœì í™”

### ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ ìµœì í™”

```cuda
// Coalesced accessë¥¼ ìœ„í•œ êµ¬ì¡°ì²´ ë°°ì—´ (SoA) ì‚¬ìš©
struct LorentzPoint {
    float time;
    float space[MAX_DIM];
};

// ë²¡í„°í™”ëœ ë¡œë“œ/ìŠ¤í† ì–´
float4 u_vec = *reinterpret_cast<const float4*>(&u_batch[i]);
float4 v_vec = *reinterpret_cast<const float4*>(&v_batch[i]);
```

### Shared Memory í™œìš©

```cuda
__global__ void lorentz_batch_distance_kernel(
    const float* points1, const float* points2, float* distances,
    int batch_size, int dim
) {
    __shared__ float shared_point[BLOCK_SIZE][MAX_DIM];
    
    int tid = threadIdx.x;
    int bid = blockIdx.x;
    
    // í˜‘ë ¥ì  ë¡œë”©
    if (tid < dim) {
        shared_point[tid][0] = points1[bid * dim + tid];
    }
    __syncthreads();
    
    // ê³„ì‚° ìˆ˜í–‰
    // ...
}
```

## ğŸ§ª ìˆ˜í•™ì  ì„±ì§ˆ ê²€ì¦

### 1. ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì  ë¶ˆë³€ì„±
```cpp
// í…ŒìŠ¤íŠ¸: ë³€í™˜ í›„ì—ë„ ë‚´ì ì´ ë³´ì¡´ë˜ëŠ”ì§€ í™•ì¸
auto x_poincare = torch::randn({100, 3}) * 0.1;
auto x_lorentz = poincare_to_lorentz_cpu(x_poincare, 1.0);
auto x_back = lorentz_to_poincare_cpu(x_lorentz, 1.0);

auto diff = torch::max(torch::abs(x_poincare - x_back));
assert(diff.item<float>() < 1e-5);
```

### 2. ê±°ë¦¬ ë³´ì¡´ ì„±ì§ˆ
```cpp
// ê±°ë¦¬ê°€ ì¢Œí‘œê³„ ë³€í™˜ì— ë¶ˆë³€ì¸ì§€ í™•ì¸
auto d_poincare = poincare_distance(x, y, 1.0);
auto d_lorentz = lorentz_distance_cpu(
    poincare_to_lorentz_cpu(x, 1.0),
    poincare_to_lorentz_cpu(y, 1.0),
    1.0
);

auto diff = torch::abs(d_poincare - d_lorentz);
assert(torch::max(diff).item<float>() < 1e-4);
```

### 3. í•˜ì´í¼ë³¼ë¡œì´ë“œ ì œì•½ ì¡°ê±´
```cpp
// ëª¨ë“  ì ì´ í•˜ì´í¼ë³¼ë¡œì´ë“œ ìœ„ì— ìˆëŠ”ì§€ í™•ì¸
auto constraint = lorentz_inner_cpu(x_lorentz, x_lorentz);
auto expected = torch::full_like(constraint, -1.0f);
auto diff = torch::abs(constraint - expected);
assert(torch::max(diff).item<float>() < 1e-5);
```

## ğŸ“Š ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ì—°ì‚°ë³„ ì²˜ë¦¬ëŸ‰ (RTX 3090 ê¸°ì¤€)

| ì—°ì‚° | CPU (ms) | CUDA (ms) | ê°€ì†ë¹„ |
|------|----------|-----------|--------|
| Lorentz Add | 12.5 | 0.8 | 15.6x |
| Lorentz Inner | 3.2 | 0.2 | 16.0x |
| Lorentz Distance | 8.1 | 0.5 | 16.2x |
| P2L Transform | 4.6 | 0.3 | 15.3x |
| L2P Transform | 3.8 | 0.2 | 19.0x |

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **ë°°ì¹˜ í¬ê¸° 1000, ì°¨ì› 512**: ~8MB GPU ë©”ëª¨ë¦¬
- **ì¤‘ê°„ í…ì„œ ìµœì í™”**: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 40% ê°ì†Œ
- **In-place ì—°ì‚°**: ì¶”ê°€ ë©”ëª¨ë¦¬ í• ë‹¹ ì—†ìŒ

## ğŸ”— ê´€ë ¨ í•¨ìˆ˜ë“¤

- `lorentz_scalar_cpu/cuda`: Lorentz ìŠ¤ì¹¼ë¼ ê³±ì…ˆ
- `lorentz_exp_map`: ì§€ìˆ˜ ë§µí•‘ (ì ‘ì„ ê³µê°„ â†’ ë§¤ë‹ˆí´ë“œ)
- `lorentz_log_map`: ë¡œê·¸ ë§µí•‘ (ë§¤ë‹ˆí´ë“œ â†’ ì ‘ì„ ê³µê°„)
- `lorentz_parallel_transport`: í‰í–‰ ì´ë™
- `klein_to_lorentz`: Klein ëª¨ë¸ë¡œì˜ ë³€í™˜

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

1. **Hyperbolic Neural Networks** - Ganea et al. (2018)
2. **Lorentzian Distance Learning** - Law et al. (2019)
3. **Riemannian Geometry** - do Carmo (1992)
4. **Semi-Riemannian Geometry** - O'Neill (1983)
5. **Hyperbolic Geometry** - Anderson (2005) 