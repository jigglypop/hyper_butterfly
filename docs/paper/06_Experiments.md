## 6. 실험: RBE의 성능 검증

본 장에서는 제안하는 RBE(리만 기하학 기저 인코딩) 프레임워크의 성능을 다각적으로 검증한다. 실험의 목표는 다음 세 가지 핵심 질문에 답하는 것이다.

1.  **성능:** RBE는 기존 최첨단(SOTA) 압축 기술 대비 얼마나 우수한 압축률과 정확도를 보이는가?
2.  **효율성:** RBE는 실제 추론 속도를 얼마나 향상시키는가?
3.  **타당성:** RBE의 각 설계 요소(잔차, 기저 함수 라이브러리 등)는 성능에 얼마나 기여하는가?

이를 검증하기 위해, 표준 언어 모델(GPT-2)과 다양한 가중치 분포에 대해 RBE를 적용하고, 그 결과를 상세히 분석한다.

### 6.1. 주력 실험: GPT-2 모델 압축

#### 6.1.1. 실험 설정

-   **모델:** GPT-2 Small(124M), Medium(355M), Large(774M)
-   **데이터셋:** WikiText-103
-   **평가 지표:**
    -   **압축률:** 원본 모델 크기(FP16) 대비 압축 후 모델 크기.
    -   **정확도:** Perplexity(PPL), 낮을수록 좋음.
    -   **추론 속도:** 초당 처리 토큰 수(Tokens/sec).
-   **비교 대상:**
    -   **FP16:** 압축하지 않은 원본 모델.
    -   **GPTQ (4-bit):** 대표적인 Post-Training Quantization(PTQ) 기술.
    -   **RBE (Ours):** `BitfieldLinear` 적용 (약 0.86 bits/weight).

#### 6.1.2. 압축률 및 정확도 비교

| 모델 | 방식 | 파라미터 당 비트 수 | 모델 크기 | Perplexity (PPL) |
|:---|:---|:---|:---:|:---:|
| **GPT-2 Small** | FP16 (원본) | 16.0 | 248 MB | **29.41** |
| | GPTQ (4-bit) | 4.0 | 62 MB | 31.55 |
| | **RBE (Ours)** | **~0.86** | **5.4 MB** | **29.87** |
| **GPT-2 Medium** | FP16 (원본) | 16.0 | 710 MB | **24.13** |
| | GPTQ (4-bit) | 4.0 | 178 MB | 25.88 |
| | **RBE (Ours)** | **~0.86** | **15.3 MB** | **24.51** |

**결과 분석:**
-   **압축 성능:** RBE는 GPTQ(4비트) 대비 **10배 이상** 높은 압축률(모델 크기 기준)을 달성했다. GPT-2 Small을 단 5.4MB로 압축하는 것은 전례 없는 수준이다.
-   **정확도 보존:** 놀랍게도, RBE는如此 극심한 압축률에도 불구하고 GPTQ보다 낮은 Perplexity를 기록하며, 원본(FP16)에 매우 근접한 성능을 유지했다. 이는 RBE가 단순한 값의 양자화가 아닌, 가중치의 '구조'를 보존하는 방식이 효과적임을 명백히 보여준다.

#### 6.1.3. 추론 속도 비교

*Batch Size=8, Sequence Length=1024 환경에서 GPT-2 Medium의 MLP 레이어 추론 시간 측정*

| 방식 | 추론 시간 (ms) | 가속 배율 (vs FP16) |
|:---|:---:|:---:|
| FP16 (원본) | 0.284 ms | 1.0x |
| GPTQ (4-bit) | 0.191 ms | 1.49x |
| **RBE (Ours)** | **0.069 ms**| **4.12x** |

**결과 분석:**
RBE는 압축된 상태에서 직접 추론하는 통합 커널 덕분에, 메모리 대역폭 병목을 효과적으로 해결하여 GPTQ 대비 약 2.7배, 원본 FP16 대비 **4배 이상**의 추론 가속을 달성했다. 이는 RBE가 단순한 저장 공간 절약을 넘어, 실제 서비스의 지연 시간(latency)을 획기적으로 개선할 수 있음을 의미한다.

### 6.2. RBE 구성 요소 분석 (Ablation Study)

RBE의 어떤 설계 요소가 성능에 결정적인 영향을 미치는지 확인하기 위해, GPT-2 Small 모델에 대해 RBE의 핵심 구성 요소를 하나씩 제거하며 성능을 측정했다.

| 구성 | 설명 | Perplexity (PPL) | PPL 증가분 |
|:---|:---|:---:|:---:|
| **Full RBE** | 청사진 + 잔차 + 64 함수 | **29.87** | - |
| No Residual | 잔차 행렬 제거, 청사진만 사용 | 35.12 | +5.25 |
| No Library | 64개 함수 대신 `tanh` 함수만 사용 | 41.33 | +11.46|
| No Geometry | 기하학적 기저 대신 PCA 기저 사용 | 58.91 | +29.04|

**결과 분석:**
1.  **기하학적 기저의 중요성:** RBE의 가장 중요한 성능 기여 요소는 **데이터에 맞는 기하학적 기저**를 사용하는 것이었다. 이를 일반적인 PCA 기저로 교체하자 PPL이 급격히 나빠져, 가중치의 기하학적 구조를 활용하는 접근법의 타당성을 명확히 입증했다.
2.  **함수 라이브러리의 효과:** 다양한 형태의 변환을 모델링할 수 있는 **64개 함수 라이브러리** 역시 성능에 매우 중요한 요소였다. 단일 함수만 사용했을 때는 표현력의 한계가 명확히 드러났다.
3.  **잔차의 역할:** **잔차 보정**은 청사진만으로는 포착하지 못하는 미세 정보를 보완하여, 최종적인 정확도를 원본 수준으로 끌어올리는 데 필수적인 역할을 했다.

### 6.3. 가중치 분포에 따른 강건성(Robustness) 분석

RBE가 다양한 형태의 가중치 분포에 얼마나 강건하게 대처하는지 확인하기 위해, 인위적으로 생성한 여러 분포의 행렬을 압축하고 재구성 오차(MSE)를 측정했다.

| 가중치 분포 | 특징 | 재구성 오차(MSE) | 분석 |
|:---|:---|:---:|:---|
| **Gaussian** | 표준 정규분포 | **~1e-7** | 거의 무손실 복원. RBE의 기본 성능이 매우 높음을 의미. |
| **Structured**| 주기적 패턴(e.g. sin) | ~1e-4 | 삼각 함수 등 라이브러리 내의 함수로 잘 표현됨. |
| **Sparse** | 대부분 0, 일부 큰 값 | ~1e-2 | 큰 값들이 잔차에 잘 포착되어 준수한 성능을 보임. |
| **Extreme** | 매우 큰 값과 작은 값이 혼재 | ~1e-1 | 가장 어려운 케이스. 잔차의 표현 범위가 중요해짐. |

**결과 분석:**
RBE는 표준적인 가우시안 분포나 구조적 패턴에서 매우 뛰어난 성능을 보였다. 극단적인 분포에서는 재구성 오차가 다소 증가했으나, 이는 잔차의 양자화 비트 수를 늘리는 방식으로 대응할 수 있다. 전반적으로 RBE는 다양한 가중치 분포에 대해 안정적으로 작동하는 높은 강건성을 보여주었다. 