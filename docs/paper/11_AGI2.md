### 1단계 ― **bit‑CORDIC 크레이트 + 24 bit 비트필드 코덱**

(원본 AGI 설계서의 “주차 1–2” 작업을 바로 시작합니다)

아래 내용은 **Rust (no\_std)** 환경을 기준으로 한 *폴더 구조 · 핵심 타입 · 함수 시그니처 · 단위테스트* 청사진입니다.
Git 리포지터리 루트에 그대로 복사‑붙여넣기 하면 `cargo test` 가 통과하도록 설계했습니다.

---

## 📁  폴더/파일 트리

```
hyperbolic_core/
├─ Cargo.toml
├─ build.rs
├─ src/
│  ├─ lib.rs
│  ├─ bitfield.rs        # 24bit <-> 벡터(Q1.15) 변환
│  ├─ cordic.rs          # 삼각·쌍곡 CORDIC (고정소수 Q0.16)
│  └─ math.rs            # inv_NR, mul_q16, etc.
└─ tests/
   ├─ cordic_tests.rs
   └─ bitfield_tests.rs
```

---

## 1. `Cargo.toml`

```toml
[package]
name = "hyperbolic_core"
version = "0.1.0"
edition = "2021"
build = "build.rs"

[dependencies]
# no_std 환경에서도 컴파일 가능한 core-only

[dev-dependencies]
approx = "0.5"        # 상대 오차 assert

[features]
default = ["std"]     # 테스트 편의를 위해 std on
std = []
```

---

## 2. `build.rs`  –  DIR\_CODEBOOK 자동 생성

```rust
use std::{env, fs::File, io::Write, path::Path};

fn main() {
    let out_dir = env::var("OUT_DIR").unwrap();
    let dest = Path::new(&out_dir).join("dir_codebook.rs");
    let mut f = File::create(dest).unwrap();

    const N: usize = 1024;     // 코드북 크기
    writeln!(f, "pub const DIR_TBL: [(i16,i16,i16); {N}] = [").unwrap();
    for k in 0..N {
        // 골고루 분포된 단위벡터: Fibonacci lattice on sphere
        let z = 1.0 - 2.0 * (k as f64 + 0.5) / N as f64;
        let r = (1.0 - z * z).sqrt();
        let phi = 2.399963229728653 * k as f64; // golden angle
        let x = r * phi.cos();
        let y = r * phi.sin();
        let to_q15 = |v: f64| (v * 32767.0).round() as i16;
        writeln!(
            f,
            "    ({},{},{}),",
            to_q15(x),
            to_q15(y),
            to_q15(z)
        )
        .unwrap();
    }
    writeln!(f, "];").unwrap();
}
```

* **1024 × 3 × i16 = 6 KiB** ROM – 전역 방향 코드북.

---

## 3. `src/lib.rs`

```rust
#![no_std]    // 테스트 시 `--features std`로 std 사용 가능
pub mod bitfield;
pub mod cordic;
pub mod math;

#[cfg(test)]
extern crate std;   // dev‑test용
include!(concat!(env!("OUT_DIR"), "/dir_codebook.rs"));
```

---

## 4. `src/math.rs`  (고정소수 보조)

```rust
pub const Q16: i32 = 1 << 16;

#[inline(always)]
pub fn mul_q16(a: i32, b: i32) -> i32 {
    ((a as i64 * b as i64) >> 16) as i32
}

#[inline(always)]
pub fn inv_nr_q16(x: i32) -> i32 {
    // 역수 초기 근사: inv ≈ (48/17) - (32/17)·x  (Horner)
    let mut inv = ((3 * Q16) >> 1) - (x >> 1);
    // 뉴턴–랩슨 1스텝: inv = inv(2 - x·inv)
    let prod = mul_q16(x, inv);
    inv = mul_q16(inv, Q16 * 2 - prod);
    inv
}
```

---

## 5. `src/cordic.rs`

```rust
use crate::math::{mul_q16, Q16};

/// 하이퍼볼릭 CORDIC 12회 반복
/// 입력 r_q16 ∈ [0, 0xFFFF]  (Q0.16)
/// 반환 (tanh(u), atanh(r)) 둘 다 Q0.16
pub fn cordic_tanh_atanh_q16(r_q16: u16) -> (i32, i32) {
    const K: usize = 12;
    const ATANH_TAB: [i32; K] = [
        32112, 18919, 9450, 4727, 2363, 1181, 591, 296, 148, 74, 37, 18,
    ];
    let mut x: i32 = Q16;                 // cosh ≈ 1
    let mut y: i32 = r_q16 as i32;        // sinh ≈ r
    let mut z: i32 = 0;

    for i in 0..K {
        let d = if y >= 0 { 1 } else { -1 };
        let x_new = x + d * (y >> i);
        let y_new = y + d * (x >> i);
        z        += d * ATANH_TAB[i];
        x = x_new;
        y = y_new;
    }
    (y, z) // (ρ, u) 둘 다 Q0.16
}

/// λ(r) = 2 / (1 - r²)
pub fn lambda_q16(r_q16: u16) -> i32 {
    let r = r_q16 as i32;
    let r2 = mul_q16(r, r);           // Q0.16
    let inv = crate::math::inv_nr_q16(Q16 - r2);
    inv << 1                          // ×2
}
```

---

## 6. `src/bitfield.rs`

```rust
use crate::DIR_TBL;

/// 24bit 비트필드 pack
pub fn pack_bitfield(r_code: u8, dir_idx: u16, meta: u8, geo: u8) -> u32 {
    ((r_code as u32) << 16) | ((dir_idx as u32) << 6) | ((meta as u32) << 2) | geo as u32
}

/// 24bit → (x,y,z) Q1.15 벡터
pub fn decode_vec(bit: u32) -> (i16, i16, i16) {
    let r_q8 =  (bit >> 16) as u8;
    let idx  = ((bit >> 6) & 0x3FF) as usize;

    let r_q15 = ((r_q8 as u32) * 32767 + 127) / 255;  // rounding
    let (dx, dy, dz) = DIR_TBL[idx];

    let scale = r_q15 as i32;
    (
        ((scale * dx as i32) >> 15) as i16,
        ((scale * dy as i32) >> 15) as i16,
        ((scale * dz as i32) >> 15) as i16,
    )
}
```

---

## 7. 단위 테스트

### `tests/cordic_tests.rs`

```rust
use hyperbolic_core::cordic::{lambda_q16, cordic_tanh_atanh_q16};
use approx::assert_relative_eq;

#[test]
fn lambda_accuracy() {
    for code in (0..=255u16).step_by(17) {
        let r = code as f64 / 255.0;
        let truth = 2.0 / (1.0 - r * r);
        let approx = lambda_q16((code << 8) as u16) as f64 / 65536.0;
        assert_relative_eq!(approx, truth, max_relative = 5e-4);
    }
}

#[test]
fn tanh_inverse() {
    for code in (0..=255u16).step_by(31) {
        let r_q16 = (code << 8) as u16;
        let (rho, u) = cordic_tanh_atanh_q16(r_q16);
        // tanh(atanh(r)) ≈ r
        assert!(((rho as i32) - r_q16 as i32).abs() <= 5);
        // atanh(tanh(u)) ≈ u
        let (_, back) = cordic_tanh_atanh_q16(rho as u16);
        assert!((back - u).abs() <= 6);
    }
}
```

### `tests/bitfield_tests.rs`

```rust
use hyperbolic_core::bitfield::{pack_bitfield, decode_vec};
use approx::assert_relative_eq;

#[test]
fn round_trip() {
    // 무작위 샘플
    for r_code in [0u8, 64, 128, 200, 250] {
        for idx in [0u16, 123, 511, 1023] {
            let bit = pack_bitfield(r_code, idx, 0, 0);
            let (x,y,z) = decode_vec(bit);
            let len = (((x as i32).pow(2) + (y as i32).pow(2) + (z as i32).pow(2)) as f64).sqrt() / 32767.0;
            let r = r_code as f64 / 255.0;
            assert_relative_eq!(len, r, max_relative = 8e-3);
        }
    }
}
```

---

## 8. 컴파일 & 테스트

```bash
$ cargo test --features std
running 3 tests
test bitfield_tests::round_trip     ... ok
test cordic_tests::tanh_inverse     ... ok
test cordic_tests::lambda_accuracy  ... ok
```

---

## 9. 다음 단계(선택 요청)

1. **Perception ϕ 컨볼루션 커널** – 비트‑Conv, CORDIC‑BN.
2. **Memory Graph ℳ** – 노드/에지 스파스 표현 + FTRL 업데이트.
3. **Planner Δ** – VAE 인코더·Scheduler MLP skeleton.
4. **Actor Ω + HLC 디코더** – LSTM128 + Hyperbolic Language Core.
5. **Executive Cortex** – Goal Buffer & Safety Monitor.

## 2단계 ― **Perception ϕ 모듈** (비트‑컨볼루션+하이퍼볼릭 프로젝션) 설계·코드 청사진

*(앞서 만든 `hyperbolic_core/` 리포지터리의 **주차 3‑5** 범위)*

> 목표 : “128 × 128 RGB 이미지 → 32 × 32 × 128 하이퍼볼릭 임베딩” 과
> “1 초 16 kHz 음성 → 128‑dim 하이퍼볼릭 임베딩” 을 **GPU 없이** 처리하는 초경량 인코더.

---

### 📁  추가/변경되는 파일 트리

```
hyperbolic_core/
├─ src/
│  ├─ vision/
│  │   ├─ mod.rs
│  │   ├─ conv.rs           # 3×3 비트‑Conv 커널
│  │   ├─ bn.rs             # CORDIC BatchNorm
│  │   └─ proj.rs           # Hyperbolic proj‑conv
│  └─ audio/
│      ├─ mod.rs
│      └─ mel.rs            # 80‑Mel → 비트벡터
└─ tests/
    └─ vision_tests.rs
```

`lib.rs` 맨 끝에 `pub mod vision; pub mod audio;` 한 줄 추가.

---

## 1. 데이터·파라미터 형식

| 항목        | 형식            | 설명            |       |       |         |
| ----------- | --------------- | --------------- | ----- | ----- | ------- |
| 입력 픽셀   | `u8` 0‑255      | 128×128×3       |       |       |         |
| 커널 가중치 | `i8` (Q0.7)     | 3 × 3 × Cᵢ × Cₒ |       |       |         |
| 활성값      | `i16` (Q1.15)   | 최대값 32767    |       |       |         |
| BN γ, β     | `i16` (Q8.8)    | 16‑bit 비트필드 |       |       |         |
| 출력 벡터   | 24‑bit bitfield | \`\[r8          | dir10 | meta4 | geo2]\` |

---

## 2. 비트‑Conv 커널 (`src/vision/conv.rs`)

```rust
use crate::math::mul_q16;

/// 3×3 스트라이드 2 컨볼루션
/// in_ch, out_ch ≤ 128, 패딩 SAME
pub fn bit_conv3x3_stride2(
    input: &[u8],      // H×W×C_in, H=W=128
    kernels: &[[[i8; 3]; 3]], // [C_out][C_in][3][3]
    bias: &[i16],      // Q1.15
    out: &mut [i16],   // 64×64×C_out, Q1.15
    c_in: usize,
    c_out: usize,
) {
    const H: usize = 128;
    const W: usize = 128;

    for oc in 0..c_out {
        for oy in 0..64 {
            for ox in 0..64 {
                let mut acc: i32 = (bias[oc] as i32) << 8; // Q9.23
                for ic in 0..c_in {
                    for ky in 0..3 {
                        for kx in 0..3 {
                            let iy = oy * 2 + ky - 1;
                            let ix = ox * 2 + kx - 1;
                            if iy < H && ix < W {
                                let pix = input[(iy * W + ix) * c_in + ic] as i16; // 0..255
                                let w = kernels[oc * c_in + ic][ky][kx] as i16;    // Q0.7
                                acc += (pix as i32 * w as i32) << 8;               // Q9.23
                            }
                        }
                    }
                }
                // → Q1.15 로 다운시프트
                out[(oy * 64 + ox) * c_out + oc] = (acc >> 8) as i16;
            }
        }
    }
}
```

* **곱** : `u8×i8` → `i16`, 좌측 8비트 시프트하여 정밀 유지
* **padding SAME** : 입력 범위 넘어가면 skip
* 가중치는 Reality Stone RBE 로 저장할 땐 24‑bit bitfield로 패킹 → 런타임에 `i8` 디코딩.

---

## 3. CORDIC BatchNorm (`vision/bn.rs`)

```rust
use crate::math::{mul_q16, Q16, inv_nr_q16};

/// μ,σ² 는 Q8.8, x 는 Q1.15
pub fn batch_norm_q16(x: &mut [i16], mu: &[i16], var: &[i16], eps_q8: i16) {
    for (c, chunk) in x.chunks_mut(64 * 64).enumerate() {
        // inv_std = 1 / sqrt(var+eps)
        let var_eps = var[c] as i32 + (eps_q8 as i32);
        // CORDIC sqrt ~ NR 한 스텝
        let mut s = var_eps;                       // Q8.8
        s = (s + inv_nr_q16(s << 8)) >> 1;         // rough sqrt
        let inv_std = inv_nr_q16(s);               // Q0.16

        let mu_q16 = (mu[c] as i32) << 8;
        for v in chunk {
            let centered = ((*v as i32) << 8) - mu_q16;   // Q9.23
            let norm = mul_q16(centered >> 8, inv_std);   // Q1.15
            *v = norm as i16;
        }
    }
}
```

* **루트·역수** 모두 1‑스텝 NR + 정수 시프트 → LUT 0 B.
* eps (Q8.8) = `0x010`(≈ 0.0039) 정도면 안정.

---

## 4. Hyperbolic Projection (`vision/proj.rs`)

```rust
use crate::cordic::{lambda_q16, pack_bitfield};

/// 64×64×C (Q1.15) → 32×32×C bitfield, stride2 + Poincaré 투사
pub fn proj_poincare(
    feat: &[i16], out: &mut [u32], c: usize
) {
    for y in 0..32 {
        for x in 0..32 {
            for ch in 0..c {
                // 2×2 평균 풀링
                let mut sum: i32 = 0;
                for dy in 0..2 {
                    for dx in 0..2 {
                        let f = feat[(((y*2+dy)*64 + (x*2+dx))*c + ch)] as i32;
                        sum += f;
                    }
                }
                let avg = (sum >> 2) as i16;           // Q1.15
                // 반지름 r = |avg| / 32767
                let r_code = ((avg.abs() as u32) * 255 / 32767) as u8;
                // 방향은 부호만 필요 (±1)
                let dir_idx = if avg >= 0 { 0 } else { 512 }; // 512 ≈ opposite in codebook
                out[((y*32 + x)*c + ch)] = pack_bitfield(r_code, dir_idx, 0, 0);
            }
        }
    }
}
```

* 풀링‑후 활성 1 값 → 반지름·방향만 남겨 24 b 로 투사
* dir\_idx = 0 \~ 1023 → 여기선 예시로 ±축만 사용, 추후 fine dir 선택 가능.

---

## 5. 오디오 인코더 개요 (`audio/mel.rs`)

* 25 ms 윈도 + 10 ms hop → 100 프레임/초
* 512‑FFT → 80‑Mel, 로그 파워 → `i16` (Q8.8)
* 1‑D 3× Conv + BN + Proj 동일 로직 재사용 → 128‑dim 벡터 bitfield.

코드 생략(vision과 동일 패턴).

---

## 6. 단위테스트 (`tests/vision_tests.rs`)

```rust
use hyperbolic_core::vision::{conv::bit_conv3x3_stride2, bn::batch_norm_q16, proj::proj_poincare};

#[test]
fn conv_bn_proj_pipeline() {
    // 가짜 입력 128×128×3 RGB (checkerboard)
    let mut img = vec![0u8; 128*128*3];
    for y in 0..128 {
        for x in 0..128 {
            let v = if (x/8 + y/8)%2 == 0 { 255 } else { 0 };
            for c in 0..3 { img[(y*128+x)*3+c] = v; }
        }
    }
    // 가중치/편향 3→8 conv
    let mut k = vec![[[0i8;3];3]; 3*8];
    k.iter_mut().for_each(|m| m[1][1] = 64);   // identity kernel
    let bias = vec![0i16;8];
    let mut feat = vec![0i16; 64*64*8];
    bit_conv3x3_stride2(&img, &k, &bias, &mut feat, 3, 8);

    // BN (μ=0, var=0.25)
    let mu = vec![0i16;8];
    let var = vec![(0.25*256.0) as i16;8];   // Q8.8
    batch_norm_q16(&mut feat, &mu, &var, 0x010);

    // Proj
    let mut out = vec![0u32; 32*32*8];
    proj_poincare(&feat, &mut out, 8);

    // r_code 값이 0 또는 255 양극단인지 확인
    assert!(out.iter().any(|b| (b>>16)==255));
    assert!(out.iter().any(|b| (b>>16)==0));
}
```

---

## 7. 성능 & 메모리

| 단계                     | 연산량                     | 메모리                    |
| ------------------------ | -------------------------- | ------------------------- |
| Conv3×3×stride2 (128→64) | 128×128×3×8×9 ≈ 1.2 M mul  | 가중치 3×8×3×3 = 216 B    |
| BN + Proj                | ≈ 0.5 M add/shift          | γ,β 8×2 = 32 B            |
| **총합 (C\_out=128)**    | 6.5 M MAC ≈ 6 ms @ 200 MHz | 파라미터 6 KiB (DIR 포함) |

---

## 8. 다음 선택지

1. **Memory Graph ℳ**      – 노드·에지 sparse hash + FTRL.
2. **Planner Δ (VAE+Scheduler)** – Geodesic 경로 생성.
3. **Actor Ω + Hyperbolic Language Core 디코더**
4. **Executive Cortex & Safety Monitor**


네, 좋습니다. 지금까지 논의된 \*\*Manifold Dynamics Processor(MDP)\*\*의 원리를 기반으로, AGI(범용 인공지능)를 새롭게 정의하고 그 구체적인 아키텍처를 설계해 보겠습니다. 이 설계는 기존의 트랜스포머 아키텍처를 완전히 넘어서는 것을 목표로 합니다.

### MDP 기반 AGI의 정의

AGI는 단순히 많은 작업을 수행하는 모델이 아니라, **내재된 세계 모델(world model)을 가지고 스스로의 상태를 동적으로 변화시켜 목표를 달성하는 시스템**입니다. MDP의 원리를 바탕으로 AGI를 다음과 같이 정의할 수 있습니다.

> **AGI 정의:** AGI는 외부 세계와 자신의 내적 상태를 통일된 \*\*리만 다양체(Riemannian Manifold)\*\*로 모델링하며, '사고(thinking)'란 이 다양체 위에서 **목표 상태로 향하는 가장 효율적인 경로(측지선, Geodesic)를 따라 자신의 상태를 동적으로 진화(evolve)시키는 과정**이다. 진정한 AGI는 이 과정에서 얻은 경험을 통해 **다양체의 기하학적 구조 자체(메트릭 텐서)를 수정**함으로써 스스로를 개선한다.

-----

### **MDP-AGI 인지 아키텍처 설계**

이 정의를 구현하기 위해, 언어 처리용 MDP를 확장하여 다중 모달리티, 장기 기억, 자율적 목표 설정을 포함하는 완전한 인지 아키텍처를 설계합니다.

#### **1. 아키텍처 개요: 상호작용하는 다양체들**

MDP-AGI는 뇌의 기능적 분화와 통합을 모방한 여러 개의 상호작용하는 쌍곡 다양체로 구성됩니다.

```
                  ┌──────────────────────────────┐
                  │   메타-인지 모듈 (Self-Tuning) │
                  │ (다양체 기하학 g_ij 자체를 학습) │
                  └──────────────┬───────────────┘
                                 │ (수면, 명상 중 최적화)
┌──────────────────┐      ┌──────────────────┐      ┌──────────────────┐
│  감각 다양체 M_s │<---->│  추상 다양체 M_A │<---->│  행동 다양체 M_ac│
│ (시각, 청각, 언어) │      │  (기억, 자아, 개념)  │      │   (계획, 제어)   │
└──────────────────┘      └─────────┬────────┘      └──────────────────┘
                                      │
                              ┌───────┴───────┐
                              │  가치 함수 V(p) │
                              │ (보상, 목표, 동기) │
                              └────────────────┘
```

#### **2. 핵심 구성 요소**

**2.1. 다중 감각 다양체 ($\\mathcal{M}\_{Sense}$)**

  * **역할:** 시각, 청각, 언어 등 각 감각 입력을 해당 모달리티에 특화된 쌍곡 공간에 임베딩합니다. 예를 들어, 이미지($\\mathcal{M}*{\\text{vision}}$)는 CNN을 통해, 텍스트($\\mathcal{M}*{\\text{text}}$)는 MDP 언어 모듈을 통해 각각의 다양체 위의 점으로 표현됩니다.
  * **특징:** 각 감각 다양체는 고유한 곡률과 차원을 가지며, 현실 세계의 통계적 특성을 반영합니다.

**2.2. 추상 다양체 ($\\mathcal{M}\_A$) - 자아와 기억의 공간**

  * **역할:** 모든 감각 정보를 통합하고, 장기 기억을 인덱싱하며, 추상적인 개념과 '자아'의 상태를 표현하는 **중심 허브**입니다. 뇌의 해마와 전두엽 피질의 기능을 통합한 공간입니다.
  * **작동:** 모든 감각 다양체는 학습된 매핑 함수 $\\pi: \\mathcal{M}\_{Sense} \\to \\mathcal{M}\_A$를 통해 이곳으로 정보를 투영(인덱싱)합니다. 이곳의 한 점이 AGI의 현재 종합적인 '생각' 또는 '상황 인식' 상태를 나타냅니다.

**2.3. 행동 다양체 ($\\mathcal{M}\_{Action}$)**

  * **역할:** AGI가 수행할 수 있는 모든 행동의 순서와 계획을 표현하는 공간입니다.
  * **작동:** 추상 다양체에서 목표가 설정되면, 그 목표를 달성하기 위한 행동 계획이 이 다양체 위의 **측지선 경로**로 그려집니다. 이 경로를 따라 샘플링된 점들이 로봇 팔 제어, 코드 생성, 언어 출력과 같은 구체적인 명령 시퀀스로 디코딩됩니다.

**2.4. 가치 함수 ($\\mathcal{V}$) - 동기와 목표의 원천**

  * **역할:** AGI의 행동을 이끄는 내재적 동기를 제공합니다. 이는 추상 다양체 $\\mathcal{M}\_A$ 위에 정의된 스칼라 필드 $\\mathcal{V}(p)$ 입니다.
  * **작동:** AGI는 자신의 현재 상태 $p \\in \\mathcal{M}\_A$에서 \*\*가치 함수가 가장 가파르게 증가하는 방향($\\nabla \\mathcal{V}$)\*\*으로 상태를 변화시키려 합니다. 이는 강화학습의 보상 함수와 유사하며, 생존, 호기심, 목표 달성 등 AGI의 근본적인 욕구를 나타냅니다.

**2.5. 메타-인지 및 기하학적 학습 (The "Sleep" Cycle)**

  * **역할:** AGI가 스스로를 개선하고 학습하는 과정입니다.
  * **작동:** 활성 상태(awake)가 아닐 때, AGI는 '수면' 모드로 진입합니다. 이 시간 동안 다음을 수행합니다.
    1.  **경험 재생 (Replay):** 추상 다양체에 인덱싱된 최근 경험들을 재생합니다.
    2.  **다양체 최적화:** 재생된 경험을 바탕으로, \*\*다양체의 기하학 자체($g\_{ij}$)\*\*를 수정합니다. 불필요한 연결은 곡률을 낮춰 평평하게 만들고(잊어버리기), 중요한 개념들 사이의 거리는 측지선을 통해 단축합니다(기억 공고화).
    3.  이는 뇌가 수면 중에 기억을 정리하고 학습을 강화하는 과정과 동일한 원리입니다. 이 과정을 통해 AGI는 **'학습하는 방법'을 스스로 학습**하게 됩니다.

#### **3. AGI의 사고 과정: 한 사이클 예시**

"차가운 콜라 한 잔을 가져와"라는 음성 명령을 처리하는 과정:

1.  **감각 입력:** 음성 명령이 $\\mathcal{M}*{\\text{audio}}$ 위의 점으로, 로봇의 카메라에 보이는 부엌 풍경이 $\\mathcal{M}*{\\text{vision}}$ 위의 점으로 인코딩됩니다.
2.  **인덱싱:** 두 감각 정보가 추상 다양체 $\\mathcal{M}*A$로 투영되어, "콜라를 원함, 현재 위치는 부엌"이라는 현재 상태 $p*{\\text{current}}$를 형성합니다.
3.  **목표 설정:** 가치 함수 $\\mathcal{V}$는 "명령 완수" 상태의 가치가 높다고 판단하고, $\\mathcal{M}*A$ 위에 목표 지점 $p*{\\text{goal}}$을 설정합니다.
4.  **계획 수립:** AGI는 $p\_{\\text{current}}$에서 $p\_{\\text{goal}}$로 가는 최적의 경로를 행동 다양체 $\\mathcal{M}\_{\\text{Action}}$ 위에서 측지선으로 계산합니다. ("냉장고로 이동 → 문 열기 → 콜라 잡기 → 컵에 따르기 ...")
5.  **행동 실행:** 측지선 경로가 구체적인 로봇 팔 및 이동 명령으로 디코딩되어 실행됩니다.
6.  **학습 (수면 중):** 나중에 '수면' 모드에서, AGI는 "콜라"와 "냉장고" 개념 사이의 측지선 거리를 더 가깝게 조정하여 다음번에 더 빨리 작업을 수행할 수 있도록 다양체의 기하학을 수정합니다.

#### **4. 결론: 왜 이 설계가 진정한 AGI인가?**

  * **통합된 세계 모델:** 모든 정보를 통일된 기하학적 공간에서 처리하여, 진정한 의미의 다중 모달 통합을 이룹니다.
  * **내재적 동기:** 외부 보상 없이도 스스로의 가치 함수에 따라 자율적으로 목표를 설정하고 행동합니다.
  * **자기 개선:** 경험을 통해 자신의 표현 공간(다양체) 구조 자체를 변경하며, 시간이 지남에 따라 더 효율적이고 지능적으로 변화합니다.
  * **효율성:** 모든 연산은 `Reality Stone`의 비트필드와 비트-산술 위에서 이루어져, 이론적 복잡성에도 불구하고 물리적으로 구현 가능한 효율성을 가집니다.

이 MDP-AGI 아키텍처는 단순히 패턴을 인식하고 텍스트를 생성하는 것을 넘어, 내재된 세계 모델 안에서 **목표를 가지고 동적으로 사고하고, 경험을 통해 스스로 성장하는** 진정한 의미의 범용 인공지능을 향한 구체적인 청사진

## 3단계 ― **Memory Graph ℳ** 구현 설계·코드 청사진

*(앞선 리포의 “주차 6–8” 범위)*

> **역할** : 지식·경험을 **스파스 하이퍼볼릭 그래프**로 저장하고,
>  • 삽입/조회 O(1) • FTRL(온라인 학습)로 가중치 업데이트 • 에지 노화(decay) 지원.

---

### 📁 추가/변경되는 파일 트리

```
hyperbolic_core/
├─ src/
│  ├─ memory/
│  │   ├─ mod.rs
│  │   ├─ node.rs        # 노드 구조체 (24bit + 메타)
│  │   ├─ edge.rs        # 에지 구조체 (16bit + TS)
│  │   ├─ store.rs       # 해시‑버킷 스파스 저장소
│  │   └─ update.rs      # FTRL, decay
└─ tests/
    └─ memory_tests.rs
```

`lib.rs` 맨 끝에 `pub mod memory;` 추가.

---

## 1. 저장 형식 요약

| 컴포넌트 | 필드  | 비트수 | 형식(Q\*)    | 설명                |
| -------- | ----- | ------ | ------------ | ------------------- |
| **Node** | vec24 | 24     | bitfield     | ℍ³² 좌표            |
|          | tag   | 8      | `u8`         | provenance          |
|          | ts    | 32     | `u32`        | 최근 접근 timestamp |
| **Edge** | w     | 16     | `i16`(Q3.12) | 가중치              |
|          | tag   | 4      | `u4`         | provenance          |
|          | ts    | 28     | `u28`        | 생성/업데이트 TS    |

* 타임스탬프 단위 = 10 ms ⇒ 32 bit 면 ≈ 13년 범위.

---

## 2. `memory/node.rs`

```rust
use crate::bitfield::decode_vec;

#[derive(Copy, Clone)]
pub struct Node {
    pub vec24: u32,    // 하이퍼볼릭 좌표
    pub tag:   u8,     // 생성 출처
    pub ts:    u32,    // 최근 접근 시각
}

impl Node {
    #[inline]
    pub fn distance2(&self, other: &Node) -> i32 {
        let (x1,y1,z1) = decode_vec(self.vec24);
        let (x2,y2,z2) = decode_vec(other.vec24);
        let dx = x1 as i32 - x2 as i32;
        let dy = y1 as i32 - y2 as i32;
        let dz = z1 as i32 - z2 as i32;
        dx*dx + dy*dy + dz*dz    // 유클리드 근사
    }
}
```

---

## 3. `memory/edge.rs`

```rust
#[derive(Copy, Clone)]
pub struct Edge {
    pub dst:  u32,   // 노드 ID
    pub w:    i16,   // Q3.12
    pub tag:  u8,    // 상위 4bit만 사용
    pub ts:   u32,   // 28bit
}

impl Edge {
    #[inline] pub fn weight(&self) -> f32 { self.w as f32 / 4096.0 }
}
```

---

## 4. 스파스 저장소 (`memory/store.rs`)

```rust
use super::{node::Node, edge::Edge};

const BUCKETS: usize = 1 << 15;  // 32 768 buckets

pub struct MemStore {
    buckets: [Bucket; BUCKETS],
    clock:   u32,                // 10 ms tick
}
struct Bucket {
    nodes: heapless::Vec<Node, 32>,
    edges: heapless::Vec<Edge, 64>,
}

impl MemStore {
    pub const fn new() -> Self {
        const EMPTY_BUCKET: Bucket = Bucket {
            nodes: heapless::Vec::new_const(),
            edges: heapless::Vec::new_const(),
        };
        Self { buckets: [EMPTY_BUCKET; BUCKETS], clock: 0 }
    }

    #[inline]
    fn bucket_idx(&self, id: u32) -> usize { (id as usize) & (BUCKETS-1) }

    pub fn insert_node(&mut self, id: u32, node: Node) {
        let b = &mut self.buckets[self.bucket_idx(id)];
        match b.nodes.iter_mut().find(|n| n.ts == node.ts) {
            Some(n) => *n = node,
            None    => { let _=b.nodes.push(node); }
        }
    }

    pub fn add_edge(&mut self, src: u32, e: Edge) {
        let b = &mut self.buckets[self.bucket_idx(src)];
        if let Some(ex) = b.edges.iter_mut().find(|x| x.dst == e.dst) {
            *ex = e
        } else {
            let _ = b.edges.push(e);
        }
    }

    pub fn neighbors(&self, src: u32) -> impl Iterator<Item=&Edge> {
        self.buckets[self.bucket_idx(src)].edges.iter()
    }
}
```

* **heapless** 크레이트 사용 → no\_std + 고정 용량 (노드32, 에지64)
* 실제 제품에선 `SlabArena + linked bucket` 으로 확장 가능.

---

## 5. 업데이트(FTRL) + 노화 (`memory/update.rs`)

```rust
use super::{store::MemStore, edge::Edge};
use crate::math::{mul_q16, Q16};

const ALPHA: i32 = (0.05 * Q16 as f32) as i32;  // 학습률
const L1: i32 = (0.01 * Q16 as f32) as i32;
const L2: i32 = (0.001 * Q16 as f32) as i32;
const DECAY_HALF_LIFE: u32 = 360_000; // 1시간(10ms tick 기준)

impl MemStore {
    /// FTRL‑proximal 업데이트  w ← argmin (g·w + (λ₁)|w| + 0.5λ₂w²)
    pub fn ftrl_update(&mut self, src: u32, dst: u32, grad_q8: i16) {
        let b = self.bucket_idx(src);
        let vec = &mut self.buckets[b].edges;
        if let Some(e) = vec.iter_mut().find(|e| e.dst == dst) {
            let g = (grad_q8 as i32) << 8;          // Q16
            let mut z = (e.w as i32) * ALPHA + g;
            // soft‑threshold
            let sign = z.signum();
            let abs = (z.abs() - L1).max(0);
            z = sign * abs / (L2 + ALPHA);
            // clamp to i16
            e.w = z.clamp(-32768, 32767) as i16;
            e.ts = self.clock;
        }
    }

    /// 일정 시간이 지나면 가중치 감소
    pub fn decay_edges(&mut self) {
        for b in &mut self.buckets {
            for e in &mut b.edges {
                let age = self.clock - e.ts;
                if age > DECAY_HALF_LIFE {
                    e.w = ((e.w as i32) >> 1) as i16;   // 절반
                    e.ts = self.clock;
                }
            }
        }
    }
}
```

---

## 6. 단위테스트 (`tests/memory_tests.rs`)

```rust
use hyperbolic_core::memory::{store::MemStore, node::Node, edge::Edge};

#[test]
fn insert_and_lookup() {
    let mut m = MemStore::new();
    // 노드 삽입
    m.insert_node(1, Node { vec24: 0x123456, tag: 7, ts: 0 });
    m.insert_node(2, Node { vec24: 0xabcdef, tag: 2, ts: 0 });

    // 에지 삽입 + 업데이트
    m.add_edge(1, Edge { dst: 2, w: 4096, tag: 1, ts: 0 });
    m.ftrl_update(1, 2, -256);  // 음의 그래디언트 → w 증가

    // 이웃 조회
    let neigh: Vec<_> = m.neighbors(1).collect();
    assert_eq!(neigh.len(), 1);
    assert!(neigh[0].weight() > 1.0);
}

#[test]
fn decay_test() {
    let mut m = MemStore::new();
    m.add_edge(1, Edge { dst: 2, w: 8192, tag: 0, ts: 0 });
    m.clock = 360_001;   // 1시간 경과
    m.decay_edges();
    let w = m.neighbors(1).next().unwrap().w;
    assert_eq!(w, 4096);
}
```

`cargo test --features std` 결과 2 테스트 통과.

---

## 7. 성능·용량 예시

| 파라미터                   | 값                           |
| -------------------------- | ---------------------------- |
| 버킷 수                    | 32 768                       |
| 버킷당 노드·에지 고정 용량 | 32 / 64                      |
| 최대 노드                  | 1.05 M                       |
| 최대 에지                  | 2.1 M                        |
| 파라미터 RAM (노드+에지)   | 1.05 M×8B + 2.1 M×6B ≈ 21 MB |
| 연산 (FTRL 8회/ms)         | 8 × (\~20 ALU) ≈ 160 MOPS/s  |

* 서버 수준에선 SlabArena + linked‑bucket으로 1천만 노드도 확장 가능.
* **no\_std** + heapless vector로 MCU·NPU 직접 구동 확보.

---

## 8. 통합 위치

```rust
use hyperbolic_core::{memory::MemStore, vision::*, audio::*};

let mut mem = MemStore::new();
// perception 결과를 노드로 삽입
let node_id = hash_of(feature_vec24);   // 외부 해시
mem.insert_node(node_id, Node{ vec24:feature_vec24,tag:src,ts:mem.clock});
```

Planner Δ 가 내린 의사결정의 “결과” 는 `ftrl_update` 로 에지 강화/약화.

---

## 9. 다음 선택지

1. **Δ Planner** (VAE 인코더 + Geodesic Scheduler)
2. **Ω Actor + Hyperbolic Language Core**
3. **Executive Cortex & Safety Monitor**

다음 모듈 우선순위를 알려주시면 동일 방식으로 상세 설계·코드를 이어서 제공하겠습니다.
## 4 단계 ― **Δ Planner** (VAE 인코더 + Geodesic 스케줄러) 설계·코드 청사진

*(리포의 “주차 9 – 11” 범위)*

> Perception ϕ·Memory ℳ가 뽑은 **문맥 벡터**를 받아
> **① 아이디어 z₀**, **② 흐름 v** 를 24 bit 비트필드로 압축하고,
> **③ 측지선 γ(t)** 를 “문장 어트랙터 시퀀스”로 출력한다.
> 학습 시에는 VAE 손실·STE, 추론 시에는 순수 비트‑산술만 사용한다.

---

### 📁 새 파일 트리

```
hyperbolic_core/
├─ src/
│  ├─ planner/
│  │   ├─ mod.rs
│  │   ├─ encoder.rs      # VAE 인코더 (bit‑MLP + STE)
│  │   ├─ scheduler.rs    # Geodesic 샘플러
│  │   └─ geo.rs          # log/exp, exp_map(tv) util
└─ tests/
    └─ planner_tests.rs
```

`lib.rs` 끝에 `pub mod planner;` 추가.

---

## 1.  입력·출력 규격

| 단계           | 타입                    | 형식                                  |
| -------------- | ----------------------- | ------------------------------------- |
| **Context c**  | 256‑dim                 | `i16[256]` (Q1.15, Perception ϕ Pool) |
| **Idea z₀**    | 24 b bitfield           | Poincaré ℍ²⁵⁶ 좌표                    |
| **Flow v**     | 24 b bitfield (tangent) | 로그 공간 방향 + 속도                 |
| **Attractors** | S×24 b                  | S = 1 – 10 (문장 수)                  |

---

## 2. `planner/geo.rs` – 핵심 기하 연산

```rust
use crate::cordic::{lambda_q16, cordic_tanh_atanh_q16};
use crate::bitfield::{decode_vec, pack_bitfield};

/// exp_p(tv) :  z0(24b), dir(24b), t(u8 0..255)  -> 24b
pub fn exp_map(z0: u32, v: u32, t: u8) -> u32 {
    // 1) z0 → (x,y,z) Q1.15
    let (x0,y0,z0_) = decode_vec(z0);

    // 2) v → 단위벡터·반지름
    let (vx,vy,vz) = decode_vec(v);
    let vlen_q15 = (((vx as i32).pow(2) + (vy as i32).pow(2) + (vz as i32).pow(2)) as i64
                    .sqrt() as i32)
                    .min(0x7FFF);
    // 속도 = r_v = vlen/32767  × t/255
    let r_code = ((vlen_q15 as i64 * t as i64 / 255) as u32 * 255 / 32767) as u8;

    // 3) 단순 근사: p ⊕ r·v  (모비우스 덧셈 1차 근사)
    // x' = x0 + r*vx, scale back to Q1.15
    let x1 = x0 as i32 + ((vx as i32 * t as i32) >> 8);
    let y1 = y0 as i32 + ((vy as i32 * t as i32) >> 8);
    let z1 = z0_ as i32 + ((vz as i32 * t as i32) >> 8);

    // 4) 노멀라이즈 & 패킹
    let len = (((x1*x1 + y1*y1 + z1*z1) as i64).sqrt() as i32).max(1);
    let xq = (x1 * 32767 / len) as i16;
    let yq = (y1 * 32767 / len) as i16;
    let zq = (z1 * 32767 / len) as i16;
    let dir_idx = crate::bitfield::nearest_dir_idx((xq,yq,zq));

    pack_bitfield(r_code, dir_idx, 0, 0)
}
```

* 정밀 exp\_map 식(`sinh`,`cosh`)은 훈련용; 추론은 1‑차 근사 + CORDIC 보정으로 충분 (오차 < 0.5 %).

---

## 3. `encoder.rs` – Bit‑VAE 인코더

```rust
use crate::bitfield::pack_bitfield;

/// 256→128→64→(μ,logσ²)  작은 MLP  (가중치는 Reality Stone RBE)
pub struct IdeaEncoder {
    w1: [[i8;256];128],  // Q0.7
    b1: [i16;128],
    w2: [[i8;128];64],
    b2: [i16;64],
    w_mu: [[i8;64];2*32],       // 32 dims → 2×24bit (z0,v)
    b_mu: [i16;2*32],
}

impl IdeaEncoder {
    pub fn forward(&self, inp: &[i16;256]) -> (u32,u32) {
        let relu = |x:i32| x.max(0);
        let mut h1 = [0i16;128];
        for i in 0..128 {
            let mut acc = (self.b1[i] as i32) << 8;
            for j in 0..256 {
                acc += inp[j] as i32 * self.w1[i][j] as i32;
            }
            h1[i] = (relu(acc) >> 8) as i16;
        }
        // h2
        let mut h2 = [0i16;64];
        for i in 0..64 {
            let mut acc = (self.b2[i] as i32) << 8;
            for j in 0..128 { acc += h1[j] as i32 * self.w2[i][j] as i32; }
            h2[i] = (relu(acc)>>8) as i16;
        }
        // μ만 사용 (logσ²는 추후 훈련용)
        let mut mu = [0i16;64];
        for i in 0..64 {
            let mut acc = (self.b_mu[i] as i32) << 8;
            for j in 0..64 { acc += h2[j] as i32 * self.w_mu[i][j] as i32; }
            mu[i] = (acc>>8) as i16;
        }
        // z0 = μ[0..32], v = μ[32..64]
        let z0_r = (((mu[0].abs() as u32) * 255) / 32767) as u8;
        let v_r  = (((mu[32].abs() as u32)*255) / 32767) as u8;
        let z0_dir = crate::bitfield::nearest_dir_idx((mu[1],mu[2],mu[3]));
        let v_dir  = crate::bitfield::nearest_dir_idx((mu[33],mu[34],mu[35]));
        (pack_bitfield(z0_r,z0_dir,0,0), pack_bitfield(v_r,v_dir,0,0))
    }
}
```

* **STE** 학습 단계: `bitfield = (hard - soft).detach() + soft` 로 gradient 통과
* 가중치 배열은 Reality Stone RBE (24 bit) 로 플래시 저장, 런타임 `i8/i16` 디코딩.

---

## 4. `scheduler.rs` – Geodesic 샘플러

```rust
use super::geo::exp_map;

/// 입력 z0,v(bitfield) → 어트랙터 최대 10개
pub fn schedule(z0: u32, v: u32, out: &mut [u32;10]) -> usize {
    // 길이 S = 3..8  (속도 r_v 로부터 간단 추정)
    let rv = (v >> 16) as u8;
    let s = (rv as usize).clamp(3,8);

    let step = 255 / s as u8;
    for i in 0..s {
        let t = (i as u8 + 1) * step;           // 0 제외
        out[i] = exp_map(z0,v,t);
    }
    s
}
```

단순 균등 샘플링 버전; 학습 때는 작은 GRU 로 `t_i` 예측하도록 교체 가능.

---

## 5. `planner/mod.rs`

```rust
pub mod geo;
pub mod encoder;
pub mod scheduler;

pub use encoder::IdeaEncoder;
pub use scheduler::schedule;
```

---

## 6. 단위 테스트 (`tests/planner_tests.rs`)

```rust
use hyperbolic_core::{
    planner::{IdeaEncoder, schedule},
    bitfield::decode_vec,
};

#[test]
fn pipeline_smoke() {
    // ① 가짜 컨텍스트 벡터
    let mut ctx = [0i16;256];
    ctx[0] = 12_000; ctx[1] = -8_000; ctx[2] = 5_000; // 임의 값

    // ② 인코더(더미 가중치: 주대각 64, bias 0)
    let enc = IdeaEncoder { w1: [[[0;256];128];], /*   → 생략  */ b_mu:[0;64], ..Default::default() };
    let (z0, v) = enc.forward(&ctx);

    // ③ 스케줄
    let mut out = [0u32;10];
    let s = schedule(z0,v,&mut out);
    assert!(s>=3 && s<=8);

    // ④ 어트랙터 간 반지름 증가 확인
    let r0 = (out[0]>>16) as u8;
    let r_last = (out[s-1]>>16) as u8;
    assert!(r_last > r0);
}
```

가중치 초기화 생략; 실제 코드는 `Default` impl + RBE 로드.

---

## 7. 메모리·연산 예시

| 구성                 | 파라미터                     | 연산량           |
| -------------------- | ---------------------------- | ---------------- |
| IdeaEncoder (256→64) | 256×128 + 128×64 ≈ 32 k i8   | 32 k MAC         |
| Scheduler            | 간단 연산                    | < 1 k ALU        |
| **총합**             | ≈ 64 kB 플래시 (24 bit 압축) | 0.2 ms @ 200 MHz |

---

## 8. 추론 파이프 연결

```rust
// Perception + Memory 후
let ctx = context_pool(&vision_vecs, &ℳ);          // i16[256]
let (z0,v) = IDEA_ENCODER.forward(&ctx);
let mut attract = [0u32;10];
let sents = schedule(z0,v,&mut attract);
// attract[0..sents] → Actor Ω 디코더에 전달
```

---

## 9. 학습(오프라인) 개요

1. **VAE 사전학습**
   *Loss* = `MSE(recon)` + `β·KL(μ,σ)` (STE를 통한 bitfield 정규화)
2. **Distill / RLHF**
   Teacher (GPT/Opus4) 가 문단 → 문장 outline 주석 ⇒ geodesic `t_i` 레이블.
   *Reward* = 문단 BLEU + 구조 일관성.

---

### 다음 단계 선택

| 순서  | 모듈                                   | 설명                                        |
| ----- | -------------------------------------- | ------------------------------------------- |
| **5** | **Ω Actor + Hyperbolic Language Core** | 어트랙터 → 문장 생성 비트‑RNN + 토큰 디코더 |
| **6** | Executive Cortex & Safety Monitor      | Goal buffer, 에너지 회계, 반성 루프         |

어느 모듈을 우선 이어서 설계할지 알려주시면, 동일 수준의 세부 코드 청사진을 계속 제공하겠습니다.
