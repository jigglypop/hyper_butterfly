## 3a. 비트필드 압축 및 추론: 궁극의 파라미터 경량화

스플라인 압축이 기하학적 연속성을 활용하여 파라미터를 줄이는 방법이라면, 비트필드(Bitfield) 방법론은 한 걸음 더 나아가 각 가중치 행(row vector) 자체를 **단 몇 바이트의 이산적인 코드로 표현**하고, 심지어 **압축된 상태 그대로 행렬 곱셈을 수행**하여 추론 속도까지 가속하는 궁극의 경량화 기술이다.

### 3a.1 수학적 원리: 좌표계의 변환과 양자화

1.  **기하학적 표현 (Geometric Representation)**:
    -   신경망 가중치 행렬의 각 행 $w \in \mathbb{R}^n$이 푸앵카레 볼 $\mathbb{B}^n$ 내의 한 점이라고 가정한다 (학습 시 $\|w\|<1$ 제약).
    -   푸앵카레 볼의 기하학적 성질에 따라, 점 $w$는 원점에서의 로그 사상(Log map)을 통해 접공간(tangent space)의 벡터 $v = \log_0(w)$로 유일하게 대응된다.
    -   이 벡터 $v$는 다시 **크기(radius)** $r = \|v\|$와 **방향(direction)** $u = v/\|v\|$ 라는 극좌표계와 유사한 $(r, u)$ 쌍으로 유일하게 분해할 수 있다.
    -   따라서, 원래의 행 벡터 $w$는 다음 수식으로 완벽하게 복원된다. 이 관계가 전체 방법론의 수학적 무손실성을 보장하는 기초이다.
        $w = \exp_0(v) = \exp_0(r \cdot u) = \tanh(r/2) \cdot u$

2.  **이산화 및 양자화 (Discretization & Quantization)**:
    -   **방향의 이산화**: $n$차원 단위 구($S^{n-1}$) 위에 존재하는 무한히 많은 방향 벡터 $u$를, 미리 정의된 유한한 개수($B$)의 **단위 기저 벡터 테이블 $\{b_j\}_{j=1}^B$** 중 가장 가까운 하나로 근사한다. 이제 방향은 테이블의 인덱스 `idx`라는 정수로 표현된다.
    -   **크기의 양자화**: 연속적인 실수 값 $r$을 8비트(또는 k비트)의 고정소수점 값 `amp`(amplitude)로 양자화한다.
    -   이제 $w$의 정보는 `(idx, amp)`라는 이산적인 쌍으로 압축되었다.

### 3a.2 비트필드 설계

위의 이산화된 정보를 몇 가지 메타데이터와 함께 22비트(또는 24/32비트)의 정수 하나에 패킹(packing)한다.

| 필드 | 비트 폭 | 설명 |
| :--- | :--- | :--- |
| `cat` | 2 | 기하학의 종류 (Poincaré, Lorentz 등) |
| `sub` | 2 | 기저 함수의 종류 (exp/log, sinh/cosh, sin/cos) |
| `idx` | 8 | 방향을 가리키는 기저 테이블의 인덱스 (최대 256개) |
| `d` | 2 | 도함수 차수 (C∞ 함수의 주기성 활용) |
| `amp` | 8 | 크기(반지름)를 나타내는 8비트 고정소수점 값 |
| **합계**| **22** | **하나의 가중치 행을 단 3바이트 미만으로 표현** |

### 3a.3 압축 상태에서의 직접 추론

이 방법론의 가장 혁신적인 부분은, 가중치 행렬 $W$를 전부 복원하지 않고 **압축된 코드 상태 그대로** 행렬-벡터 곱셈($y = xW^T$)을 수행하는 것이다.

-   출력 벡터의 $i$번째 요소 $y_i$는 입력 $x$와 $i$번째 가중치 행 $w_i$의 내적이다.
    $y_i = x \cdot w_i$
-   $w_i = \tanh(r_i/2) \cdot u_i$ 관계를 대입하면,
    $y_i = x \cdot (\tanh(r_i/2) \cdot u_i)$
-   내적의 선형성에 의해 스칼라 항은 밖으로 나올 수 있다.
    $y_i = \tanh(r_i/2) \cdot (x \cdot u_i)$

이 수식 변환은 연산 패러다임을 바꾼다.
1.  **전처리 (Pre-computation)**: 입력 $x$가 들어오면, 기저 테이블의 모든 벡터 $\{b_j\}$와 내적한 값 `dotB[j] = x · b_j` 를 미리 계산해둔다. 이 연산은 $m$에 무관하게 단 한번만 수행된다.
2.  **메인 루프 (Main Loop)**: $m$개의 행을 순회하며 다음을 반복한다.
    a. $i$번째 행의 22비트 코드에서 `idx_i`와 `amp_i`를 비트 연산으로 빠르게 추출한다.
    b. `amp_i`로부터 스케일 값 $s_i = \tanh(r_i/2)$를 계산한다.
    c. 최종 결과 $y_i = s_i \cdot \text{dotB}[\text{idx}_i]$ 를 얻는다.

거대한 $O(m \cdot n)$ 행렬 곱셈이, 작은 전처리($O(B \cdot n)$)와 $m$번의 스칼라 곱셈($O(m)$)으로 대체된다. $B \ll m$인 현대 LLM 구조에서 이는 **FLOP과 메모리 대역폭 모두에서 극적인 성능 향상**을 가져온다.

### 3a.4 압축률 분석

-   **원본 파라미터 크기 (행 1개)**: $n \times 32$ bits
-   **압축 후 파라미터 크기 (행 1개)**: 22 bits (비트필드)
-   **압축률**: $\rho = \frac{22}{32n} \approx \frac{0.69}{n}$

$n=4096$인 Llama-3의 FFN 레이어의 경우, 압축률은 약 **0.017%**가 되어, 파라미터 크기를 **약 6000배** 줄일 수 있다. 여기에 기저 테이블의 크기($B \times n \times 16$ bits)가 더해지지만, 전체 모델에 걸쳐 공유되므로 그 영향은 미미하다. 