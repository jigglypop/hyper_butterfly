## 3. 방법론: Reality Stone의 핵심 구성 요소

`Reality Stone`은 연산 효율성과 파라미터 효율성을 달성하기 위해 두 가지 핵심 기술, 즉 Hyper-Butterfly 레이어와 스플라인 가중치 압축을 사용한다.

### 3.1 Hyper-Butterfly 레이어: 스펙트럼 기반 고속 연산자

Hyper-Butterfly 레이어는 기존 신경망의 밀집 행렬 곱셈($y=Wx$)을 저비용, 저파라미터 연산으로 대체하기 위해 설계되었다. 이 구조는 고속 푸리에 변환(FFT)의 나비(Butterfly) 연산 구조에서 영감을 받았으며, 이를 쌍곡 기하학에 맞게 일반화한 것이다.

Hyper-Butterfly 레이어는 입력 $x \in \mathbb{R}^N$에 대해 다음 세 단계의 연산을 수행한다.

1.  **로그 사상(Log Map)**: 입력 $x$를 쌍곡 다양체(푸앵카레 원반)의 원점에서의 접공간(유클리드 공간)으로 매핑한다.
$$ 
    u = \log_0^c(x) = \frac{\tanh^{-1}(\sqrt c\,\|x\|)}{\sqrt c\,\|x\|}\;x 
$$
2.  **버터플라이 변환(Butterfly Transform)**: 접공간 상의 벡터 $u$에 연속적인 버터플라이 행렬 곱을 적용한다. $N=2^L$일 때, $L$개의 버터플라이 행렬 $B_1, \dots, B_L$의 곱으로 선형 변환을 근사한다.
$$ 
v = B_L B_{L-1} \cdots B_1 u 
$$
    각 버터플라이 행렬 $B_\ell$은 2x2 블록 대각 행렬 형태로, 매우 적은 수의 파라미터($O(N)$)를 가진다. 전체 변환의 복잡도는 $O(N \log N)$이다.
3.  **지수 사상(Exp Map)**: 변환된 벡터 $v$를 다시 쌍곡 다양체로 매핑한다.
    $ y = \exp_0^c(v) = \tanh\bigl(\sqrt c\,\|v\|\bigr)\; \frac{v}{\sqrt c\,\|v\|} $

이 구조를 통해 밀집 행렬 $W \in \mathbb{R}^{N \times N}$이 요구하는 $O(N^2)$개의 파라미터와 연산량을 $O(N \log N)$ 수준으로 크게 절감할 수 있다.

### 3.2 스플라인 가중치 압축: 기하학적 파라미터화

대규모 언어 모델의 가중치 행렬 $W \in \mathbb{R}^{m \times n}$은 수백만에서 수십억 개의 파라미터를 포함한다. 스플라인 압축은 이 거대한 파라미터 공간을 기하학적으로 해석하여 극적인 압축을 달성하는 방법론이다.

핵심 아이디어는 $m$개의 행 벡터 $\{W_{i,:}\}_{i=1}^m \subset \mathbb{R}^n$ 전체를 **단 하나의 연속적인 곡선(스플라인) 위에 놓인 점들의 집합**으로 간주하는 것이다.

1.  **파라미터화**:
    -   **제어점(Control Points)**: 곡선의 모양을 결정하는 $(k+1)$개의 제어점 $\{P_j\}_{j=0}^k \subset \mathbb{R}^n$을 정의한다.
    -   **스플라인 함수**: 이 제어점들을 보간(interpolate)하여 매끄러운 곡선 $S(t): [0, k] \to \mathbb{R}^n$을 생성한다. Catmull-Rom 스플라인이나 B-스플라인 등이 사용될 수 있다.
2.  **무손실 복원**:
    -   원본 가중치 행렬의 각 행 $W_{i,:}$는 스플라인 곡선 위의 특정 파라미터 $t_i$에 해당하는 점으로 복원된다.
        $ W_{i,:} = S(t_i) $, 여기서 $t_i = \frac{i-1}{m-1}k$ 와 같이 균등하게 설정할 수 있다.
    -   따라서, 학습과 추론 시에는 $(k+1) \times n$개의 제어점 파라미터만 저장하고, 실제 연산이 필요할 때마다 이로부터 전체 가중치 행렬 $W$를 복원하여 사용한다.
3.  **리만 스플라인으로의 확장**:
    -   위의 과정을 유클리드 공간 대신 쌍곡 공간과 같은 리만 다양체 위에서 수행할 수 있다. 이 경우, 직선 보간은 **측지선(geodesic) 보간**으로 대체되고, 제어점은 다양체 위의 점이 된다. 이를 통해 데이터의 내재적 기하학을 존중하는 압축이 가능하다.

### 3.3 압축률 분석

스플라인 압축 방식의 압축률은 다음과 같이 분석된다.

-   **원본 파라미터 수**: $m \times n$
-   **압축 후 파라미터 수**: $(k+1) \times n$ (제어점)
-   **압축률**:
    $ \text{압축률} = \frac{(k+1)n}{mn} = \frac{k+1}{m} $

예를 들어, $m=3072$인 레이어에 대해 제어점을 50개($k+1=50$)만 사용한다면, 압축률은 $50/3072 \approx 1.6\%$가 된다. 즉, 파라미터 수를 98% 이상 절감할 수 있다. 이처럼 스플라인 압축은 모델의 크기를 수십에서 수백 배까지 줄일 수 있는 잠재력을 가진다.

**중요한 전제 조건**: 이와 같은 높은 압축률은 모델 학습 초기부터 가중치가 스플라인 곡선 위에 존재한다는 제약 하에 훈련될 때 달성 가능하다. 이미 학습된 모델에 사후 적용할 경우 정보 손실이 발생할 수 있다.

### 3.4 HeightField 방식: 안정성을 중시한 파라미터화

스플라인 방식이 높은 압축률을 제공하는 반면, 표현력에 제약을 가할 수 있다는 단점이 있다. HeightField 방식은 압축률을 일부 희생하는 대신, 원본 가중치의 자유도를 거의 그대로 보존하여 안정성을 극대화하는 접근법이다.

-   **아이디어**: 가중치 행렬의 각 행 $W_{i,:} \in \mathbb{R}^n$을 $(n-1)$차원의 좌표 벡터 $u_i \in \mathbb{R}^{n-1}$와, 그 좌표에 의해 결정되는 높이(고도) 값 $h(u_i) \in \mathbb{R}$의 결합으로 본다. 즉, $W_{i,:} = [u_i, h(u_i)]$.
-   **파라미터화**:
    -   학습 가능한 파라미터는 $m \times (n-1)$개의 좌표 $u_i$와, 높이 함수 $h(\cdot)$를 근사하는 작은 MLP의 가중치 $P$개이다.
    -   총 파라미터 수: $m \times (n-1) + P$.
-   **압축률**:
    $ \text{압축률} \approx \frac{m(n-1)}{mn} = 1 - \frac{1}{n} $
    이는 $n=768$일 경우 약 99.87%로, 압축 효과는 미미하지만 원본 가중치의 정보를 거의 손실 없이 파라미터화할 수 있다는 장점이 있다. 