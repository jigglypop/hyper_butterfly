# Lorentz ë ˆì´ì–´

## ğŸ“ ê°œìš”

Lorentz ë ˆì´ì–´ëŠ” ë¡œë Œì¸  ëª¨ë¸(í•˜ì´í¼ë³¼ë¡œì´ë“œ ëª¨ë¸)ì—ì„œ ë™ì‘í•˜ëŠ” í•˜ì´í¼ë³¼ë¦­ ì‹ ê²½ë§ ë ˆì´ì–´ì…ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ ë¯¼ì½”í”„ìŠ¤í‚¤ ê³µê°„ì˜ ë¶€ë¶„ ë§¤ë‹ˆí´ë“œë¡œì„œ í•˜ì´í¼ë³¼ë¦­ ê³µê°„ì„ í‘œí˜„í•˜ë©°, ì„ í˜• ëŒ€ìˆ˜ ì—°ì‚°ì´ ë” ì§ê´€ì ì…ë‹ˆë‹¤.

## ğŸ§® ìˆ˜í•™ì  ë°°ê²½

### ë¡œë Œì¸  ëª¨ë¸ (í•˜ì´í¼ë³¼ë¡œì´ë“œ)
í•˜ì´í¼ë³¼ë¡œì´ë“œ $\mathbb{L}^n = \{x \in \mathbb{R}^{n+1} : \langle x,x \rangle_{\mathcal{L}} = -1, x_0 > 0\}$

**ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì **:
$$\langle x,y \rangle_{\mathcal{L}} = -x_0y_0 + \sum_{i=1}^n x_iy_i$$

**ê±°ë¦¬ í•¨ìˆ˜**:
$$d_{\mathbb{L}}(x,y) = \text{arccosh}(-\langle x,y \rangle_{\mathcal{L}})$$

### ë¡œë Œì¸  ëª¨ë¸ì˜ ì¥ì 

1. **ì„ í˜•ì„±**: ì ‘ì„  ê³µê°„ì—ì„œì˜ ì—°ì‚°ì´ ì§ê´€ì 
2. **ì•ˆì •ì„±**: ìˆ˜ì¹˜ì ìœ¼ë¡œ ë” ì•ˆì •í•¨
3. **ëŒ€ì¹­ì„±**: ëª¨ë“  ë°©í–¥ì´ ê¸°í•˜í•™ì ìœ¼ë¡œ ë™ë“±

### í•˜ì´í¼ë³¼ë¦­ ì„ í˜• ë³€í™˜

ë¡œë Œì¸  ëª¨ë¸ì—ì„œì˜ ì„ í˜• ë³€í™˜:

$$f(x) = \text{proj}_{\mathbb{L}}(Wx + b)$$

ì—¬ê¸°ì„œ $\text{proj}_{\mathbb{L}}$ëŠ” í•˜ì´í¼ë³¼ë¡œì´ë“œë¡œì˜ íˆ¬ì˜ í•¨ìˆ˜ì…ë‹ˆë‹¤.

**íˆ¬ì˜ í•¨ìˆ˜**:
$$\text{proj}_{\mathbb{L}}(y) = \frac{y}{\sqrt{|\langle y,y \rangle_{\mathcal{L}}|}} \text{ if } \langle y,y \rangle_{\mathcal{L}} < 0$$

## ğŸ”§ êµ¬í˜„ ìƒì„¸

### 1. Forward Pass

```cpp
torch::Tensor lorentz_forward_cpu(
    const torch::Tensor& input,
    const torch::Tensor& weight,
    const torch::Tensor& bias,
    float curvature
)
```

**êµ¬í˜„ íë¦„**:
1. **ì…ë ¥ ê²€ì¦**: ì…ë ¥ì´ í•˜ì´í¼ë³¼ë¡œì´ë“œ ìœ„ì— ìˆëŠ”ì§€ í™•ì¸
2. **ì ‘ì„  ê³µê°„ ë³€í™˜**: ë¡œê·¸ ë§¤í•‘ì„ í†µí•´ ì ‘ì„  ê³µê°„ìœ¼ë¡œ ì´ë™
3. **ìœ í´ë¦¬ë“œ ì—°ì‚°**: $Wx + b$ ê³„ì‚°
4. **ë§¤ë‹ˆí´ë“œ ë³µê·€**: ì§€ìˆ˜ ë§¤í•‘ì„ í†µí•´ í•˜ì´í¼ë³¼ë¡œì´ë“œë¡œ ë³µê·€

### 2. ë¡œê·¸ ë§¤í•‘ (Logarithmic Map)

ì ‘ì„  ê³µê°„ìœ¼ë¡œì˜ ë§¤í•‘:

$$\log_x(y) = \frac{\text{arccosh}(-\langle x,y \rangle_{\mathcal{L}})}{\|\text{proj}_{T_x\mathbb{L}}(y)\|} \cdot \text{proj}_{T_x\mathbb{L}}(y)$$

```cpp
torch::Tensor lorentz_log_map(
    const torch::Tensor& x,
    const torch::Tensor& y
) {
    auto inner_product = lorentz_inner(x, y);  // ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì 
    auto distance = torch::acosh(-inner_product.clamp_min(1.0f + EPS));
    
    // ì ‘ì„  ê³µê°„ìœ¼ë¡œ íˆ¬ì˜
    auto tangent = y + inner_product.unsqueeze(-1) * x;
    auto tangent_norm = torch::norm(tangent, 2, -1, true);
    
    return distance.unsqueeze(-1) * tangent / tangent_norm.clamp_min(EPS);
}
```

### 3. ì§€ìˆ˜ ë§¤í•‘ (Exponential Map)

ë§¤ë‹ˆí´ë“œë¡œì˜ ë³µê·€:

$$\exp_x(v) = \cosh(\|v\|)x + \sinh(\|v\|)\frac{v}{\|v\|}$$

```cpp
torch::Tensor lorentz_exp_map(
    const torch::Tensor& x,
    const torch::Tensor& v
) {
    auto v_norm = torch::norm(v, 2, -1, true);
    auto cosh_norm = torch::cosh(v_norm);
    auto sinh_norm = torch::sinh(v_norm);
    
    auto result = cosh_norm.unsqueeze(-1) * x;
    
    auto v_normalized = v / v_norm.clamp_min(EPS);
    result += sinh_norm.unsqueeze(-1) * v_normalized;
    
    return result;
}
```

### 4. Backward Pass

ë¡œë Œì¸  ëª¨ë¸ì—ì„œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°:

```cpp
torch::Tensor lorentz_backward_cpu(
    const torch::Tensor& grad_output,
    const torch::Tensor& input,
    const torch::Tensor& weight,
    float curvature
) {
    // ì ‘ì„  ê³µê°„ì—ì„œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°
    auto tangent_grad = parallel_transport(grad_output, input);
    
    // ê°€ì¤‘ì¹˜ ê·¸ë˜ë””ì–¸íŠ¸
    auto weight_grad = torch::mm(tangent_grad.transpose(-2, -1), input);
    
    // ì…ë ¥ ê·¸ë˜ë””ì–¸íŠ¸ (ì ‘ì„  ê³µê°„)
    auto input_grad = torch::mm(tangent_grad, weight);
    
    return input_grad;
}
```

## ğŸ“Š ì„±ëŠ¥ íŠ¹ì„±

### ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±

ë¡œë Œì¸  ëª¨ë¸ì€ nì°¨ì› í•˜ì´í¼ë³¼ë¦­ ê³µê°„ì„ (n+1)ì°¨ì›ìœ¼ë¡œ ì„ë² ë”©í•˜ë¯€ë¡œ:

- **ë©”ëª¨ë¦¬ ì˜¤ë²„í—¤ë“œ**: +1 ì°¨ì› (ì•½ 1/nì˜ ì¶”ê°€ ë©”ëª¨ë¦¬)
- **ê³„ì‚° ì˜¤ë²„í—¤ë“œ**: ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì  ê³„ì‚°

### ìˆ˜ì¹˜ì  ì•ˆì •ì„±

í¬ì¸ì¹´ë ˆ ëª¨ë¸ ëŒ€ë¹„ ì¥ì :

1. **ê²½ê³„ ë¬¸ì œ ì—†ìŒ**: í•˜ì´í¼ë³¼ë¡œì´ë“œëŠ” ë‹«íŒ ì§‘í•©ì´ ì•„ë‹˜
2. **ì¼ê´€ëœ ìŠ¤ì¼€ì¼**: ëª¨ë“  ì ì—ì„œ ë™ì¼í•œ ê¸°í•˜í•™ì  êµ¬ì¡°
3. **ì§êµì„±**: ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì ì˜ ì§êµì„±

## ğŸ¯ ì‚¬ìš© ì˜ˆì œ

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
import torch
import reality_stone as rs

# ë¡œë Œì¸  ë ˆì´ì–´ ì´ˆê¸°í™”
layer = rs.LorentzLayer(
    input_dim=128,
    output_dim=64,
    curvature=1.0,
    bias=True
)

# ì…ë ¥ ë°ì´í„° (í•˜ì´í¼ë³¼ë¡œì´ë“œ ìœ„ì˜ ì ë“¤)
# ì²« ë²ˆì§¸ ì¢Œí‘œëŠ” sqrt(1 + ||x||^2)ë¡œ ì„¤ì •
x_euclidean = torch.randn(32, 128) * 0.1
x_0 = torch.sqrt(1 + torch.sum(x_euclidean**2, dim=1, keepdim=True))
x = torch.cat([x_0, x_euclidean], dim=1)  # [32, 129]

# Forward pass
output = layer(x)
print(f"Output shape: {output.shape}")  # [32, 65]

# í•˜ì´í¼ë³¼ë¡œì´ë“œ ì œì•½ ì¡°ê±´ í™•ì¸
lorentz_inner = rs.lorentz_inner_cpu(output, output)
print(f"Lorentz inner product: {lorentz_inner[:5]}")  # ëª¨ë‘ -1ì— ê°€ê¹Œì›Œì•¼ í•¨
```

### í¬ì¸ì¹´ë ˆ-ë¡œë Œì¸  ë³€í™˜

```python
# í¬ì¸ì¹´ë ˆ ë””ìŠ¤í¬ì—ì„œ ë¡œë Œì¸  ëª¨ë¸ë¡œ ë³€í™˜
poincare_points = torch.randn(32, 64) * 0.3
lorentz_points = rs.poincare_to_lorentz_cpu(poincare_points, curvature=1.0)

# ë¡œë Œì¸  ë ˆì´ì–´ ì ìš©
lorentz_layer = rs.LorentzLayer(65, 33, curvature=1.0)
lorentz_output = lorentz_layer(lorentz_points)

# ë‹¤ì‹œ í¬ì¸ì¹´ë ˆë¡œ ë³€í™˜
poincare_output = rs.lorentz_to_poincare_cpu(lorentz_output, curvature=1.0)
```

### ê³„ì¸µì  ì„ë² ë”©

```python
class LorentzHierarchicalEncoder(torch.nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dims, curvature=1.0):
        super().__init__()
        self.curvature = curvature
        
        # ìœ í´ë¦¬ë“œ ì„ë² ë”©
        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)
        
        # ë¡œë Œì¸  ë ˆì´ì–´ë“¤
        dims = [embed_dim + 1] + [d + 1 for d in hidden_dims]
        self.lorentz_layers = torch.nn.ModuleList([
            rs.LorentzLayer(dims[i], dims[i+1], curvature)
            for i in range(len(dims)-1)
        ])
        
    def forward(self, tokens):
        # ìœ í´ë¦¬ë“œ ì„ë² ë”©
        x = self.embedding(tokens)  # [batch, seq_len, embed_dim]
        
        # ë¡œë Œì¸  ê³µê°„ìœ¼ë¡œ ë³€í™˜
        x = rs.euclidean_to_lorentz(x)  # [batch, seq_len, embed_dim+1]
        
        # ë¡œë Œì¸  ë ˆì´ì–´ë“¤ ì ìš©
        for layer in self.lorentz_layers:
            x = torch.tanh(layer(x))  # í•˜ì´í¼ë³¼ë¦­ í™œì„±í™”
            
        return x

# ì‚¬ìš© ì˜ˆì œ
model = LorentzHierarchicalEncoder(
    vocab_size=10000,
    embed_dim=128,
    hidden_dims=[64, 32],
    curvature=1.0
)

tokens = torch.randint(0, 10000, (16, 20))  # [batch, seq_len]
embeddings = model(tokens)
```

## âš¡ CUDA ìµœì í™”

### ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì  ìµœì í™”

```cuda
__device__ float lorentz_inner_product(
    const float* __restrict__ x,
    const float* __restrict__ y,
    int dim
) {
    float result = -x[0] * y[0];  // ì‹œê°„ ì„±ë¶„
    
    // ê³µê°„ ì„±ë¶„ë“¤ (ì–¸ë¡¤ë§ìœ¼ë¡œ ìµœì í™”)
    for (int i = 1; i < dim; i += 4) {
        float4 x_vec = reinterpret_cast<const float4*>(x + i)[0];
        float4 y_vec = reinterpret_cast<const float4*>(y + i)[0];
        
        result += x_vec.x * y_vec.x;
        result += x_vec.y * y_vec.y;
        result += x_vec.z * y_vec.z;
        result += x_vec.w * y_vec.w;
    }
    
    return result;
}
```

### ë©”ëª¨ë¦¬ ì ‘ê·¼ íŒ¨í„´ ìµœì í™”

```cuda
__global__ void lorentz_forward_kernel(
    const float* __restrict__ input,
    const float* __restrict__ weight,
    const float* __restrict__ bias,
    float* __restrict__ output,
    int batch_size,
    int input_dim,
    int output_dim
) {
    // íƒ€ì¼ë§ì„ í†µí•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
    __shared__ float s_input[TILE_SIZE][TILE_SIZE];
    __shared__ float s_weight[TILE_SIZE][TILE_SIZE];
    
    int tx = threadIdx.x, ty = threadIdx.y;
    int bx = blockIdx.x, by = blockIdx.y;
    
    // ... ìµœì í™”ëœ ë§¤íŠ¸ë¦­ìŠ¤ ê³±ì…ˆ
}
```

## ğŸ” ëª¨ë¸ê°„ ë³€í™˜

### í¬ì¸ì¹´ë ˆ â†” ë¡œë Œì¸ 

```cpp
// í¬ì¸ì¹´ë ˆ â†’ ë¡œë Œì¸ 
torch::Tensor poincare_to_lorentz_cpu(
    const torch::Tensor& x,
    float curvature
) {
    auto x_norm_sq = torch::sum(x * x, -1, true);
    auto x_0 = (1 + curvature * x_norm_sq) / (1 - curvature * x_norm_sq);
    auto x_rest = 2 * x / (1 - curvature * x_norm_sq);
    
    return torch::cat({x_0, x_rest}, -1);
}

// ë¡œë Œì¸  â†’ í¬ì¸ì¹´ë ˆ
torch::Tensor lorentz_to_poincare_cpu(
    const torch::Tensor& x,
    float curvature
) {
    auto x_0 = x.narrow(-1, 0, 1);
    auto x_rest = x.narrow(-1, 1, x.size(-1) - 1);
    
    return x_rest / (x_0 + 1.0f / std::sqrt(curvature));
}
```

## ğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼

### ê³„ì‚° ë³µì¡ë„ ë¹„êµ

| ì—°ì‚° | í¬ì¸ì¹´ë ˆ | ë¡œë Œì¸  | ì„±ëŠ¥ë¹„ |
|------|----------|--------|--------|
| ë‚´ì  ê³„ì‚° | O(n) | O(n+1) | 0.95x |
| ê±°ë¦¬ ê³„ì‚° | O(n) | O(n+1) | 0.98x |
| ì„ í˜• ë³€í™˜ | O(nÂ²) + O(mobius) | O(nÂ²) + O(proj) | 1.1x |

### GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

| ë°°ì¹˜ í¬ê¸° | ì°¨ì› | í¬ì¸ì¹´ë ˆ (MB) | ë¡œë Œì¸  (MB) | ë¹„ìœ¨ |
|-----------|------|---------------|-------------|------|
| 32 | 128 | 1.6 | 1.65 | 1.03x |
| 128 | 256 | 12.8 | 13.3 | 1.04x |
| 512 | 512 | 102.4 | 106.5 | 1.04x |

## ğŸ”— ê´€ë ¨ í•¨ìˆ˜

- [`lorentz_add_cpu/cuda`](../ops/lorentz.md#ë¡œë Œì¸ -ë§ì…ˆ): ë¡œë Œì¸  ë§ì…ˆ ì—°ì‚°
- [`lorentz_inner_cpu/cuda`](../ops/lorentz.md#ë¯¼ì½”í”„ìŠ¤í‚¤-ë‚´ì ): ë¯¼ì½”í”„ìŠ¤í‚¤ ë‚´ì 
- [`lorentz_distance_cpu/cuda`](../ops/lorentz.md#í•˜ì´í¼ë³¼ë¦­-ê±°ë¦¬): í•˜ì´í¼ë³¼ë¦­ ê±°ë¦¬ ê³„ì‚°

## ğŸ“š ì°¸ê³  ë¬¸í—Œ

1. **Hyperbolic Neural Networks** - Ganea et al. (2018)
2. **Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry** - Nickel & Kiela (2018)
3. **Hyperbolic Graph Neural Networks** - Chami et al. (2019)
4. **Hyperbolic Deep Neural Networks: A Survey** - Peng et al. (2021) 